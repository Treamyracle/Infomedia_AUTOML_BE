2026-02-02 15:30:17,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 15:30:17,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 15:30:17,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 15:30:17,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:03:51,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:03:51,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:03:51,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:03:51,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:14:23,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:14:23,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:14:23,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:14:23,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:47,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:47,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:47,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:47,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:57,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:57,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:57,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:15:57,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:16:09,645:INFO:PyCaret ClassificationExperiment
2026-02-02 16:16:09,646:INFO:Logging name: clf-default-name
2026-02-02 16:16:09,646:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-02 16:16:09,646:INFO:version 3.3.2
2026-02-02 16:16:09,646:INFO:Initializing setup()
2026-02-02 16:16:09,646:INFO:self.USI: fa90
2026-02-02 16:16:09,646:INFO:self._variable_keys: {'fold_generator', 'exp_id', 'idx', 'USI', 'seed', 'html_param', 'data', 'X_test', 'n_jobs_param', 'target_param', 'y_train', 'exp_name_log', 'gpu_n_jobs_param', 'fold_groups_param', 'is_multiclass', 'X_train', 'fold_shuffle_param', 'logging_param', '_available_plots', 'pipeline', 'log_plots_param', 'y', 'memory', 'fix_imbalance', '_ml_usecase', 'X', 'gpu_param', 'y_test'}
2026-02-02 16:16:09,646:INFO:Checking environment
2026-02-02 16:16:09,646:INFO:python_version: 3.11.9
2026-02-02 16:16:09,646:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-02 16:16:09,646:INFO:machine: AMD64
2026-02-02 16:16:09,660:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-02 16:16:09,661:INFO:Memory: svmem(total=16866873344, available=3706916864, percent=78.0, used=13159956480, free=3706916864)
2026-02-02 16:16:09,661:INFO:Physical Core: 8
2026-02-02 16:16:09,661:INFO:Logical Core: 16
2026-02-02 16:16:09,661:INFO:Checking libraries
2026-02-02 16:16:09,661:INFO:System:
2026-02-02 16:16:09,661:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-02 16:16:09,661:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-02 16:16:09,661:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-02 16:16:09,661:INFO:PyCaret required dependencies:
2026-02-02 16:16:09,974:INFO:                 pip: 24.0
2026-02-02 16:16:09,974:INFO:          setuptools: 80.9.0
2026-02-02 16:16:09,974:INFO:             pycaret: 3.3.2
2026-02-02 16:16:09,974:INFO:             IPython: 9.8.0
2026-02-02 16:16:09,974:INFO:          ipywidgets: 8.1.8
2026-02-02 16:16:09,974:INFO:                tqdm: 4.67.1
2026-02-02 16:16:09,974:INFO:               numpy: 1.26.4
2026-02-02 16:16:09,975:INFO:              pandas: 2.1.4
2026-02-02 16:16:09,975:INFO:              jinja2: 3.1.6
2026-02-02 16:16:09,975:INFO:               scipy: 1.11.4
2026-02-02 16:16:09,975:INFO:              joblib: 1.3.2
2026-02-02 16:16:09,975:INFO:             sklearn: 1.4.2
2026-02-02 16:16:09,975:INFO:                pyod: 2.0.6
2026-02-02 16:16:09,975:INFO:            imblearn: 0.14.1
2026-02-02 16:16:09,975:INFO:   category_encoders: 2.7.0
2026-02-02 16:16:09,975:INFO:            lightgbm: 4.6.0
2026-02-02 16:16:09,975:INFO:               numba: 0.63.1
2026-02-02 16:16:09,975:INFO:            requests: 2.32.5
2026-02-02 16:16:09,975:INFO:          matplotlib: 3.7.5
2026-02-02 16:16:09,975:INFO:          scikitplot: 0.3.7
2026-02-02 16:16:09,975:INFO:         yellowbrick: 1.5
2026-02-02 16:16:09,975:INFO:              plotly: 6.5.0
2026-02-02 16:16:09,975:INFO:    plotly-resampler: Not installed
2026-02-02 16:16:09,975:INFO:             kaleido: 1.2.0
2026-02-02 16:16:09,975:INFO:           schemdraw: 0.15
2026-02-02 16:16:09,975:INFO:         statsmodels: 0.14.6
2026-02-02 16:16:09,975:INFO:              sktime: 0.26.0
2026-02-02 16:16:09,975:INFO:               tbats: 1.1.3
2026-02-02 16:16:09,975:INFO:            pmdarima: 2.0.4
2026-02-02 16:16:09,975:INFO:              psutil: 7.1.3
2026-02-02 16:16:09,975:INFO:          markupsafe: 3.0.3
2026-02-02 16:16:09,976:INFO:             pickle5: Not installed
2026-02-02 16:16:09,976:INFO:         cloudpickle: 3.1.2
2026-02-02 16:16:09,976:INFO:         deprecation: 2.1.0
2026-02-02 16:16:09,976:INFO:              xxhash: 3.6.0
2026-02-02 16:16:09,976:INFO:           wurlitzer: Not installed
2026-02-02 16:16:09,976:INFO:PyCaret optional dependencies:
2026-02-02 16:16:10,195:INFO:                shap: Not installed
2026-02-02 16:16:10,195:INFO:           interpret: Not installed
2026-02-02 16:16:10,195:INFO:                umap: Not installed
2026-02-02 16:16:10,195:INFO:     ydata_profiling: Not installed
2026-02-02 16:16:10,195:INFO:  explainerdashboard: Not installed
2026-02-02 16:16:10,196:INFO:             autoviz: Not installed
2026-02-02 16:16:10,196:INFO:           fairlearn: Not installed
2026-02-02 16:16:10,196:INFO:          deepchecks: Not installed
2026-02-02 16:16:10,196:INFO:             xgboost: 3.1.2
2026-02-02 16:16:10,196:INFO:            catboost: 1.2.8
2026-02-02 16:16:10,196:INFO:              kmodes: Not installed
2026-02-02 16:16:10,196:INFO:             mlxtend: Not installed
2026-02-02 16:16:10,196:INFO:       statsforecast: Not installed
2026-02-02 16:16:10,196:INFO:        tune_sklearn: Not installed
2026-02-02 16:16:10,196:INFO:                 ray: Not installed
2026-02-02 16:16:10,196:INFO:            hyperopt: Not installed
2026-02-02 16:16:10,196:INFO:              optuna: 4.6.0
2026-02-02 16:16:10,196:INFO:               skopt: Not installed
2026-02-02 16:16:10,196:INFO:              mlflow: Not installed
2026-02-02 16:16:10,196:INFO:              gradio: Not installed
2026-02-02 16:16:10,197:INFO:             fastapi: 0.123.10
2026-02-02 16:16:10,197:INFO:             uvicorn: 0.38.0
2026-02-02 16:16:10,197:INFO:              m2cgen: Not installed
2026-02-02 16:16:10,197:INFO:           evidently: Not installed
2026-02-02 16:16:10,197:INFO:               fugue: Not installed
2026-02-02 16:16:10,197:INFO:           streamlit: Not installed
2026-02-02 16:16:10,197:INFO:             prophet: Not installed
2026-02-02 16:16:10,197:INFO:None
2026-02-02 16:16:10,197:INFO:Set up data.
2026-02-02 16:16:10,254:INFO:Set up folding strategy.
2026-02-02 16:16:10,254:INFO:Set up train/test split.
2026-02-02 16:23:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:20,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:20,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:28,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:28,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:28,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:28,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-02 16:23:50,789:INFO:PyCaret ClassificationExperiment
2026-02-02 16:23:50,789:INFO:Logging name: clf-default-name
2026-02-02 16:23:50,790:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-02 16:23:50,790:INFO:version 3.3.2
2026-02-02 16:23:50,790:INFO:Initializing setup()
2026-02-02 16:23:50,790:INFO:self.USI: 137a
2026-02-02 16:23:50,790:INFO:self._variable_keys: {'y', 'data', 'X_test', 'gpu_n_jobs_param', 'y_test', 'n_jobs_param', 'fix_imbalance', 'memory', 'X_train', 'fold_generator', '_available_plots', 'seed', 'is_multiclass', 'USI', 'idx', 'fold_shuffle_param', 'log_plots_param', 'fold_groups_param', 'target_param', 'X', 'exp_name_log', 'pipeline', 'gpu_param', 'exp_id', 'y_train', '_ml_usecase', 'logging_param', 'html_param'}
2026-02-02 16:23:50,790:INFO:Checking environment
2026-02-02 16:23:50,790:INFO:python_version: 3.11.9
2026-02-02 16:23:50,790:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-02 16:23:50,790:INFO:machine: AMD64
2026-02-02 16:23:50,803:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-02 16:23:50,804:INFO:Memory: svmem(total=16866873344, available=3402387456, percent=79.8, used=13464485888, free=3402387456)
2026-02-02 16:23:50,805:INFO:Physical Core: 8
2026-02-02 16:23:50,805:INFO:Logical Core: 16
2026-02-02 16:23:50,805:INFO:Checking libraries
2026-02-02 16:23:50,805:INFO:System:
2026-02-02 16:23:50,805:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-02 16:23:50,805:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-02 16:23:50,805:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-02 16:23:50,806:INFO:PyCaret required dependencies:
2026-02-02 16:23:50,933:INFO:                 pip: 24.0
2026-02-02 16:23:50,933:INFO:          setuptools: 80.9.0
2026-02-02 16:23:50,933:INFO:             pycaret: 3.3.2
2026-02-02 16:23:50,933:INFO:             IPython: 9.8.0
2026-02-02 16:23:50,933:INFO:          ipywidgets: 8.1.8
2026-02-02 16:23:50,934:INFO:                tqdm: 4.67.1
2026-02-02 16:23:50,934:INFO:               numpy: 1.26.4
2026-02-02 16:23:50,934:INFO:              pandas: 2.1.4
2026-02-02 16:23:50,934:INFO:              jinja2: 3.1.6
2026-02-02 16:23:50,934:INFO:               scipy: 1.11.4
2026-02-02 16:23:50,934:INFO:              joblib: 1.3.2
2026-02-02 16:23:50,934:INFO:             sklearn: 1.4.2
2026-02-02 16:23:50,934:INFO:                pyod: 2.0.6
2026-02-02 16:23:50,934:INFO:            imblearn: 0.14.1
2026-02-02 16:23:50,934:INFO:   category_encoders: 2.7.0
2026-02-02 16:23:50,934:INFO:            lightgbm: 4.6.0
2026-02-02 16:23:50,934:INFO:               numba: 0.63.1
2026-02-02 16:23:50,934:INFO:            requests: 2.32.5
2026-02-02 16:23:50,934:INFO:          matplotlib: 3.7.5
2026-02-02 16:23:50,934:INFO:          scikitplot: 0.3.7
2026-02-02 16:23:50,934:INFO:         yellowbrick: 1.5
2026-02-02 16:23:50,934:INFO:              plotly: 6.5.0
2026-02-02 16:23:50,934:INFO:    plotly-resampler: Not installed
2026-02-02 16:23:50,935:INFO:             kaleido: 1.2.0
2026-02-02 16:23:50,935:INFO:           schemdraw: 0.15
2026-02-02 16:23:50,935:INFO:         statsmodels: 0.14.6
2026-02-02 16:23:50,935:INFO:              sktime: 0.26.0
2026-02-02 16:23:50,935:INFO:               tbats: 1.1.3
2026-02-02 16:23:50,935:INFO:            pmdarima: 2.0.4
2026-02-02 16:23:50,935:INFO:              psutil: 7.1.3
2026-02-02 16:23:50,935:INFO:          markupsafe: 3.0.3
2026-02-02 16:23:50,935:INFO:             pickle5: Not installed
2026-02-02 16:23:50,935:INFO:         cloudpickle: 3.1.2
2026-02-02 16:23:50,935:INFO:         deprecation: 2.1.0
2026-02-02 16:23:50,935:INFO:              xxhash: 3.6.0
2026-02-02 16:23:50,935:INFO:           wurlitzer: Not installed
2026-02-02 16:23:50,935:INFO:PyCaret optional dependencies:
2026-02-02 16:23:50,995:INFO:                shap: Not installed
2026-02-02 16:23:50,995:INFO:           interpret: Not installed
2026-02-02 16:23:50,995:INFO:                umap: Not installed
2026-02-02 16:23:50,995:INFO:     ydata_profiling: Not installed
2026-02-02 16:23:50,995:INFO:  explainerdashboard: Not installed
2026-02-02 16:23:50,995:INFO:             autoviz: Not installed
2026-02-02 16:23:50,995:INFO:           fairlearn: Not installed
2026-02-02 16:23:50,995:INFO:          deepchecks: Not installed
2026-02-02 16:23:50,995:INFO:             xgboost: 3.1.2
2026-02-02 16:23:50,995:INFO:            catboost: 1.2.8
2026-02-02 16:23:50,995:INFO:              kmodes: Not installed
2026-02-02 16:23:50,995:INFO:             mlxtend: Not installed
2026-02-02 16:23:50,995:INFO:       statsforecast: Not installed
2026-02-02 16:23:50,996:INFO:        tune_sklearn: Not installed
2026-02-02 16:23:50,996:INFO:                 ray: Not installed
2026-02-02 16:23:50,996:INFO:            hyperopt: Not installed
2026-02-02 16:23:50,996:INFO:              optuna: 4.6.0
2026-02-02 16:23:50,996:INFO:               skopt: Not installed
2026-02-02 16:23:50,996:INFO:              mlflow: Not installed
2026-02-02 16:23:50,996:INFO:              gradio: Not installed
2026-02-02 16:23:50,996:INFO:             fastapi: 0.123.10
2026-02-02 16:23:50,996:INFO:             uvicorn: 0.38.0
2026-02-02 16:23:50,996:INFO:              m2cgen: Not installed
2026-02-02 16:23:50,996:INFO:           evidently: Not installed
2026-02-02 16:23:50,996:INFO:               fugue: Not installed
2026-02-02 16:23:50,996:INFO:           streamlit: Not installed
2026-02-02 16:23:50,996:INFO:             prophet: Not installed
2026-02-02 16:23:50,996:INFO:None
2026-02-02 16:23:50,996:INFO:Set up data.
2026-02-02 16:23:51,028:INFO:Set up folding strategy.
2026-02-02 16:23:51,029:INFO:Set up train/test split.
2026-02-02 16:23:51,116:INFO:Set up index.
2026-02-02 16:23:51,118:INFO:Assigning column types.
2026-02-02 16:23:51,133:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-02 16:23:51,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:23:51,205:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:23:51,270:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:51,273:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:54,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:23:54,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:23:54,563:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:54,571:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:54,571:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-02 16:23:54,636:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:23:54,686:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:54,694:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:54,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:23:54,804:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:54,808:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:54,809:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-02 16:23:54,919:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:54,923:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:55,045:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:55,049:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:55,064:INFO:Preparing preprocessing pipeline...
2026-02-02 16:23:55,074:INFO:Set up label encoding.
2026-02-02 16:23:55,075:INFO:Set up simple imputation.
2026-02-02 16:23:55,084:INFO:Set up encoding of categorical features.
2026-02-02 16:23:55,282:INFO:Finished creating preprocessing pipeline.
2026-02-02 16:23:55,296:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pm10', 'pm25', 'so2', 'co', 'o3',
                                             'no2', 'max',
                                             'is_holiday_nasional',
                                             'is_weekend', 'temp_max',
                                             'temp_min', '...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['tanggal'],
                                    transformer=TargetEncoder(cols=['tanggal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2026-02-02 16:23:55,296:INFO:Creating final display dataframe.
2026-02-02 16:23:55,900:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               8225
1                        Target                                           kategori
2                   Target type                                         Multiclass
3                Target mapping  BAIK: 0, SANGAT TIDAK SEHAT: 1, SEDANG: 2, TID...
4           Original data shape                                         (5853, 39)
5        Transformed data shape                                         (5853, 54)
6   Transformed train set shape                                         (4097, 54)
7    Transformed test set shape                                         (1756, 54)
8              Numeric features                                                 34
9          Categorical features                                                  4
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               137a
2026-02-02 16:23:56,010:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:56,014:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:56,139:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:23:56,143:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:23:56,145:INFO:setup() successfully completed in 5.36s...............
2026-02-02 16:23:56,145:INFO:Initializing compare_models()
2026-02-02 16:23:56,145:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-02 16:23:56,145:INFO:Checking exceptions
2026-02-02 16:23:56,157:INFO:Preparing display monitor
2026-02-02 16:23:56,167:INFO:Initializing Logistic Regression
2026-02-02 16:23:56,167:INFO:Total runtime is 0.0 minutes
2026-02-02 16:23:56,168:INFO:SubProcess create_model() called ==================================
2026-02-02 16:23:56,168:INFO:Initializing create_model()
2026-02-02 16:23:56,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:23:56,168:INFO:Checking exceptions
2026-02-02 16:23:56,168:INFO:Importing libraries
2026-02-02 16:23:56,168:INFO:Copying training dataset
2026-02-02 16:23:56,194:INFO:Defining folds
2026-02-02 16:23:56,194:INFO:Declaring metric variables
2026-02-02 16:23:56,194:INFO:Importing untrained model
2026-02-02 16:23:56,195:INFO:Logistic Regression Imported successfully
2026-02-02 16:23:56,196:INFO:Starting cross validation
2026-02-02 16:23:56,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:23:56,218:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:03,222:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,256:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,262:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,269:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,271:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,277:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,293:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,298:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:03,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,350:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,368:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,375:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,375:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,375:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,375:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,375:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,376:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,376:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,376:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,378:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,379:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,379:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,379:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,381:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,381:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,381:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,382:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,382:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,384:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,384:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,384:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,384:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:03,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,386:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,387:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,388:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,388:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:03,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:04,030:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:24:04,035:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:04,035:INFO:Initializing create_model()
2026-02-02 16:24:04,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:04,036:INFO:Checking exceptions
2026-02-02 16:24:04,036:INFO:Importing libraries
2026-02-02 16:24:04,036:INFO:Copying training dataset
2026-02-02 16:24:04,051:INFO:Defining folds
2026-02-02 16:24:04,051:INFO:Declaring metric variables
2026-02-02 16:24:04,051:INFO:Importing untrained model
2026-02-02 16:24:04,052:INFO:Logistic Regression Imported successfully
2026-02-02 16:24:04,052:INFO:Starting cross validation
2026-02-02 16:24:04,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:04,061:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:10,584:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,718:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,720:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,747:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,766:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,768:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,770:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,771:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,776:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,778:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,779:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,780:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,785:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,789:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,790:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,794:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,795:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,799:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,802:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,802:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,806:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,807:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,809:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,812:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,813:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,815:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,820:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,823:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,823:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2026-02-02 16:24:10,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,830:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,832:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,833:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,835:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,836:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,838:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,839:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,840:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,842:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,844:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,847:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,849:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,852:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,855:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,874:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:10,878:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,881:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,884:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,887:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:10,890:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:10,892:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:11,170:ERROR:create_model() for lr raised an exception or returned all 0.0:
2026-02-02 16:24:11,172:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:11,172:INFO:Initializing K Neighbors Classifier
2026-02-02 16:24:11,173:INFO:Total runtime is 0.25009655157725014 minutes
2026-02-02 16:24:11,173:INFO:SubProcess create_model() called ==================================
2026-02-02 16:24:11,173:INFO:Initializing create_model()
2026-02-02 16:24:11,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:11,173:INFO:Checking exceptions
2026-02-02 16:24:11,173:INFO:Importing libraries
2026-02-02 16:24:11,173:INFO:Copying training dataset
2026-02-02 16:24:11,186:INFO:Defining folds
2026-02-02 16:24:11,187:INFO:Declaring metric variables
2026-02-02 16:24:11,187:INFO:Importing untrained model
2026-02-02 16:24:11,187:INFO:K Neighbors Classifier Imported successfully
2026-02-02 16:24:11,187:INFO:Starting cross validation
2026-02-02 16:24:11,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:11,197:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:16,328:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,328:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,332:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,335:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,335:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,338:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,338:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,339:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,340:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,340:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,342:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,347:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,348:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,350:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,351:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,351:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,354:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,356:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,359:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,363:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,369:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,374:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,378:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,379:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,381:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:16,383:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,384:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,386:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,386:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,387:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,388:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,390:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,391:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,391:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,392:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,393:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,396:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,396:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:16,397:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,400:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:16,828:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:24:16,830:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:16,830:INFO:Initializing create_model()
2026-02-02 16:24:16,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:16,830:INFO:Checking exceptions
2026-02-02 16:24:16,830:INFO:Importing libraries
2026-02-02 16:24:16,830:INFO:Copying training dataset
2026-02-02 16:24:16,845:INFO:Defining folds
2026-02-02 16:24:16,845:INFO:Declaring metric variables
2026-02-02 16:24:16,845:INFO:Importing untrained model
2026-02-02 16:24:16,845:INFO:K Neighbors Classifier Imported successfully
2026-02-02 16:24:16,846:INFO:Starting cross validation
2026-02-02 16:24:16,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:16,855:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:21,961:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,967:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,972:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,972:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,975:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,976:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,977:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,978:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,979:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,981:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,981:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,982:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,984:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,985:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,986:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,987:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,989:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,989:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,991:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,991:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,994:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,995:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,995:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,998:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:21,998:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:21,999:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:21,999:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:22,002:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,003:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,003:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,003:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,003:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,004:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:22,005:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,007:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,008:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,008:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,008:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,009:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,010:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,010:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,011:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,011:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,013:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,014:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,014:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,017:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,018:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,021:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,022:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,026:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,027:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:22,032:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,036:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,039:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,042:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,047:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:22,052:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:22,472:ERROR:create_model() for knn raised an exception or returned all 0.0:
2026-02-02 16:24:22,474:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:22,475:INFO:Initializing Naive Bayes
2026-02-02 16:24:22,475:INFO:Total runtime is 0.43846731980641684 minutes
2026-02-02 16:24:22,475:INFO:SubProcess create_model() called ==================================
2026-02-02 16:24:22,475:INFO:Initializing create_model()
2026-02-02 16:24:22,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:22,475:INFO:Checking exceptions
2026-02-02 16:24:22,476:INFO:Importing libraries
2026-02-02 16:24:22,476:INFO:Copying training dataset
2026-02-02 16:24:22,489:INFO:Defining folds
2026-02-02 16:24:22,489:INFO:Declaring metric variables
2026-02-02 16:24:22,489:INFO:Importing untrained model
2026-02-02 16:24:22,489:INFO:Naive Bayes Imported successfully
2026-02-02 16:24:22,489:INFO:Starting cross validation
2026-02-02 16:24:22,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:22,498:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:27,602:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,606:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,606:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,609:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,610:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,613:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,614:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,617:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,619:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,620:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,620:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,622:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,624:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,631:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,633:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,635:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,635:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,637:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,639:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,641:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,643:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,643:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,647:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,648:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,649:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,651:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,653:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,659:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,660:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,663:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,667:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,672:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,680:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,682:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,684:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,685:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,688:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,691:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:27,692:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,696:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,696:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,701:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,705:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,709:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:27,713:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:27,717:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:28,194:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:24:28,195:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:28,196:INFO:Initializing create_model()
2026-02-02 16:24:28,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:28,196:INFO:Checking exceptions
2026-02-02 16:24:28,196:INFO:Importing libraries
2026-02-02 16:24:28,196:INFO:Copying training dataset
2026-02-02 16:24:28,209:INFO:Defining folds
2026-02-02 16:24:28,210:INFO:Declaring metric variables
2026-02-02 16:24:28,210:INFO:Importing untrained model
2026-02-02 16:24:28,210:INFO:Naive Bayes Imported successfully
2026-02-02 16:24:28,210:INFO:Starting cross validation
2026-02-02 16:24:28,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:28,220:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:33,308:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,313:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,316:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,318:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,321:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,323:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,324:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,327:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,327:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,330:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,332:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,336:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,339:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,341:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,344:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,344:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,349:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,352:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,355:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,374:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,380:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,388:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,393:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,396:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,397:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,399:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,400:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,400:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:33,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,404:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,405:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,405:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,410:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,412:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,412:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,413:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,414:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,416:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,416:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,421:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,421:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,423:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:33,424:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,427:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:33,917:ERROR:create_model() for nb raised an exception or returned all 0.0:
2026-02-02 16:24:33,919:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:33,920:INFO:Initializing Decision Tree Classifier
2026-02-02 16:24:33,920:INFO:Total runtime is 0.6292204260826111 minutes
2026-02-02 16:24:33,920:INFO:SubProcess create_model() called ==================================
2026-02-02 16:24:33,920:INFO:Initializing create_model()
2026-02-02 16:24:33,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:33,920:INFO:Checking exceptions
2026-02-02 16:24:33,921:INFO:Importing libraries
2026-02-02 16:24:33,921:INFO:Copying training dataset
2026-02-02 16:24:33,934:INFO:Defining folds
2026-02-02 16:24:33,935:INFO:Declaring metric variables
2026-02-02 16:24:33,935:INFO:Importing untrained model
2026-02-02 16:24:33,935:INFO:Decision Tree Classifier Imported successfully
2026-02-02 16:24:33,935:INFO:Starting cross validation
2026-02-02 16:24:33,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:33,944:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:39,003:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,005:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,007:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,008:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,010:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,011:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,013:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,015:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,016:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,017:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,018:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,019:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,021:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,022:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,022:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,025:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,029:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,032:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,037:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,037:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,041:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,042:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,043:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,046:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,049:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,052:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,055:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,058:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,067:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,073:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,078:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,082:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,087:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,091:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,094:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,095:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,097:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,099:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,101:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,102:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,104:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,110:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,111:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,111:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,112:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,115:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,115:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,115:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,119:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,120:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,120:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,124:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,124:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,126:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:39,129:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:39,629:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:24:39,631:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:39,632:INFO:Initializing create_model()
2026-02-02 16:24:39,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:39,632:INFO:Checking exceptions
2026-02-02 16:24:39,632:INFO:Importing libraries
2026-02-02 16:24:39,632:INFO:Copying training dataset
2026-02-02 16:24:39,646:INFO:Defining folds
2026-02-02 16:24:39,646:INFO:Declaring metric variables
2026-02-02 16:24:39,646:INFO:Importing untrained model
2026-02-02 16:24:39,646:INFO:Decision Tree Classifier Imported successfully
2026-02-02 16:24:39,647:INFO:Starting cross validation
2026-02-02 16:24:39,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:39,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:44,722:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,727:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,730:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,733:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,742:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,746:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,747:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,750:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,751:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,751:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,755:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,755:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,756:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,757:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,760:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,760:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,762:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,763:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,764:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,765:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,766:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,768:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,770:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,770:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,773:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,773:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,775:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,776:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,777:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,778:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,779:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,780:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,781:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,782:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,784:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,785:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,788:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,790:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,792:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,794:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,795:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,799:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,801:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,804:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,804:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:24:44,805:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,809:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,809:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,812:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,815:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,823:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,825:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,828:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,831:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:44,832:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:44,835:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:45,342:ERROR:create_model() for dt raised an exception or returned all 0.0:
2026-02-02 16:24:45,343:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:45,344:INFO:Initializing SVM - Linear Kernel
2026-02-02 16:24:45,344:INFO:Total runtime is 0.8196245869000753 minutes
2026-02-02 16:24:45,344:INFO:SubProcess create_model() called ==================================
2026-02-02 16:24:45,345:INFO:Initializing create_model()
2026-02-02 16:24:45,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:45,345:INFO:Checking exceptions
2026-02-02 16:24:45,345:INFO:Importing libraries
2026-02-02 16:24:45,345:INFO:Copying training dataset
2026-02-02 16:24:45,358:INFO:Defining folds
2026-02-02 16:24:45,358:INFO:Declaring metric variables
2026-02-02 16:24:45,358:INFO:Importing untrained model
2026-02-02 16:24:45,359:INFO:SVM - Linear Kernel Imported successfully
2026-02-02 16:24:45,359:INFO:Starting cross validation
2026-02-02 16:24:45,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:45,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:50,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,758:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,760:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,762:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,765:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,770:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,767:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,774:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,777:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,779:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,781:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,787:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,789:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,799:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,807:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,826:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,830:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,834:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,836:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,841:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,846:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,850:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,855:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,860:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,865:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,960:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,963:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,966:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,968:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,970:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:50,971:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,974:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,975:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,976:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,980:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,983:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,986:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:50,989:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:50,992:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:51,089:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2026-02-02 16:24:51,152:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2026-02-02 16:24:51,194:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:51,197:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:51,200:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:51,202:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:51,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:51,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:51,385:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:24:51,387:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:51,387:INFO:Initializing create_model()
2026-02-02 16:24:51,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:51,388:INFO:Checking exceptions
2026-02-02 16:24:51,388:INFO:Importing libraries
2026-02-02 16:24:51,388:INFO:Copying training dataset
2026-02-02 16:24:51,401:INFO:Defining folds
2026-02-02 16:24:51,401:INFO:Declaring metric variables
2026-02-02 16:24:51,402:INFO:Importing untrained model
2026-02-02 16:24:51,402:INFO:SVM - Linear Kernel Imported successfully
2026-02-02 16:24:51,402:INFO:Starting cross validation
2026-02-02 16:24:51,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:51,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:24:56,606:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,615:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,618:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,626:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,664:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,682:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,687:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,722:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,725:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,730:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,734:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,745:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,800:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,805:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,808:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,810:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,811:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,813:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,823:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,825:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,828:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,831:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,833:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,836:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,895:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:56,898:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,904:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,909:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,911:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,914:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:56,916:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:56,977:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2026-02-02 16:24:57,018:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:24:57,021:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:57,024:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:57,026:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:57,029:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:24:57,031:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:24:57,308:ERROR:create_model() for svm raised an exception or returned all 0.0:
2026-02-02 16:24:57,309:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:24:57,310:INFO:Initializing Ridge Classifier
2026-02-02 16:24:57,310:INFO:Total runtime is 1.0190495252609253 minutes
2026-02-02 16:24:57,310:INFO:SubProcess create_model() called ==================================
2026-02-02 16:24:57,311:INFO:Initializing create_model()
2026-02-02 16:24:57,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:24:57,311:INFO:Checking exceptions
2026-02-02 16:24:57,311:INFO:Importing libraries
2026-02-02 16:24:57,311:INFO:Copying training dataset
2026-02-02 16:24:57,324:INFO:Defining folds
2026-02-02 16:24:57,324:INFO:Declaring metric variables
2026-02-02 16:24:57,324:INFO:Importing untrained model
2026-02-02 16:24:57,325:INFO:Ridge Classifier Imported successfully
2026-02-02 16:24:57,325:INFO:Starting cross validation
2026-02-02 16:24:57,327:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:24:57,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:02,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,410:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,412:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,412:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,413:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,414:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,414:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,420:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,420:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,421:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,424:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,424:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,425:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,425:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,426:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,427:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,428:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,429:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,430:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,432:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,432:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,436:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,437:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,441:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,442:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,445:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,445:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,447:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,449:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,450:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,450:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,454:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,456:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,459:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,459:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:02,460:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,463:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,463:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,464:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,466:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,467:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,470:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,471:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,475:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,480:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:02,486:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:02,974:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:25:02,976:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:02,976:INFO:Initializing create_model()
2026-02-02 16:25:02,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:02,976:INFO:Checking exceptions
2026-02-02 16:25:02,976:INFO:Importing libraries
2026-02-02 16:25:02,977:INFO:Copying training dataset
2026-02-02 16:25:02,989:INFO:Defining folds
2026-02-02 16:25:02,989:INFO:Declaring metric variables
2026-02-02 16:25:02,989:INFO:Importing untrained model
2026-02-02 16:25:02,990:INFO:Ridge Classifier Imported successfully
2026-02-02 16:25:02,990:INFO:Starting cross validation
2026-02-02 16:25:02,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:02,999:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:08,145:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,149:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,151:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,155:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,156:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,158:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,159:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,161:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,162:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,164:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,165:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,166:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,168:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,170:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,189:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,193:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,198:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,199:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,202:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,203:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,203:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,208:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,208:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,209:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,212:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,212:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,213:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,213:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,214:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,216:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,216:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,217:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,217:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,218:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,220:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,220:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,223:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,223:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:08,224:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

metric.capitalize()} is", len(result))

2026-02-02 16:25:08,228:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,228:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,228:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,231:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,233:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,238:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,243:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,248:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:08,251:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:08,714:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2026-02-02 16:25:08,715:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:08,716:INFO:Initializing Random Forest Classifier
2026-02-02 16:25:08,716:INFO:Total runtime is 1.2091535846392314 minutes
2026-02-02 16:25:08,716:INFO:SubProcess create_model() called ==================================
2026-02-02 16:25:08,717:INFO:Initializing create_model()
2026-02-02 16:25:08,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:08,717:INFO:Checking exceptions
2026-02-02 16:25:08,717:INFO:Importing libraries
2026-02-02 16:25:08,717:INFO:Copying training dataset
2026-02-02 16:25:08,731:INFO:Defining folds
2026-02-02 16:25:08,731:INFO:Declaring metric variables
2026-02-02 16:25:08,731:INFO:Importing untrained model
2026-02-02 16:25:08,732:INFO:Random Forest Classifier Imported successfully
2026-02-02 16:25:08,732:INFO:Starting cross validation
2026-02-02 16:25:08,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:08,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:14,619:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,624:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,628:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,631:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,633:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,636:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,637:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,641:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,641:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,643:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,645:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,645:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,647:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,649:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,651:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,652:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,655:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,655:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,658:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,658:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,670:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,681:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,683:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,685:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,687:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,689:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,692:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,697:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,731:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,736:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:14,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,742:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,745:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,746:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,747:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,749:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,750:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:14,754:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:14,757:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:15,145:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:25:15,147:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:15,147:INFO:Initializing create_model()
2026-02-02 16:25:15,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:15,148:INFO:Checking exceptions
2026-02-02 16:25:15,148:INFO:Importing libraries
2026-02-02 16:25:15,148:INFO:Copying training dataset
2026-02-02 16:25:15,168:INFO:Defining folds
2026-02-02 16:25:15,168:INFO:Declaring metric variables
2026-02-02 16:25:15,168:INFO:Importing untrained model
2026-02-02 16:25:15,169:INFO:Random Forest Classifier Imported successfully
2026-02-02 16:25:15,169:INFO:Starting cross validation
2026-02-02 16:25:15,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:15,182:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:21,392:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,397:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,403:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,407:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,407:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,410:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,414:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,415:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,416:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,416:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,423:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,423:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,428:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,433:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,436:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,440:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,443:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,447:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,464:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,469:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,473:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,476:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,476:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,478:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,481:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,482:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,484:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,487:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,490:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,493:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,497:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,500:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,505:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:25:21,510:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,513:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,516:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,518:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,521:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:21,523:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:21,918:ERROR:create_model() for rf raised an exception or returned all 0.0:
2026-02-02 16:25:21,920:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:21,920:INFO:Initializing Quadratic Discriminant Analysis
2026-02-02 16:25:21,920:INFO:Total runtime is 1.4292222420374552 minutes
2026-02-02 16:25:21,921:INFO:SubProcess create_model() called ==================================
2026-02-02 16:25:21,921:INFO:Initializing create_model()
2026-02-02 16:25:21,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:21,921:INFO:Checking exceptions
2026-02-02 16:25:21,921:INFO:Importing libraries
2026-02-02 16:25:21,921:INFO:Copying training dataset
2026-02-02 16:25:21,935:INFO:Defining folds
2026-02-02 16:25:21,935:INFO:Declaring metric variables
2026-02-02 16:25:21,935:INFO:Importing untrained model
2026-02-02 16:25:21,935:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-02 16:25:21,935:INFO:Starting cross validation
2026-02-02 16:25:21,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:21,944:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:27,091:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:27,673:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:25:27,675:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:27,675:INFO:Initializing create_model()
2026-02-02 16:25:27,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:27,675:INFO:Checking exceptions
2026-02-02 16:25:27,675:INFO:Importing libraries
2026-02-02 16:25:27,675:INFO:Copying training dataset
2026-02-02 16:25:27,688:INFO:Defining folds
2026-02-02 16:25:27,688:INFO:Declaring metric variables
2026-02-02 16:25:27,689:INFO:Importing untrained model
2026-02-02 16:25:27,689:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-02 16:25:27,689:INFO:Starting cross validation
2026-02-02 16:25:27,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:27,698:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:32,596:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,694:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,696:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,698:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,716:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,724:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,733:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:32,765:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:25:33,351:ERROR:create_model() for qda raised an exception or returned all 0.0:
2026-02-02 16:25:33,353:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:33,354:INFO:Initializing Ada Boost Classifier
2026-02-02 16:25:33,354:INFO:Total runtime is 1.619791030883789 minutes
2026-02-02 16:25:33,354:INFO:SubProcess create_model() called ==================================
2026-02-02 16:25:33,354:INFO:Initializing create_model()
2026-02-02 16:25:33,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:33,354:INFO:Checking exceptions
2026-02-02 16:25:33,354:INFO:Importing libraries
2026-02-02 16:25:33,355:INFO:Copying training dataset
2026-02-02 16:25:33,368:INFO:Defining folds
2026-02-02 16:25:33,368:INFO:Declaring metric variables
2026-02-02 16:25:33,368:INFO:Importing untrained model
2026-02-02 16:25:33,368:INFO:Ada Boost Classifier Imported successfully
2026-02-02 16:25:33,369:INFO:Starting cross validation
2026-02-02 16:25:33,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:33,378:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:38,458:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,458:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,468:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,468:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,481:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,487:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,487:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,488:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,488:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:38,497:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:39,203:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,206:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,206:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,214:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,214:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,217:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,218:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,219:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,220:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,222:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,222:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,224:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,225:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,227:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,228:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,229:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,232:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,235:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,237:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,238:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,242:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,244:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,245:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,245:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,245:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,246:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,247:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,247:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,248:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,248:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,250:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,250:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,250:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,252:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,253:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,253:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,253:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:39,256:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,256:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,257:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,257:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,258:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,260:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,260:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,261:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,262:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,265:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,267:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:39,270:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:39,704:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:25:39,706:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:39,707:INFO:Initializing create_model()
2026-02-02 16:25:39,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:39,707:INFO:Checking exceptions
2026-02-02 16:25:39,707:INFO:Importing libraries
2026-02-02 16:25:39,707:INFO:Copying training dataset
2026-02-02 16:25:39,720:INFO:Defining folds
2026-02-02 16:25:39,720:INFO:Declaring metric variables
2026-02-02 16:25:39,721:INFO:Importing untrained model
2026-02-02 16:25:39,721:INFO:Ada Boost Classifier Imported successfully
2026-02-02 16:25:39,721:INFO:Starting cross validation
2026-02-02 16:25:39,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:39,731:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:44,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,701:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,716:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,717:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,718:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,731:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,752:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,762:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,782:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:44,807:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:25:45,441:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,444:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,447:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,450:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,455:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,455:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,457:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,460:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,464:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,467:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,470:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,471:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,474:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,475:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,477:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,477:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,479:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,480:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,481:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,485:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,486:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,488:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,489:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,490:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,492:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,493:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,494:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,496:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,498:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,499:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,502:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,502:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,504:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,506:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,507:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,508:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,511:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,513:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,516:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,516:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:25:45,518:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,520:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,521:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,523:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,526:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,530:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,535:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:25:45,541:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:25:45,920:ERROR:create_model() for ada raised an exception or returned all 0.0:
2026-02-02 16:25:45,922:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:45,922:INFO:Initializing Gradient Boosting Classifier
2026-02-02 16:25:45,922:INFO:Total runtime is 1.8292478481928507 minutes
2026-02-02 16:25:45,923:INFO:SubProcess create_model() called ==================================
2026-02-02 16:25:45,923:INFO:Initializing create_model()
2026-02-02 16:25:45,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:45,923:INFO:Checking exceptions
2026-02-02 16:25:45,923:INFO:Importing libraries
2026-02-02 16:25:45,923:INFO:Copying training dataset
2026-02-02 16:25:45,936:INFO:Defining folds
2026-02-02 16:25:45,936:INFO:Declaring metric variables
2026-02-02 16:25:45,936:INFO:Importing untrained model
2026-02-02 16:25:45,937:INFO:Gradient Boosting Classifier Imported successfully
2026-02-02 16:25:45,937:INFO:Starting cross validation
2026-02-02 16:25:45,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:45,946:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:25:59,698:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:25:59,700:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:25:59,700:INFO:Initializing create_model()
2026-02-02 16:25:59,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:25:59,701:INFO:Checking exceptions
2026-02-02 16:25:59,701:INFO:Importing libraries
2026-02-02 16:25:59,701:INFO:Copying training dataset
2026-02-02 16:25:59,714:INFO:Defining folds
2026-02-02 16:25:59,714:INFO:Declaring metric variables
2026-02-02 16:25:59,714:INFO:Importing untrained model
2026-02-02 16:25:59,715:INFO:Gradient Boosting Classifier Imported successfully
2026-02-02 16:25:59,715:INFO:Starting cross validation
2026-02-02 16:25:59,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:25:59,723:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:13,420:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2026-02-02 16:26:13,422:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:13,422:INFO:Initializing Linear Discriminant Analysis
2026-02-02 16:26:13,423:INFO:Total runtime is 2.2876035014788307 minutes
2026-02-02 16:26:13,423:INFO:SubProcess create_model() called ==================================
2026-02-02 16:26:13,423:INFO:Initializing create_model()
2026-02-02 16:26:13,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:13,423:INFO:Checking exceptions
2026-02-02 16:26:13,423:INFO:Importing libraries
2026-02-02 16:26:13,423:INFO:Copying training dataset
2026-02-02 16:26:13,437:INFO:Defining folds
2026-02-02 16:26:13,437:INFO:Declaring metric variables
2026-02-02 16:26:13,437:INFO:Importing untrained model
2026-02-02 16:26:13,437:INFO:Linear Discriminant Analysis Imported successfully
2026-02-02 16:26:13,437:INFO:Starting cross validation
2026-02-02 16:26:13,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:13,446:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:18,690:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,693:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,694:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,694:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,697:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,697:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,698:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,700:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,700:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,700:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,703:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,703:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,703:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,705:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,706:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,706:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,706:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,708:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,708:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,708:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,711:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,711:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,712:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,712:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,715:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,716:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,717:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,719:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,721:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,721:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,722:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,724:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,726:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,728:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,729:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,730:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,730:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,731:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,732:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,733:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,734:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,735:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,735:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,736:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:18,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,747:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,747:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,748:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,750:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,752:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,757:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,761:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:18,765:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:18,770:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:19,266:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:26:19,267:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:19,268:INFO:Initializing create_model()
2026-02-02 16:26:19,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:19,268:INFO:Checking exceptions
2026-02-02 16:26:19,268:INFO:Importing libraries
2026-02-02 16:26:19,268:INFO:Copying training dataset
2026-02-02 16:26:19,281:INFO:Defining folds
2026-02-02 16:26:19,281:INFO:Declaring metric variables
2026-02-02 16:26:19,282:INFO:Importing untrained model
2026-02-02 16:26:19,282:INFO:Linear Discriminant Analysis Imported successfully
2026-02-02 16:26:19,282:INFO:Starting cross validation
2026-02-02 16:26:19,284:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:19,291:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:24,496:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,502:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,503:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,506:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,507:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,509:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,511:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,512:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,515:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,516:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,517:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,519:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,520:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,520:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,524:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,525:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,529:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,533:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,537:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,541:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,545:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,546:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,548:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,550:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,553:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,555:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,558:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,559:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,560:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,566:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,567:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,570:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,575:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,577:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,581:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,582:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,586:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,587:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,591:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,591:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,592:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:26:24,594:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,596:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,596:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,597:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,599:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,600:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,600:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,602:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,603:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,605:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:24,610:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:24,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:25,067:ERROR:create_model() for lda raised an exception or returned all 0.0:
2026-02-02 16:26:25,069:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:25,070:INFO:Initializing Extra Trees Classifier
2026-02-02 16:26:25,070:INFO:Total runtime is 2.4817166090011593 minutes
2026-02-02 16:26:25,070:INFO:SubProcess create_model() called ==================================
2026-02-02 16:26:25,071:INFO:Initializing create_model()
2026-02-02 16:26:25,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:25,071:INFO:Checking exceptions
2026-02-02 16:26:25,071:INFO:Importing libraries
2026-02-02 16:26:25,071:INFO:Copying training dataset
2026-02-02 16:26:25,085:INFO:Defining folds
2026-02-02 16:26:25,085:INFO:Declaring metric variables
2026-02-02 16:26:25,085:INFO:Importing untrained model
2026-02-02 16:26:25,086:INFO:Extra Trees Classifier Imported successfully
2026-02-02 16:26:25,086:INFO:Starting cross validation
2026-02-02 16:26:25,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:25,095:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:30,703:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,708:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,713:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,728:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,729:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,735:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,748:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,748:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,752:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,756:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,762:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,790:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,792:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,796:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,796:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,797:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,799:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,801:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,802:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,802:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,805:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,805:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,805:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,809:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,809:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,810:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,813:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,816:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,816:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,820:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,826:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,828:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,831:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,836:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,845:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,850:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,855:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,858:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,861:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,863:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,867:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,922:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:30,925:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,928:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,930:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,933:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:30,936:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:30,939:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:31,297:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:26:31,299:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:31,300:INFO:Initializing create_model()
2026-02-02 16:26:31,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:31,300:INFO:Checking exceptions
2026-02-02 16:26:31,300:INFO:Importing libraries
2026-02-02 16:26:31,300:INFO:Copying training dataset
2026-02-02 16:26:31,314:INFO:Defining folds
2026-02-02 16:26:31,314:INFO:Declaring metric variables
2026-02-02 16:26:31,315:INFO:Importing untrained model
2026-02-02 16:26:31,315:INFO:Extra Trees Classifier Imported successfully
2026-02-02 16:26:31,315:INFO:Starting cross validation
2026-02-02 16:26:31,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:31,327:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:37,060:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,060:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,060:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,060:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,065:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,065:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,065:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,066:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,069:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,069:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,069:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,070:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,070:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,071:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,072:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,074:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,074:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,074:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,075:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,075:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,078:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,078:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,079:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,079:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,079:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,080:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,081:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,082:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,082:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,083:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,083:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,086:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,086:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,086:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,087:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,087:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,087:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,089:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,094:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,126:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,127:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,131:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,133:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,136:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,136:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,139:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,140:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:37,140:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,142:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,144:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,145:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,145:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,146:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,148:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,148:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,151:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,152:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,154:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,157:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:37,159:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:37,596:ERROR:create_model() for et raised an exception or returned all 0.0:
2026-02-02 16:26:37,599:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:37,599:INFO:Initializing Extreme Gradient Boosting
2026-02-02 16:26:37,600:INFO:Total runtime is 2.690543413162231 minutes
2026-02-02 16:26:37,600:INFO:SubProcess create_model() called ==================================
2026-02-02 16:26:37,600:INFO:Initializing create_model()
2026-02-02 16:26:37,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:37,601:INFO:Checking exceptions
2026-02-02 16:26:37,601:INFO:Importing libraries
2026-02-02 16:26:37,601:INFO:Copying training dataset
2026-02-02 16:26:37,618:INFO:Defining folds
2026-02-02 16:26:37,618:INFO:Declaring metric variables
2026-02-02 16:26:37,618:INFO:Importing untrained model
2026-02-02 16:26:37,619:INFO:Extreme Gradient Boosting Imported successfully
2026-02-02 16:26:37,619:INFO:Starting cross validation
2026-02-02 16:26:37,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:37,629:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:44,577:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,580:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,581:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,582:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,585:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,586:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,587:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,588:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,590:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,591:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,591:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,592:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,592:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,594:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,595:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,596:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,597:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,597:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,599:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,599:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,600:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,601:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,601:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,603:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,603:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,604:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,605:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,605:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,605:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,607:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,608:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,609:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,609:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,610:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,610:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,614:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,614:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,615:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:44,618:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,619:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,620:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,624:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

apitalize()} is", len(result))

2026-02-02 16:26:44,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:44,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:44,633:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:45,379:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:26:45,381:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:45,382:INFO:Initializing create_model()
2026-02-02 16:26:45,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:45,382:INFO:Checking exceptions
2026-02-02 16:26:45,382:INFO:Importing libraries
2026-02-02 16:26:45,382:INFO:Copying training dataset
2026-02-02 16:26:45,395:INFO:Defining folds
2026-02-02 16:26:45,395:INFO:Declaring metric variables
2026-02-02 16:26:45,395:INFO:Importing untrained model
2026-02-02 16:26:45,396:INFO:Extreme Gradient Boosting Imported successfully
2026-02-02 16:26:45,396:INFO:Starting cross validation
2026-02-02 16:26:45,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:45,405:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:26:51,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,423:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,427:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,431:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,435:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,438:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,440:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,444:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,445:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,450:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,454:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,457:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,461:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,463:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,465:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,468:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,470:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,475:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,476:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,480:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,480:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,481:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,483:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,485:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,488:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,489:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,490:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,492:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,493:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,493:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,496:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,496:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,499:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,502:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,545:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,549:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,553:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,557:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,562:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,625:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:26:51,629:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,632:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,636:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:51,639:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:26:51,641:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:26:52,367:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2026-02-02 16:26:52,369:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:26:52,370:INFO:Initializing Light Gradient Boosting Machine
2026-02-02 16:26:52,370:INFO:Total runtime is 2.936723498503367 minutes
2026-02-02 16:26:52,370:INFO:SubProcess create_model() called ==================================
2026-02-02 16:26:52,371:INFO:Initializing create_model()
2026-02-02 16:26:52,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:26:52,371:INFO:Checking exceptions
2026-02-02 16:26:52,371:INFO:Importing libraries
2026-02-02 16:26:52,371:INFO:Copying training dataset
2026-02-02 16:26:52,385:INFO:Defining folds
2026-02-02 16:26:52,385:INFO:Declaring metric variables
2026-02-02 16:26:52,385:INFO:Importing untrained model
2026-02-02 16:26:52,386:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-02 16:26:52,386:INFO:Starting cross validation
2026-02-02 16:26:52,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:26:52,395:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:27:03,241:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:03,248:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,253:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:03,257:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,270:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,458:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:03,467:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,472:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:03,480:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,489:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,681:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:03,687:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,691:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:03,695:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,699:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:03,702:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:03,708:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:04,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:04,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:04,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:04,686:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:04,691:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:04,699:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:04,705:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:05,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:05,211:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:05,215:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:05,220:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:05,227:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:05,231:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:05,235:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:05,590:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:27:05,592:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:27:05,593:INFO:Initializing create_model()
2026-02-02 16:27:05,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:27:05,593:INFO:Checking exceptions
2026-02-02 16:27:05,593:INFO:Importing libraries
2026-02-02 16:27:05,593:INFO:Copying training dataset
2026-02-02 16:27:05,606:INFO:Defining folds
2026-02-02 16:27:05,606:INFO:Declaring metric variables
2026-02-02 16:27:05,607:INFO:Importing untrained model
2026-02-02 16:27:05,607:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-02 16:27:05,608:INFO:Starting cross validation
2026-02-02 16:27:05,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:27:05,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:27:15,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:15,639:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:15,643:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:15,647:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:15,652:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:15,655:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:15,659:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:16,396:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,401:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,407:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,412:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,423:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,606:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:16,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,616:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,620:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,626:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:16,630:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:16,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:17,029:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2026-02-02 16:27:17,030:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:27:17,031:INFO:Initializing CatBoost Classifier
2026-02-02 16:27:17,031:INFO:Total runtime is 3.347736569245656 minutes
2026-02-02 16:27:17,031:INFO:SubProcess create_model() called ==================================
2026-02-02 16:27:17,032:INFO:Initializing create_model()
2026-02-02 16:27:17,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:27:17,032:INFO:Checking exceptions
2026-02-02 16:27:17,032:INFO:Importing libraries
2026-02-02 16:27:17,032:INFO:Copying training dataset
2026-02-02 16:27:17,045:INFO:Defining folds
2026-02-02 16:27:17,045:INFO:Declaring metric variables
2026-02-02 16:27:17,045:INFO:Importing untrained model
2026-02-02 16:27:17,046:INFO:CatBoost Classifier Imported successfully
2026-02-02 16:27:17,046:INFO:Starting cross validation
2026-02-02 16:27:17,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:27:17,055:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:27:30,970:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:30,974:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:30,977:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:30,978:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:30,981:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:30,984:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:30,986:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:31,000:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2026-02-02 16:27:31,001:INFO:Calculating mean and std
2026-02-02 16:27:31,001:INFO:Creating metrics dataframe
2026-02-02 16:27:31,003:INFO:Uploading results into container
2026-02-02 16:27:31,004:INFO:Uploading model into container now
2026-02-02 16:27:31,005:INFO:_master_model_container: 1
2026-02-02 16:27:31,005:INFO:_display_container: 2
2026-02-02 16:27:31,005:INFO:<catboost.core.CatBoostClassifier object at 0x0000020A9BD30350>
2026-02-02 16:27:31,005:INFO:create_model() successfully completed......................................
2026-02-02 16:27:31,122:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000020A9BD30350> raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:27:31,122:WARNING:Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2026-02-02 16:27:31,123:INFO:Initializing create_model()
2026-02-02 16:27:31,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:27:31,123:INFO:Checking exceptions
2026-02-02 16:27:31,123:INFO:Importing libraries
2026-02-02 16:27:31,123:INFO:Copying training dataset
2026-02-02 16:27:31,136:INFO:Defining folds
2026-02-02 16:27:31,136:INFO:Declaring metric variables
2026-02-02 16:27:31,136:INFO:Importing untrained model
2026-02-02 16:27:31,137:INFO:CatBoost Classifier Imported successfully
2026-02-02 16:27:31,137:INFO:Starting cross validation
2026-02-02 16:27:31,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:27:31,144:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:27:52,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:52,197:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:52,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:52,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:52,209:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:52,213:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:52,216:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:55,771:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:55,777:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:55,781:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:55,784:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:55,789:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:55,793:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:55,796:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:59,267:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:27:59,273:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:59,278:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:59,281:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:59,285:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:27:59,289:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:27:59,293:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:05,600:ERROR:create_model() for <catboost.core.CatBoostClassifier object at 0x0000020A9BD30350> raised an exception or returned all 0.0:
2026-02-02 16:28:05,602:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:28:05,602:INFO:Initializing Dummy Classifier
2026-02-02 16:28:05,602:INFO:Total runtime is 4.157259102662405 minutes
2026-02-02 16:28:05,603:INFO:SubProcess create_model() called ==================================
2026-02-02 16:28:05,603:INFO:Initializing create_model()
2026-02-02 16:28:05,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:28:05,603:INFO:Checking exceptions
2026-02-02 16:28:05,603:INFO:Importing libraries
2026-02-02 16:28:05,603:INFO:Copying training dataset
2026-02-02 16:28:05,617:INFO:Defining folds
2026-02-02 16:28:05,617:INFO:Declaring metric variables
2026-02-02 16:28:05,618:INFO:Importing untrained model
2026-02-02 16:28:05,618:INFO:Dummy Classifier Imported successfully
2026-02-02 16:28:05,618:INFO:Starting cross validation
2026-02-02 16:28:05,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:28:05,627:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:28:10,927:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:10,932:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,935:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,938:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,941:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,946:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,950:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,953:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:10,959:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,962:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:10,964:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,968:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,968:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,973:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,973:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,975:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,977:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,978:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,982:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,986:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,989:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:10,991:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,993:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:10,996:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:10,999:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,002:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,005:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,010:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,014:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:11,018:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,020:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:11,021:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,023:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,026:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,026:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,028:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,029:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,031:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,032:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,035:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,040:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,045:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:11,045:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:11,049:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,050:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,054:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,054:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,058:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,058:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,061:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,062:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,064:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,065:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:11,066:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,070:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:11,482:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2026-02-02 16:28:11,484:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:28:11,484:INFO:Initializing create_model()
2026-02-02 16:28:11,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9B5E5550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF04D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:28:11,484:INFO:Checking exceptions
2026-02-02 16:28:11,484:INFO:Importing libraries
2026-02-02 16:28:11,484:INFO:Copying training dataset
2026-02-02 16:28:11,498:INFO:Defining folds
2026-02-02 16:28:11,498:INFO:Declaring metric variables
2026-02-02 16:28:11,498:INFO:Importing untrained model
2026-02-02 16:28:11,498:INFO:Dummy Classifier Imported successfully
2026-02-02 16:28:11,499:INFO:Starting cross validation
2026-02-02 16:28:11,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:28:11,508:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2026-02-02 16:28:16,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,639:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,643:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,647:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,652:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,653:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,655:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,658:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,662:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,665:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,670:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,670:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,681:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,681:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,682:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,683:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,684:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,685:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,688:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2026-02-02 16:28:16,688:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,688:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,691:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,692:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,693:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,696:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,697:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,699:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,700:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,702:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,702:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,705:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,706:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,706:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,709:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,709:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,709:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'TIDAK SEHAT') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:28:16,713:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:16,714:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:28:17,217:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2026-02-02 16:28:17,218:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 225, in _encode
    return _map_to_integer(values, uniques)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in _map_to_integer
    return np.array([table[v] for v in values])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 165, in <listcomp>
    return np.array([table[v] for v in values])
                     ~~~~~^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 159, in __missing__
    raise KeyError(key)
KeyError: 'SANGAT TIDAK SEHAT'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 463, in _process_worker
    r = call_item()
        ^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\externals\loky\process_executor.py", line 291, in __call__
    return self.fn(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 140, in fit_and_score
    return wrapper(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 138, in wrapper
    return _fit_and_score(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 917, in _fit_and_score
    test_scores = _score(
                  ^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 154, in wrapper
    args[1], y_transformed = args[0]._memory_full_transform(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 111, in _full_transform
    X, y = pipeline._memory_transform(transformer, X, y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_label.py", line 137, in transform
    return _encode(y, uniques=self.classes_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_encode.py", line 227, in _encode
    raise ValueError(f"y contains previously unseen labels: {str(e)}")
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
ValueError: y contains previously unseen labels: 'SANGAT TIDAK SEHAT'

2026-02-02 16:28:17,220:INFO:_master_model_container: 1
2026-02-02 16:28:17,220:INFO:_display_container: 2
2026-02-02 16:28:17,221:INFO:[]
2026-02-02 16:28:17,221:INFO:compare_models() successfully completed......................................
2026-02-02 16:28:17,229:INFO:Initializing save_model()
2026-02-02 16:28:17,229:INFO:save_model(model=[], model_name=models\dataset_merged_classification_auto, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pm10', 'pm25', 'so2', 'co', 'o3',
                                             'no2', 'max',
                                             'is_holiday_nasional',
                                             'is_weekend', 'temp_max',
                                             'temp_min', '...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['tanggal'],
                                    transformer=TargetEncoder(cols=['tanggal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-02-02 16:28:17,229:INFO:Adding model into prep_pipe
2026-02-02 16:28:17,240:INFO:models\dataset_merged_classification_auto.pkl saved in current working directory
2026-02-02 16:28:17,248:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pm10', 'pm25', 'so2', 'co', 'o3',
                                             'no2', 'max',
                                             'is_holiday_nasional',
                                             'is_weekend', 'temp_max',
                                             'temp_min', 'temp_mean',
                                             'precipitation_sum',
                                             'precipit...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['tanggal'],
                                    transformer=TargetEncoder(cols=['tanggal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model', [])],
         verbose=False)
2026-02-02 16:28:17,248:INFO:save_model() successfully completed......................................
2026-02-02 16:47:26,837:INFO:PyCaret ClassificationExperiment
2026-02-02 16:47:26,837:INFO:Logging name: clf-default-name
2026-02-02 16:47:26,837:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-02 16:47:26,837:INFO:version 3.3.2
2026-02-02 16:47:26,837:INFO:Initializing setup()
2026-02-02 16:47:26,837:INFO:self.USI: 7abe
2026-02-02 16:47:26,837:INFO:self._variable_keys: {'y', 'data', 'X_test', 'gpu_n_jobs_param', 'y_test', 'n_jobs_param', 'fix_imbalance', 'memory', 'X_train', 'fold_generator', '_available_plots', 'seed', 'is_multiclass', 'USI', 'idx', 'fold_shuffle_param', 'log_plots_param', 'fold_groups_param', 'target_param', 'X', 'exp_name_log', 'pipeline', 'gpu_param', 'exp_id', 'y_train', '_ml_usecase', 'logging_param', 'html_param'}
2026-02-02 16:47:26,837:INFO:Checking environment
2026-02-02 16:47:26,837:INFO:python_version: 3.11.9
2026-02-02 16:47:26,837:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-02 16:47:26,838:INFO:machine: AMD64
2026-02-02 16:47:26,838:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-02 16:47:26,838:INFO:Memory: svmem(total=16866873344, available=4196401152, percent=75.1, used=12670472192, free=4196401152)
2026-02-02 16:47:26,838:INFO:Physical Core: 8
2026-02-02 16:47:26,838:INFO:Logical Core: 16
2026-02-02 16:47:26,838:INFO:Checking libraries
2026-02-02 16:47:26,838:INFO:System:
2026-02-02 16:47:26,838:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-02 16:47:26,838:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-02 16:47:26,838:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-02 16:47:26,838:INFO:PyCaret required dependencies:
2026-02-02 16:47:26,839:INFO:                 pip: 24.0
2026-02-02 16:47:26,839:INFO:          setuptools: 80.9.0
2026-02-02 16:47:26,839:INFO:             pycaret: 3.3.2
2026-02-02 16:47:26,839:INFO:             IPython: 9.8.0
2026-02-02 16:47:26,839:INFO:          ipywidgets: 8.1.8
2026-02-02 16:47:26,839:INFO:                tqdm: 4.67.1
2026-02-02 16:47:26,839:INFO:               numpy: 1.26.4
2026-02-02 16:47:26,839:INFO:              pandas: 2.1.4
2026-02-02 16:47:26,839:INFO:              jinja2: 3.1.6
2026-02-02 16:47:26,839:INFO:               scipy: 1.11.4
2026-02-02 16:47:26,839:INFO:              joblib: 1.3.2
2026-02-02 16:47:26,839:INFO:             sklearn: 1.4.2
2026-02-02 16:47:26,840:INFO:                pyod: 2.0.6
2026-02-02 16:47:26,840:INFO:            imblearn: 0.14.1
2026-02-02 16:47:26,840:INFO:   category_encoders: 2.7.0
2026-02-02 16:47:26,840:INFO:            lightgbm: 4.6.0
2026-02-02 16:47:26,840:INFO:               numba: 0.63.1
2026-02-02 16:47:26,840:INFO:            requests: 2.32.5
2026-02-02 16:47:26,840:INFO:          matplotlib: 3.7.5
2026-02-02 16:47:26,840:INFO:          scikitplot: 0.3.7
2026-02-02 16:47:26,840:INFO:         yellowbrick: 1.5
2026-02-02 16:47:26,840:INFO:              plotly: 6.5.0
2026-02-02 16:47:26,840:INFO:    plotly-resampler: Not installed
2026-02-02 16:47:26,840:INFO:             kaleido: 1.2.0
2026-02-02 16:47:26,840:INFO:           schemdraw: 0.15
2026-02-02 16:47:26,840:INFO:         statsmodels: 0.14.6
2026-02-02 16:47:26,840:INFO:              sktime: 0.26.0
2026-02-02 16:47:26,841:INFO:               tbats: 1.1.3
2026-02-02 16:47:26,841:INFO:            pmdarima: 2.0.4
2026-02-02 16:47:26,841:INFO:              psutil: 7.1.3
2026-02-02 16:47:26,841:INFO:          markupsafe: 3.0.3
2026-02-02 16:47:26,841:INFO:             pickle5: Not installed
2026-02-02 16:47:26,841:INFO:         cloudpickle: 3.1.2
2026-02-02 16:47:26,841:INFO:         deprecation: 2.1.0
2026-02-02 16:47:26,841:INFO:              xxhash: 3.6.0
2026-02-02 16:47:26,841:INFO:           wurlitzer: Not installed
2026-02-02 16:47:26,841:INFO:PyCaret optional dependencies:
2026-02-02 16:47:26,842:INFO:                shap: Not installed
2026-02-02 16:47:26,842:INFO:           interpret: Not installed
2026-02-02 16:47:26,842:INFO:                umap: Not installed
2026-02-02 16:47:26,842:INFO:     ydata_profiling: Not installed
2026-02-02 16:47:26,842:INFO:  explainerdashboard: Not installed
2026-02-02 16:47:26,842:INFO:             autoviz: Not installed
2026-02-02 16:47:26,842:INFO:           fairlearn: Not installed
2026-02-02 16:47:26,842:INFO:          deepchecks: Not installed
2026-02-02 16:47:26,842:INFO:             xgboost: 3.1.2
2026-02-02 16:47:26,842:INFO:            catboost: 1.2.8
2026-02-02 16:47:26,842:INFO:              kmodes: Not installed
2026-02-02 16:47:26,842:INFO:             mlxtend: Not installed
2026-02-02 16:47:26,843:INFO:       statsforecast: Not installed
2026-02-02 16:47:26,843:INFO:        tune_sklearn: Not installed
2026-02-02 16:47:26,843:INFO:                 ray: Not installed
2026-02-02 16:47:26,843:INFO:            hyperopt: Not installed
2026-02-02 16:47:26,843:INFO:              optuna: 4.6.0
2026-02-02 16:47:26,843:INFO:               skopt: Not installed
2026-02-02 16:47:26,843:INFO:              mlflow: Not installed
2026-02-02 16:47:26,843:INFO:              gradio: Not installed
2026-02-02 16:47:26,843:INFO:             fastapi: 0.123.10
2026-02-02 16:47:26,843:INFO:             uvicorn: 0.38.0
2026-02-02 16:47:26,843:INFO:              m2cgen: Not installed
2026-02-02 16:47:26,843:INFO:           evidently: Not installed
2026-02-02 16:47:26,843:INFO:               fugue: Not installed
2026-02-02 16:47:26,843:INFO:           streamlit: Not installed
2026-02-02 16:47:26,843:INFO:             prophet: Not installed
2026-02-02 16:47:26,843:INFO:None
2026-02-02 16:47:26,843:INFO:Set up data.
2026-02-02 16:47:26,851:INFO:Set up folding strategy.
2026-02-02 16:47:26,851:INFO:Set up train/test split.
2026-02-02 16:47:26,857:INFO:Set up index.
2026-02-02 16:47:26,857:INFO:Assigning column types.
2026-02-02 16:47:26,861:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-02 16:47:26,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:47:26,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:47:26,971:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:26,977:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:47:27,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:47:27,081:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,085:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,086:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-02 16:47:27,153:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:47:27,192:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,196:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-02 16:47:27,322:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,325:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,326:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-02 16:47:27,439:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,445:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,558:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,562:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:27,563:INFO:Preparing preprocessing pipeline...
2026-02-02 16:47:27,565:INFO:Set up label encoding.
2026-02-02 16:47:27,565:INFO:Set up simple imputation.
2026-02-02 16:47:27,567:INFO:Set up encoding of categorical features.
2026-02-02 16:47:27,624:INFO:Finished creating preprocessing pipeline.
2026-02-02 16:47:27,630:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'sound_db',
                                             'weight_g', 'size_cm3'],
                                    transformer=SimpleImput...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['color_category'],
                                    transformer=OneHotEncoder(cols=['color_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2026-02-02 16:47:27,630:INFO:Creating final display dataframe.
2026-02-02 16:47:27,834:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               7258
1                        Target                                           ripeness
2                   Target type                                         Multiclass
3                Target mapping  breaking: 0, firm-ripe: 1, hard: 2, pre-condit...
4           Original data shape                                           (250, 9)
5        Transformed data shape                                          (250, 12)
6   Transformed train set shape                                          (175, 12)
7    Transformed test set shape                                           (75, 12)
8              Numeric features                                                  7
9          Categorical features                                                  1
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               7abe
2026-02-02 16:47:27,936:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:27,940:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:28,042:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:47:28,046:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:47:28,049:INFO:setup() successfully completed in 1.22s...............
2026-02-02 16:47:28,049:INFO:Initializing compare_models()
2026-02-02 16:47:28,049:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-02-02 16:47:28,049:INFO:Checking exceptions
2026-02-02 16:47:28,053:INFO:Preparing display monitor
2026-02-02 16:47:28,056:INFO:Initializing Logistic Regression
2026-02-02 16:47:28,057:INFO:Total runtime is 0.0 minutes
2026-02-02 16:47:28,057:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:28,057:INFO:Initializing create_model()
2026-02-02 16:47:28,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:28,057:INFO:Checking exceptions
2026-02-02 16:47:28,057:INFO:Importing libraries
2026-02-02 16:47:28,057:INFO:Copying training dataset
2026-02-02 16:47:28,061:INFO:Defining folds
2026-02-02 16:47:28,061:INFO:Declaring metric variables
2026-02-02 16:47:28,061:INFO:Importing untrained model
2026-02-02 16:47:28,062:INFO:Logistic Regression Imported successfully
2026-02-02 16:47:28,062:INFO:Starting cross validation
2026-02-02 16:47:28,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:33,726:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,726:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,729:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,730:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,731:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,732:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,734:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,734:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,735:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,739:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,740:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,743:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,748:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,749:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,749:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,752:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,753:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,755:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,758:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,759:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,761:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,763:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,765:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,767:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,772:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,777:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,780:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:33,783:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,786:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,789:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,793:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,800:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:33,810:INFO:Calculating mean and std
2026-02-02 16:47:33,811:INFO:Creating metrics dataframe
2026-02-02 16:47:33,815:INFO:Uploading results into container
2026-02-02 16:47:33,816:INFO:Uploading model into container now
2026-02-02 16:47:33,817:INFO:_master_model_container: 1
2026-02-02 16:47:33,817:INFO:_display_container: 2
2026-02-02 16:47:33,818:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7258, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-02 16:47:33,818:INFO:create_model() successfully completed......................................
2026-02-02 16:47:33,969:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:33,969:INFO:Creating metrics dataframe
2026-02-02 16:47:33,973:INFO:Initializing K Neighbors Classifier
2026-02-02 16:47:33,973:INFO:Total runtime is 0.09861451387405396 minutes
2026-02-02 16:47:33,973:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:33,973:INFO:Initializing create_model()
2026-02-02 16:47:33,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:33,973:INFO:Checking exceptions
2026-02-02 16:47:33,973:INFO:Importing libraries
2026-02-02 16:47:33,973:INFO:Copying training dataset
2026-02-02 16:47:33,977:INFO:Defining folds
2026-02-02 16:47:33,978:INFO:Declaring metric variables
2026-02-02 16:47:33,978:INFO:Importing untrained model
2026-02-02 16:47:33,978:INFO:K Neighbors Classifier Imported successfully
2026-02-02 16:47:33,978:INFO:Starting cross validation
2026-02-02 16:47:33,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:34,155:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,156:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,157:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,157:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,161:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,162:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,163:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,163:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,166:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,167:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,168:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:34,168:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,242:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,247:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,251:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,256:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,260:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,262:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,272:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,275:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,279:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,284:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,288:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,290:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,300:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,303:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,306:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,316:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,319:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,322:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,338:INFO:Calculating mean and std
2026-02-02 16:47:38,339:INFO:Creating metrics dataframe
2026-02-02 16:47:38,342:INFO:Uploading results into container
2026-02-02 16:47:38,343:INFO:Uploading model into container now
2026-02-02 16:47:38,343:INFO:_master_model_container: 2
2026-02-02 16:47:38,344:INFO:_display_container: 2
2026-02-02 16:47:38,344:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-02-02 16:47:38,344:INFO:create_model() successfully completed......................................
2026-02-02 16:47:38,452:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:38,452:INFO:Creating metrics dataframe
2026-02-02 16:47:38,460:INFO:Initializing Naive Bayes
2026-02-02 16:47:38,461:INFO:Total runtime is 0.17340038617451986 minutes
2026-02-02 16:47:38,461:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:38,461:INFO:Initializing create_model()
2026-02-02 16:47:38,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:38,461:INFO:Checking exceptions
2026-02-02 16:47:38,461:INFO:Importing libraries
2026-02-02 16:47:38,461:INFO:Copying training dataset
2026-02-02 16:47:38,466:INFO:Defining folds
2026-02-02 16:47:38,466:INFO:Declaring metric variables
2026-02-02 16:47:38,466:INFO:Importing untrained model
2026-02-02 16:47:38,466:INFO:Naive Bayes Imported successfully
2026-02-02 16:47:38,466:INFO:Starting cross validation
2026-02-02 16:47:38,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:38,554:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,557:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,558:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,560:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,560:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,561:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,562:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,564:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,567:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,569:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,570:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,572:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,573:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,573:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,577:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,580:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,586:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,594:INFO:Calculating mean and std
2026-02-02 16:47:38,594:INFO:Creating metrics dataframe
2026-02-02 16:47:38,596:INFO:Uploading results into container
2026-02-02 16:47:38,597:INFO:Uploading model into container now
2026-02-02 16:47:38,597:INFO:_master_model_container: 3
2026-02-02 16:47:38,598:INFO:_display_container: 2
2026-02-02 16:47:38,598:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-02-02 16:47:38,598:INFO:create_model() successfully completed......................................
2026-02-02 16:47:38,707:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:38,707:INFO:Creating metrics dataframe
2026-02-02 16:47:38,710:INFO:Initializing Decision Tree Classifier
2026-02-02 16:47:38,710:INFO:Total runtime is 0.17756633758544924 minutes
2026-02-02 16:47:38,711:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:38,711:INFO:Initializing create_model()
2026-02-02 16:47:38,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:38,711:INFO:Checking exceptions
2026-02-02 16:47:38,711:INFO:Importing libraries
2026-02-02 16:47:38,711:INFO:Copying training dataset
2026-02-02 16:47:38,715:INFO:Defining folds
2026-02-02 16:47:38,715:INFO:Declaring metric variables
2026-02-02 16:47:38,715:INFO:Importing untrained model
2026-02-02 16:47:38,716:INFO:Decision Tree Classifier Imported successfully
2026-02-02 16:47:38,716:INFO:Starting cross validation
2026-02-02 16:47:38,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:38,810:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,811:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,811:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,812:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,815:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,820:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,820:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,823:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,825:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,832:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,832:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,837:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:38,845:INFO:Calculating mean and std
2026-02-02 16:47:38,846:INFO:Creating metrics dataframe
2026-02-02 16:47:38,848:INFO:Uploading results into container
2026-02-02 16:47:38,849:INFO:Uploading model into container now
2026-02-02 16:47:38,849:INFO:_master_model_container: 4
2026-02-02 16:47:38,849:INFO:_display_container: 2
2026-02-02 16:47:38,850:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7258, splitter='best')
2026-02-02 16:47:38,850:INFO:create_model() successfully completed......................................
2026-02-02 16:47:38,957:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:38,957:INFO:Creating metrics dataframe
2026-02-02 16:47:38,960:INFO:Initializing SVM - Linear Kernel
2026-02-02 16:47:38,961:INFO:Total runtime is 0.18173317114512128 minutes
2026-02-02 16:47:38,961:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:38,961:INFO:Initializing create_model()
2026-02-02 16:47:38,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:38,961:INFO:Checking exceptions
2026-02-02 16:47:38,961:INFO:Importing libraries
2026-02-02 16:47:38,961:INFO:Copying training dataset
2026-02-02 16:47:38,965:INFO:Defining folds
2026-02-02 16:47:38,965:INFO:Declaring metric variables
2026-02-02 16:47:38,966:INFO:Importing untrained model
2026-02-02 16:47:38,966:INFO:SVM - Linear Kernel Imported successfully
2026-02-02 16:47:38,966:INFO:Starting cross validation
2026-02-02 16:47:38,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:39,091:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,092:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,093:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,093:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,095:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,095:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,096:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,096:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,098:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,098:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,099:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,101:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,102:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:39,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:39,106:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,106:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,106:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,106:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,109:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,109:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,110:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:39,110:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:39,110:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,111:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,113:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,117:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,118:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,126:INFO:Calculating mean and std
2026-02-02 16:47:39,127:INFO:Creating metrics dataframe
2026-02-02 16:47:39,129:INFO:Uploading results into container
2026-02-02 16:47:39,129:INFO:Uploading model into container now
2026-02-02 16:47:39,129:INFO:_master_model_container: 5
2026-02-02 16:47:39,131:INFO:_display_container: 2
2026-02-02 16:47:39,131:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7258, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-02 16:47:39,131:INFO:create_model() successfully completed......................................
2026-02-02 16:47:39,236:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:39,236:INFO:Creating metrics dataframe
2026-02-02 16:47:39,239:INFO:Initializing Ridge Classifier
2026-02-02 16:47:39,240:INFO:Total runtime is 0.18640000025431316 minutes
2026-02-02 16:47:39,240:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:39,240:INFO:Initializing create_model()
2026-02-02 16:47:39,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:39,241:INFO:Checking exceptions
2026-02-02 16:47:39,241:INFO:Importing libraries
2026-02-02 16:47:39,241:INFO:Copying training dataset
2026-02-02 16:47:39,245:INFO:Defining folds
2026-02-02 16:47:39,245:INFO:Declaring metric variables
2026-02-02 16:47:39,245:INFO:Importing untrained model
2026-02-02 16:47:39,245:INFO:Ridge Classifier Imported successfully
2026-02-02 16:47:39,245:INFO:Starting cross validation
2026-02-02 16:47:39,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:39,328:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,330:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,330:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,334:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,335:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,336:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,337:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,337:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,338:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,338:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,339:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,340:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,341:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,342:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,342:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,345:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,346:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,347:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,349:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,349:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,352:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,353:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,353:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:39,353:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,354:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,354:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,355:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,357:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,357:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,358:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:39,360:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,360:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,372:INFO:Calculating mean and std
2026-02-02 16:47:39,373:INFO:Creating metrics dataframe
2026-02-02 16:47:39,375:INFO:Uploading results into container
2026-02-02 16:47:39,376:INFO:Uploading model into container now
2026-02-02 16:47:39,376:INFO:_master_model_container: 6
2026-02-02 16:47:39,376:INFO:_display_container: 2
2026-02-02 16:47:39,377:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7258, solver='auto',
                tol=0.0001)
2026-02-02 16:47:39,377:INFO:create_model() successfully completed......................................
2026-02-02 16:47:39,483:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:39,483:INFO:Creating metrics dataframe
2026-02-02 16:47:39,487:INFO:Initializing Random Forest Classifier
2026-02-02 16:47:39,487:INFO:Total runtime is 0.190519388516744 minutes
2026-02-02 16:47:39,487:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:39,487:INFO:Initializing create_model()
2026-02-02 16:47:39,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:39,487:INFO:Checking exceptions
2026-02-02 16:47:39,487:INFO:Importing libraries
2026-02-02 16:47:39,487:INFO:Copying training dataset
2026-02-02 16:47:39,491:INFO:Defining folds
2026-02-02 16:47:39,491:INFO:Declaring metric variables
2026-02-02 16:47:39,492:INFO:Importing untrained model
2026-02-02 16:47:39,492:INFO:Random Forest Classifier Imported successfully
2026-02-02 16:47:39,492:INFO:Starting cross validation
2026-02-02 16:47:39,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:39,915:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,919:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,919:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,924:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,924:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,925:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,927:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,928:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,929:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,930:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,932:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,933:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,934:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,935:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,936:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,938:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,939:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,939:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,940:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,940:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,942:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,943:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,946:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,946:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,953:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,958:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,961:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,962:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,965:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,968:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:39,976:INFO:Calculating mean and std
2026-02-02 16:47:39,976:INFO:Creating metrics dataframe
2026-02-02 16:47:39,978:INFO:Uploading results into container
2026-02-02 16:47:39,979:INFO:Uploading model into container now
2026-02-02 16:47:39,979:INFO:_master_model_container: 7
2026-02-02 16:47:39,979:INFO:_display_container: 2
2026-02-02 16:47:39,980:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7258, verbose=0,
                       warm_start=False)
2026-02-02 16:47:39,980:INFO:create_model() successfully completed......................................
2026-02-02 16:47:40,086:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:40,087:INFO:Creating metrics dataframe
2026-02-02 16:47:40,090:INFO:Initializing Quadratic Discriminant Analysis
2026-02-02 16:47:40,090:INFO:Total runtime is 0.2005654295285543 minutes
2026-02-02 16:47:40,090:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:40,090:INFO:Initializing create_model()
2026-02-02 16:47:40,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:40,090:INFO:Checking exceptions
2026-02-02 16:47:40,091:INFO:Importing libraries
2026-02-02 16:47:40,091:INFO:Copying training dataset
2026-02-02 16:47:40,095:INFO:Defining folds
2026-02-02 16:47:40,095:INFO:Declaring metric variables
2026-02-02 16:47:40,095:INFO:Importing untrained model
2026-02-02 16:47:40,095:INFO:Quadratic Discriminant Analysis Imported successfully
2026-02-02 16:47:40,096:INFO:Starting cross validation
2026-02-02 16:47:40,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:40,155:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,155:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,156:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,162:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,163:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,164:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,165:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,165:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,172:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,174:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2026-02-02 16:47:40,178:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,179:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,183:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,184:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,185:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,186:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,187:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,187:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,188:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,189:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,189:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,189:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,190:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,193:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,193:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,194:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,195:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,197:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,197:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,199:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

er, f"{metric.capitalize()} is", len(result))

at the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,201:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,203:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,205:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,206:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,207:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,208:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,208:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,210:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,214:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,215:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,217:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,223:INFO:Calculating mean and std
2026-02-02 16:47:40,224:INFO:Creating metrics dataframe
2026-02-02 16:47:40,226:INFO:Uploading results into container
2026-02-02 16:47:40,226:INFO:Uploading model into container now
2026-02-02 16:47:40,227:INFO:_master_model_container: 8
2026-02-02 16:47:40,227:INFO:_display_container: 2
2026-02-02 16:47:40,227:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-02-02 16:47:40,227:INFO:create_model() successfully completed......................................
2026-02-02 16:47:40,333:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:40,333:INFO:Creating metrics dataframe
2026-02-02 16:47:40,336:INFO:Initializing Ada Boost Classifier
2026-02-02 16:47:40,336:INFO:Total runtime is 0.20466741720835369 minutes
2026-02-02 16:47:40,337:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:40,337:INFO:Initializing create_model()
2026-02-02 16:47:40,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:40,337:INFO:Checking exceptions
2026-02-02 16:47:40,337:INFO:Importing libraries
2026-02-02 16:47:40,337:INFO:Copying training dataset
2026-02-02 16:47:40,341:INFO:Defining folds
2026-02-02 16:47:40,341:INFO:Declaring metric variables
2026-02-02 16:47:40,342:INFO:Importing untrained model
2026-02-02 16:47:40,342:INFO:Ada Boost Classifier Imported successfully
2026-02-02 16:47:40,342:INFO:Starting cross validation
2026-02-02 16:47:40,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:40,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,401:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,415:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-02-02 16:47:40,542:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,543:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,545:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,545:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,548:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,549:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,549:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,550:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,551:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,551:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,551:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,554:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,554:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,555:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,556:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,558:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,559:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,562:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,566:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,569:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,570:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,572:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,573:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,574:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,574:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,575:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,578:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,578:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,578:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,579:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:40,580:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,580:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,581:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,581:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,583:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,584:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,586:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:40,587:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,589:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:40,597:INFO:Calculating mean and std
2026-02-02 16:47:40,598:INFO:Creating metrics dataframe
2026-02-02 16:47:40,600:INFO:Uploading results into container
2026-02-02 16:47:40,600:INFO:Uploading model into container now
2026-02-02 16:47:40,601:INFO:_master_model_container: 9
2026-02-02 16:47:40,601:INFO:_display_container: 2
2026-02-02 16:47:40,601:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7258)
2026-02-02 16:47:40,601:INFO:create_model() successfully completed......................................
2026-02-02 16:47:40,707:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:40,707:INFO:Creating metrics dataframe
2026-02-02 16:47:40,710:INFO:Initializing Gradient Boosting Classifier
2026-02-02 16:47:40,710:INFO:Total runtime is 0.2109048883120219 minutes
2026-02-02 16:47:40,710:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:40,711:INFO:Initializing create_model()
2026-02-02 16:47:40,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:40,711:INFO:Checking exceptions
2026-02-02 16:47:40,711:INFO:Importing libraries
2026-02-02 16:47:40,711:INFO:Copying training dataset
2026-02-02 16:47:40,716:INFO:Defining folds
2026-02-02 16:47:40,716:INFO:Declaring metric variables
2026-02-02 16:47:40,716:INFO:Importing untrained model
2026-02-02 16:47:40,716:INFO:Gradient Boosting Classifier Imported successfully
2026-02-02 16:47:40,717:INFO:Starting cross validation
2026-02-02 16:47:40,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:41,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,369:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,374:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,378:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,395:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,396:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,400:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,402:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,404:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,404:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,405:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,406:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,408:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,409:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,410:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,411:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,413:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,413:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,413:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,415:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,417:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,418:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,419:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,422:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,424:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,424:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,426:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,427:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,428:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,430:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,434:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,436:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,438:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,438:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,440:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,442:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,443:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,446:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,452:INFO:Calculating mean and std
2026-02-02 16:47:41,453:INFO:Creating metrics dataframe
2026-02-02 16:47:41,455:INFO:Uploading results into container
2026-02-02 16:47:41,455:INFO:Uploading model into container now
2026-02-02 16:47:41,456:INFO:_master_model_container: 10
2026-02-02 16:47:41,456:INFO:_display_container: 2
2026-02-02 16:47:41,456:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7258, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-02 16:47:41,456:INFO:create_model() successfully completed......................................
2026-02-02 16:47:41,565:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:41,565:INFO:Creating metrics dataframe
2026-02-02 16:47:41,568:INFO:Initializing Linear Discriminant Analysis
2026-02-02 16:47:41,568:INFO:Total runtime is 0.2251999338467916 minutes
2026-02-02 16:47:41,568:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:41,569:INFO:Initializing create_model()
2026-02-02 16:47:41,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:41,569:INFO:Checking exceptions
2026-02-02 16:47:41,569:INFO:Importing libraries
2026-02-02 16:47:41,569:INFO:Copying training dataset
2026-02-02 16:47:41,573:INFO:Defining folds
2026-02-02 16:47:41,573:INFO:Declaring metric variables
2026-02-02 16:47:41,574:INFO:Importing untrained model
2026-02-02 16:47:41,574:INFO:Linear Discriminant Analysis Imported successfully
2026-02-02 16:47:41,574:INFO:Starting cross validation
2026-02-02 16:47:41,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:41,664:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,665:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,666:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,667:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,667:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,668:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,668:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,669:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,670:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,672:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,672:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,672:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,673:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,675:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,677:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-02 16:47:41,678:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,680:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,681:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,682:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,684:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,684:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,687:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:41,701:INFO:Calculating mean and std
2026-02-02 16:47:41,702:INFO:Creating metrics dataframe
2026-02-02 16:47:41,704:INFO:Uploading results into container
2026-02-02 16:47:41,704:INFO:Uploading model into container now
2026-02-02 16:47:41,705:INFO:_master_model_container: 11
2026-02-02 16:47:41,705:INFO:_display_container: 2
2026-02-02 16:47:41,705:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-02-02 16:47:41,705:INFO:create_model() successfully completed......................................
2026-02-02 16:47:41,810:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:41,811:INFO:Creating metrics dataframe
2026-02-02 16:47:41,814:INFO:Initializing Extra Trees Classifier
2026-02-02 16:47:41,814:INFO:Total runtime is 0.22930331230163575 minutes
2026-02-02 16:47:41,814:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:41,814:INFO:Initializing create_model()
2026-02-02 16:47:41,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:41,814:INFO:Checking exceptions
2026-02-02 16:47:41,815:INFO:Importing libraries
2026-02-02 16:47:41,815:INFO:Copying training dataset
2026-02-02 16:47:41,819:INFO:Defining folds
2026-02-02 16:47:41,819:INFO:Declaring metric variables
2026-02-02 16:47:41,820:INFO:Importing untrained model
2026-02-02 16:47:41,820:INFO:Extra Trees Classifier Imported successfully
2026-02-02 16:47:41,820:INFO:Starting cross validation
2026-02-02 16:47:41,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:42,142:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,143:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,147:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,148:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,152:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,152:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,153:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,156:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,158:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,161:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,163:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,165:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,165:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,168:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,168:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,171:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,172:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,173:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,175:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,176:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,176:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,178:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,179:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,182:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,187:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,191:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,194:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,194:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,199:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:42,206:INFO:Calculating mean and std
2026-02-02 16:47:42,207:INFO:Creating metrics dataframe
2026-02-02 16:47:42,209:INFO:Uploading results into container
2026-02-02 16:47:42,209:INFO:Uploading model into container now
2026-02-02 16:47:42,210:INFO:_master_model_container: 12
2026-02-02 16:47:42,210:INFO:_display_container: 2
2026-02-02 16:47:42,210:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7258, verbose=0,
                     warm_start=False)
2026-02-02 16:47:42,210:INFO:create_model() successfully completed......................................
2026-02-02 16:47:42,324:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:42,324:INFO:Creating metrics dataframe
2026-02-02 16:47:42,327:INFO:Initializing Extreme Gradient Boosting
2026-02-02 16:47:42,327:INFO:Total runtime is 0.23785093625386558 minutes
2026-02-02 16:47:42,328:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:42,328:INFO:Initializing create_model()
2026-02-02 16:47:42,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:42,328:INFO:Checking exceptions
2026-02-02 16:47:42,328:INFO:Importing libraries
2026-02-02 16:47:42,328:INFO:Copying training dataset
2026-02-02 16:47:42,333:INFO:Defining folds
2026-02-02 16:47:42,333:INFO:Declaring metric variables
2026-02-02 16:47:42,333:INFO:Importing untrained model
2026-02-02 16:47:42,334:INFO:Extreme Gradient Boosting Imported successfully
2026-02-02 16:47:42,334:INFO:Starting cross validation
2026-02-02 16:47:42,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:43,435:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,438:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,440:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,447:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,450:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,451:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,452:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,454:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,454:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,454:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,456:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,457:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,457:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,468:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,470:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,470:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,471:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,473:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,473:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,473:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,475:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,475:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,477:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,478:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,479:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,481:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,482:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,483:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:43,496:INFO:Calculating mean and std
2026-02-02 16:47:43,497:INFO:Creating metrics dataframe
2026-02-02 16:47:43,499:INFO:Uploading results into container
2026-02-02 16:47:43,500:INFO:Uploading model into container now
2026-02-02 16:47:43,500:INFO:_master_model_container: 13
2026-02-02 16:47:43,500:INFO:_display_container: 2
2026-02-02 16:47:43,501:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2026-02-02 16:47:43,501:INFO:create_model() successfully completed......................................
2026-02-02 16:47:43,610:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:43,611:INFO:Creating metrics dataframe
2026-02-02 16:47:43,614:INFO:Initializing Light Gradient Boosting Machine
2026-02-02 16:47:43,614:INFO:Total runtime is 0.2593039155006409 minutes
2026-02-02 16:47:43,614:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:43,614:INFO:Initializing create_model()
2026-02-02 16:47:43,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:43,614:INFO:Checking exceptions
2026-02-02 16:47:43,614:INFO:Importing libraries
2026-02-02 16:47:43,614:INFO:Copying training dataset
2026-02-02 16:47:43,619:INFO:Defining folds
2026-02-02 16:47:43,619:INFO:Declaring metric variables
2026-02-02 16:47:43,619:INFO:Importing untrained model
2026-02-02 16:47:43,620:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-02 16:47:43,620:INFO:Starting cross validation
2026-02-02 16:47:43,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:45,585:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,593:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,601:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,674:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,679:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,685:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,778:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,782:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,787:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,835:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,902:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,908:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,914:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,931:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,936:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:45,941:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,069:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,074:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,079:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,114:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,121:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,129:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,169:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,173:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,178:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,186:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,190:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,193:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:46,208:INFO:Calculating mean and std
2026-02-02 16:47:46,209:INFO:Creating metrics dataframe
2026-02-02 16:47:46,212:INFO:Uploading results into container
2026-02-02 16:47:46,213:INFO:Uploading model into container now
2026-02-02 16:47:46,213:INFO:_master_model_container: 14
2026-02-02 16:47:46,213:INFO:_display_container: 2
2026-02-02 16:47:46,214:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7258, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-02 16:47:46,215:INFO:create_model() successfully completed......................................
2026-02-02 16:47:46,339:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:46,339:INFO:Creating metrics dataframe
2026-02-02 16:47:46,343:INFO:Initializing CatBoost Classifier
2026-02-02 16:47:46,343:INFO:Total runtime is 0.30478908618291223 minutes
2026-02-02 16:47:46,343:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:46,343:INFO:Initializing create_model()
2026-02-02 16:47:46,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:46,343:INFO:Checking exceptions
2026-02-02 16:47:46,343:INFO:Importing libraries
2026-02-02 16:47:46,343:INFO:Copying training dataset
2026-02-02 16:47:46,348:INFO:Defining folds
2026-02-02 16:47:46,348:INFO:Declaring metric variables
2026-02-02 16:47:46,348:INFO:Importing untrained model
2026-02-02 16:47:46,349:INFO:CatBoost Classifier Imported successfully
2026-02-02 16:47:46,349:INFO:Starting cross validation
2026-02-02 16:47:46,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:56,187:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:56,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:56,196:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:56,891:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:56,895:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:56,902:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,529:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,534:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,540:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,651:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,660:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,831:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,836:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,839:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,967:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,970:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:57,974:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,108:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,112:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,115:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,152:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,157:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,161:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,179:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,183:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,186:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,264:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,268:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,270:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,291:INFO:Calculating mean and std
2026-02-02 16:47:58,293:INFO:Creating metrics dataframe
2026-02-02 16:47:58,296:INFO:Uploading results into container
2026-02-02 16:47:58,296:INFO:Uploading model into container now
2026-02-02 16:47:58,297:INFO:_master_model_container: 15
2026-02-02 16:47:58,297:INFO:_display_container: 2
2026-02-02 16:47:58,297:INFO:<catboost.core.CatBoostClassifier object at 0x0000020A9B5DD310>
2026-02-02 16:47:58,297:INFO:create_model() successfully completed......................................
2026-02-02 16:47:58,445:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:58,446:INFO:Creating metrics dataframe
2026-02-02 16:47:58,450:INFO:Initializing Dummy Classifier
2026-02-02 16:47:58,450:INFO:Total runtime is 0.5065654516220093 minutes
2026-02-02 16:47:58,450:INFO:SubProcess create_model() called ==================================
2026-02-02 16:47:58,450:INFO:Initializing create_model()
2026-02-02 16:47:58,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BF51150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:58,451:INFO:Checking exceptions
2026-02-02 16:47:58,451:INFO:Importing libraries
2026-02-02 16:47:58,451:INFO:Copying training dataset
2026-02-02 16:47:58,456:INFO:Defining folds
2026-02-02 16:47:58,456:INFO:Declaring metric variables
2026-02-02 16:47:58,456:INFO:Importing untrained model
2026-02-02 16:47:58,456:INFO:Dummy Classifier Imported successfully
2026-02-02 16:47:58,457:INFO:Starting cross validation
2026-02-02 16:47:58,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:47:58,549:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,554:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,555:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,558:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,558:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,559:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,559:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,560:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,561:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,563:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,565:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,566:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,566:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,567:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,568:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,569:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,569:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,570:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,570:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,571:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,572:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,573:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,574:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,574:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,574:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,575:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,575:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,576:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,578:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,579:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,581:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-02-02 16:47:58,584:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-02 16:47:58,596:INFO:Calculating mean and std
2026-02-02 16:47:58,597:INFO:Creating metrics dataframe
2026-02-02 16:47:58,600:INFO:Uploading results into container
2026-02-02 16:47:58,600:INFO:Uploading model into container now
2026-02-02 16:47:58,601:INFO:_master_model_container: 16
2026-02-02 16:47:58,601:INFO:_display_container: 2
2026-02-02 16:47:58,601:INFO:DummyClassifier(constant=None, random_state=7258, strategy='prior')
2026-02-02 16:47:58,601:INFO:create_model() successfully completed......................................
2026-02-02 16:47:58,719:INFO:SubProcess create_model() end ==================================
2026-02-02 16:47:58,719:INFO:Creating metrics dataframe
2026-02-02 16:47:58,724:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-02 16:47:58,727:INFO:Initializing create_model()
2026-02-02 16:47:58,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020A9A1564D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7258, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:47:58,727:INFO:Checking exceptions
2026-02-02 16:47:58,728:INFO:Importing libraries
2026-02-02 16:47:58,728:INFO:Copying training dataset
2026-02-02 16:47:58,733:INFO:Defining folds
2026-02-02 16:47:58,733:INFO:Declaring metric variables
2026-02-02 16:47:58,733:INFO:Importing untrained model
2026-02-02 16:47:58,733:INFO:Declaring custom model
2026-02-02 16:47:58,734:INFO:Decision Tree Classifier Imported successfully
2026-02-02 16:47:58,735:INFO:Cross validation set to False
2026-02-02 16:47:58,735:INFO:Fitting Model
2026-02-02 16:47:58,770:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7258, splitter='best')
2026-02-02 16:47:58,771:INFO:create_model() successfully completed......................................
2026-02-02 16:47:58,900:INFO:_master_model_container: 16
2026-02-02 16:47:58,901:INFO:_display_container: 2
2026-02-02 16:47:58,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7258, splitter='best')
2026-02-02 16:47:58,901:INFO:compare_models() successfully completed......................................
2026-02-02 16:47:58,910:INFO:Initializing save_model()
2026-02-02 16:47:58,910:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7258, splitter='best'), model_name=models\avocado_ripeness_dataset_classification_auto, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'sound_db',
                                             'weight_g', 'size_cm3'],
                                    transformer=SimpleImput...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['color_category'],
                                    transformer=OneHotEncoder(cols=['color_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-02-02 16:47:58,910:INFO:Adding model into prep_pipe
2026-02-02 16:47:58,922:INFO:models\avocado_ripeness_dataset_classification_auto.pkl saved in current working directory
2026-02-02 16:47:58,930:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'sound_db',
                                             'weight_g', 'size_cm3'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_va...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=7258,
                                        splitter='best'))],
         verbose=False)
2026-02-02 16:47:58,930:INFO:save_model() successfully completed......................................
2026-02-02 16:48:57,712:INFO:PyCaret RegressionExperiment
2026-02-02 16:48:57,712:INFO:Logging name: reg-default-name
2026-02-02 16:48:57,712:INFO:ML Usecase: MLUsecase.REGRESSION
2026-02-02 16:48:57,712:INFO:version 3.3.2
2026-02-02 16:48:57,712:INFO:Initializing setup()
2026-02-02 16:48:57,712:INFO:self.USI: 2040
2026-02-02 16:48:57,712:INFO:self._variable_keys: {'y', 'data', 'X_test', 'gpu_n_jobs_param', 'y_test', 'n_jobs_param', 'transform_target_param', 'memory', 'X_train', 'fold_generator', '_available_plots', 'seed', 'USI', 'idx', 'fold_shuffle_param', 'log_plots_param', 'fold_groups_param', 'target_param', 'X', 'exp_name_log', 'pipeline', 'gpu_param', 'exp_id', 'y_train', '_ml_usecase', 'logging_param', 'html_param'}
2026-02-02 16:48:57,713:INFO:Checking environment
2026-02-02 16:48:57,713:INFO:python_version: 3.11.9
2026-02-02 16:48:57,713:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-02 16:48:57,713:INFO:machine: AMD64
2026-02-02 16:48:57,713:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-02 16:48:57,713:INFO:Memory: svmem(total=16866873344, available=966717440, percent=94.3, used=15900155904, free=966717440)
2026-02-02 16:48:57,714:INFO:Physical Core: 8
2026-02-02 16:48:57,714:INFO:Logical Core: 16
2026-02-02 16:48:57,714:INFO:Checking libraries
2026-02-02 16:48:57,714:INFO:System:
2026-02-02 16:48:57,714:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-02 16:48:57,714:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-02 16:48:57,714:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-02 16:48:57,714:INFO:PyCaret required dependencies:
2026-02-02 16:48:57,714:INFO:                 pip: 24.0
2026-02-02 16:48:57,715:INFO:          setuptools: 80.9.0
2026-02-02 16:48:57,715:INFO:             pycaret: 3.3.2
2026-02-02 16:48:57,715:INFO:             IPython: 9.8.0
2026-02-02 16:48:57,715:INFO:          ipywidgets: 8.1.8
2026-02-02 16:48:57,715:INFO:                tqdm: 4.67.1
2026-02-02 16:48:57,715:INFO:               numpy: 1.26.4
2026-02-02 16:48:57,715:INFO:              pandas: 2.1.4
2026-02-02 16:48:57,715:INFO:              jinja2: 3.1.6
2026-02-02 16:48:57,716:INFO:               scipy: 1.11.4
2026-02-02 16:48:57,716:INFO:              joblib: 1.3.2
2026-02-02 16:48:57,716:INFO:             sklearn: 1.4.2
2026-02-02 16:48:57,716:INFO:                pyod: 2.0.6
2026-02-02 16:48:57,716:INFO:            imblearn: 0.14.1
2026-02-02 16:48:57,716:INFO:   category_encoders: 2.7.0
2026-02-02 16:48:57,716:INFO:            lightgbm: 4.6.0
2026-02-02 16:48:57,716:INFO:               numba: 0.63.1
2026-02-02 16:48:57,716:INFO:            requests: 2.32.5
2026-02-02 16:48:57,717:INFO:          matplotlib: 3.7.5
2026-02-02 16:48:57,717:INFO:          scikitplot: 0.3.7
2026-02-02 16:48:57,717:INFO:         yellowbrick: 1.5
2026-02-02 16:48:57,717:INFO:              plotly: 6.5.0
2026-02-02 16:48:57,717:INFO:    plotly-resampler: Not installed
2026-02-02 16:48:57,717:INFO:             kaleido: 1.2.0
2026-02-02 16:48:57,717:INFO:           schemdraw: 0.15
2026-02-02 16:48:57,717:INFO:         statsmodels: 0.14.6
2026-02-02 16:48:57,717:INFO:              sktime: 0.26.0
2026-02-02 16:48:57,717:INFO:               tbats: 1.1.3
2026-02-02 16:48:57,717:INFO:            pmdarima: 2.0.4
2026-02-02 16:48:57,717:INFO:              psutil: 7.1.3
2026-02-02 16:48:57,717:INFO:          markupsafe: 3.0.3
2026-02-02 16:48:57,717:INFO:             pickle5: Not installed
2026-02-02 16:48:57,718:INFO:         cloudpickle: 3.1.2
2026-02-02 16:48:57,718:INFO:         deprecation: 2.1.0
2026-02-02 16:48:57,718:INFO:              xxhash: 3.6.0
2026-02-02 16:48:57,718:INFO:           wurlitzer: Not installed
2026-02-02 16:48:57,718:INFO:PyCaret optional dependencies:
2026-02-02 16:48:57,718:INFO:                shap: Not installed
2026-02-02 16:48:57,718:INFO:           interpret: Not installed
2026-02-02 16:48:57,718:INFO:                umap: Not installed
2026-02-02 16:48:57,718:INFO:     ydata_profiling: Not installed
2026-02-02 16:48:57,720:INFO:  explainerdashboard: Not installed
2026-02-02 16:48:57,720:INFO:             autoviz: Not installed
2026-02-02 16:48:57,720:INFO:           fairlearn: Not installed
2026-02-02 16:48:57,720:INFO:          deepchecks: Not installed
2026-02-02 16:48:57,720:INFO:             xgboost: 3.1.2
2026-02-02 16:48:57,720:INFO:            catboost: 1.2.8
2026-02-02 16:48:57,720:INFO:              kmodes: Not installed
2026-02-02 16:48:57,720:INFO:             mlxtend: Not installed
2026-02-02 16:48:57,720:INFO:       statsforecast: Not installed
2026-02-02 16:48:57,721:INFO:        tune_sklearn: Not installed
2026-02-02 16:48:57,721:INFO:                 ray: Not installed
2026-02-02 16:48:57,721:INFO:            hyperopt: Not installed
2026-02-02 16:48:57,721:INFO:              optuna: 4.6.0
2026-02-02 16:48:57,721:INFO:               skopt: Not installed
2026-02-02 16:48:57,721:INFO:              mlflow: Not installed
2026-02-02 16:48:57,721:INFO:              gradio: Not installed
2026-02-02 16:48:57,721:INFO:             fastapi: 0.123.10
2026-02-02 16:48:57,721:INFO:             uvicorn: 0.38.0
2026-02-02 16:48:57,721:INFO:              m2cgen: Not installed
2026-02-02 16:48:57,721:INFO:           evidently: Not installed
2026-02-02 16:48:57,721:INFO:               fugue: Not installed
2026-02-02 16:48:57,721:INFO:           streamlit: Not installed
2026-02-02 16:48:57,721:INFO:             prophet: Not installed
2026-02-02 16:48:57,721:INFO:None
2026-02-02 16:48:57,721:INFO:Set up data.
2026-02-02 16:48:57,730:INFO:Set up folding strategy.
2026-02-02 16:48:57,730:INFO:Set up train/test split.
2026-02-02 16:48:57,735:INFO:Set up index.
2026-02-02 16:48:57,736:INFO:Assigning column types.
2026-02-02 16:48:57,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-02 16:48:57,743:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,753:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,764:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,933:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:57,938:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:57,939:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,951:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-02 16:48:57,962:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,149:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:58,155:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:58,156:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2026-02-02 16:48:58,166:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,340:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:58,344:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:58,350:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,453:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,533:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:58,539:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:58,539:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2026-02-02 16:48:58,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,659:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,725:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:58,732:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:58,745:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:58,885:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:58,887:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:58,889:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2026-02-02 16:48:58,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,050:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,061:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,174:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,246:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,249:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,250:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-02 16:48:59,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,433:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,438:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-02 16:48:59,597:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,601:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,603:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2026-02-02 16:48:59,790:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,793:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,983:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:48:59,986:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:48:59,988:INFO:Preparing preprocessing pipeline...
2026-02-02 16:48:59,988:INFO:Set up simple imputation.
2026-02-02 16:49:00,015:INFO:Finished creating preprocessing pipeline.
2026-02-02 16:49:00,021:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2026-02-02 16:49:00,021:INFO:Creating final display dataframe.
2026-02-02 16:49:00,103:INFO:Setup _display_container:                     Description             Value
0                    Session id              6994
1                        Target              MEDV
2                   Target type        Regression
3           Original data shape         (394, 14)
4        Transformed data shape         (394, 14)
5   Transformed train set shape         (275, 14)
6    Transformed test set shape         (119, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2040
2026-02-02 16:49:00,322:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:49:00,327:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:49:00,488:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-02 16:49:00,492:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-02 16:49:00,493:INFO:setup() successfully completed in 2.78s...............
2026-02-02 16:49:00,493:INFO:Initializing compare_models()
2026-02-02 16:49:00,493:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2026-02-02 16:49:00,493:INFO:Checking exceptions
2026-02-02 16:49:00,495:INFO:Preparing display monitor
2026-02-02 16:49:00,498:INFO:Initializing Linear Regression
2026-02-02 16:49:00,498:INFO:Total runtime is 0.0 minutes
2026-02-02 16:49:00,499:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:00,500:INFO:Initializing create_model()
2026-02-02 16:49:00,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:00,500:INFO:Checking exceptions
2026-02-02 16:49:00,500:INFO:Importing libraries
2026-02-02 16:49:00,500:INFO:Copying training dataset
2026-02-02 16:49:00,506:INFO:Defining folds
2026-02-02 16:49:00,506:INFO:Declaring metric variables
2026-02-02 16:49:00,506:INFO:Importing untrained model
2026-02-02 16:49:00,506:INFO:Linear Regression Imported successfully
2026-02-02 16:49:00,506:INFO:Starting cross validation
2026-02-02 16:49:00,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:00,589:INFO:Calculating mean and std
2026-02-02 16:49:00,589:INFO:Creating metrics dataframe
2026-02-02 16:49:00,592:INFO:Uploading results into container
2026-02-02 16:49:00,593:INFO:Uploading model into container now
2026-02-02 16:49:00,593:INFO:_master_model_container: 1
2026-02-02 16:49:00,593:INFO:_display_container: 2
2026-02-02 16:49:00,594:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2026-02-02 16:49:00,594:INFO:create_model() successfully completed......................................
2026-02-02 16:49:00,727:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:00,728:INFO:Creating metrics dataframe
2026-02-02 16:49:00,732:INFO:Initializing Lasso Regression
2026-02-02 16:49:00,732:INFO:Total runtime is 0.003912341594696045 minutes
2026-02-02 16:49:00,732:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:00,732:INFO:Initializing create_model()
2026-02-02 16:49:00,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:00,732:INFO:Checking exceptions
2026-02-02 16:49:00,732:INFO:Importing libraries
2026-02-02 16:49:00,732:INFO:Copying training dataset
2026-02-02 16:49:00,737:INFO:Defining folds
2026-02-02 16:49:00,737:INFO:Declaring metric variables
2026-02-02 16:49:00,738:INFO:Importing untrained model
2026-02-02 16:49:00,739:INFO:Lasso Regression Imported successfully
2026-02-02 16:49:00,740:INFO:Starting cross validation
2026-02-02 16:49:00,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:00,830:INFO:Calculating mean and std
2026-02-02 16:49:00,831:INFO:Creating metrics dataframe
2026-02-02 16:49:00,833:INFO:Uploading results into container
2026-02-02 16:49:00,834:INFO:Uploading model into container now
2026-02-02 16:49:00,834:INFO:_master_model_container: 2
2026-02-02 16:49:00,834:INFO:_display_container: 2
2026-02-02 16:49:00,835:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=6994, selection='cyclic', tol=0.0001,
      warm_start=False)
2026-02-02 16:49:00,835:INFO:create_model() successfully completed......................................
2026-02-02 16:49:00,957:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:00,957:INFO:Creating metrics dataframe
2026-02-02 16:49:00,960:INFO:Initializing Ridge Regression
2026-02-02 16:49:00,960:INFO:Total runtime is 0.0076991756757100425 minutes
2026-02-02 16:49:00,961:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:00,961:INFO:Initializing create_model()
2026-02-02 16:49:00,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:00,961:INFO:Checking exceptions
2026-02-02 16:49:00,961:INFO:Importing libraries
2026-02-02 16:49:00,961:INFO:Copying training dataset
2026-02-02 16:49:00,968:INFO:Defining folds
2026-02-02 16:49:00,968:INFO:Declaring metric variables
2026-02-02 16:49:00,969:INFO:Importing untrained model
2026-02-02 16:49:00,970:INFO:Ridge Regression Imported successfully
2026-02-02 16:49:00,970:INFO:Starting cross validation
2026-02-02 16:49:00,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:01,073:INFO:Calculating mean and std
2026-02-02 16:49:01,074:INFO:Creating metrics dataframe
2026-02-02 16:49:01,077:INFO:Uploading results into container
2026-02-02 16:49:01,078:INFO:Uploading model into container now
2026-02-02 16:49:01,078:INFO:_master_model_container: 3
2026-02-02 16:49:01,079:INFO:_display_container: 2
2026-02-02 16:49:01,079:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=6994, solver='auto', tol=0.0001)
2026-02-02 16:49:01,079:INFO:create_model() successfully completed......................................
2026-02-02 16:49:01,192:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:01,192:INFO:Creating metrics dataframe
2026-02-02 16:49:01,195:INFO:Initializing Elastic Net
2026-02-02 16:49:01,196:INFO:Total runtime is 0.011635029315948488 minutes
2026-02-02 16:49:01,196:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:01,196:INFO:Initializing create_model()
2026-02-02 16:49:01,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:01,196:INFO:Checking exceptions
2026-02-02 16:49:01,196:INFO:Importing libraries
2026-02-02 16:49:01,196:INFO:Copying training dataset
2026-02-02 16:49:01,201:INFO:Defining folds
2026-02-02 16:49:01,201:INFO:Declaring metric variables
2026-02-02 16:49:01,201:INFO:Importing untrained model
2026-02-02 16:49:01,201:INFO:Elastic Net Imported successfully
2026-02-02 16:49:01,201:INFO:Starting cross validation
2026-02-02 16:49:01,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:01,287:INFO:Calculating mean and std
2026-02-02 16:49:01,288:INFO:Creating metrics dataframe
2026-02-02 16:49:01,290:INFO:Uploading results into container
2026-02-02 16:49:01,290:INFO:Uploading model into container now
2026-02-02 16:49:01,291:INFO:_master_model_container: 4
2026-02-02 16:49:01,291:INFO:_display_container: 2
2026-02-02 16:49:01,291:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=6994,
           selection='cyclic', tol=0.0001, warm_start=False)
2026-02-02 16:49:01,291:INFO:create_model() successfully completed......................................
2026-02-02 16:49:01,411:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:01,411:INFO:Creating metrics dataframe
2026-02-02 16:49:01,415:INFO:Initializing Least Angle Regression
2026-02-02 16:49:01,415:INFO:Total runtime is 0.015293510754903159 minutes
2026-02-02 16:49:01,415:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:01,416:INFO:Initializing create_model()
2026-02-02 16:49:01,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:01,416:INFO:Checking exceptions
2026-02-02 16:49:01,416:INFO:Importing libraries
2026-02-02 16:49:01,416:INFO:Copying training dataset
2026-02-02 16:49:01,420:INFO:Defining folds
2026-02-02 16:49:01,420:INFO:Declaring metric variables
2026-02-02 16:49:01,420:INFO:Importing untrained model
2026-02-02 16:49:01,421:INFO:Least Angle Regression Imported successfully
2026-02-02 16:49:01,422:INFO:Starting cross validation
2026-02-02 16:49:01,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:01,505:INFO:Calculating mean and std
2026-02-02 16:49:01,505:INFO:Creating metrics dataframe
2026-02-02 16:49:01,508:INFO:Uploading results into container
2026-02-02 16:49:01,508:INFO:Uploading model into container now
2026-02-02 16:49:01,509:INFO:_master_model_container: 5
2026-02-02 16:49:01,509:INFO:_display_container: 2
2026-02-02 16:49:01,509:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=6994,
     verbose=False)
2026-02-02 16:49:01,510:INFO:create_model() successfully completed......................................
2026-02-02 16:49:01,623:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:01,624:INFO:Creating metrics dataframe
2026-02-02 16:49:01,628:INFO:Initializing Lasso Least Angle Regression
2026-02-02 16:49:01,628:INFO:Total runtime is 0.01883135239283244 minutes
2026-02-02 16:49:01,628:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:01,628:INFO:Initializing create_model()
2026-02-02 16:49:01,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:01,629:INFO:Checking exceptions
2026-02-02 16:49:01,629:INFO:Importing libraries
2026-02-02 16:49:01,629:INFO:Copying training dataset
2026-02-02 16:49:01,634:INFO:Defining folds
2026-02-02 16:49:01,634:INFO:Declaring metric variables
2026-02-02 16:49:01,634:INFO:Importing untrained model
2026-02-02 16:49:01,635:INFO:Lasso Least Angle Regression Imported successfully
2026-02-02 16:49:01,635:INFO:Starting cross validation
2026-02-02 16:49:01,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:01,723:INFO:Calculating mean and std
2026-02-02 16:49:01,723:INFO:Creating metrics dataframe
2026-02-02 16:49:01,725:INFO:Uploading results into container
2026-02-02 16:49:01,725:INFO:Uploading model into container now
2026-02-02 16:49:01,726:INFO:_master_model_container: 6
2026-02-02 16:49:01,726:INFO:_display_container: 2
2026-02-02 16:49:01,726:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=6994, verbose=False)
2026-02-02 16:49:01,726:INFO:create_model() successfully completed......................................
2026-02-02 16:49:01,839:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:01,839:INFO:Creating metrics dataframe
2026-02-02 16:49:01,842:INFO:Initializing Orthogonal Matching Pursuit
2026-02-02 16:49:01,842:INFO:Total runtime is 0.022397740681966146 minutes
2026-02-02 16:49:01,843:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:01,843:INFO:Initializing create_model()
2026-02-02 16:49:01,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:01,843:INFO:Checking exceptions
2026-02-02 16:49:01,843:INFO:Importing libraries
2026-02-02 16:49:01,843:INFO:Copying training dataset
2026-02-02 16:49:01,848:INFO:Defining folds
2026-02-02 16:49:01,848:INFO:Declaring metric variables
2026-02-02 16:49:01,848:INFO:Importing untrained model
2026-02-02 16:49:01,849:INFO:Orthogonal Matching Pursuit Imported successfully
2026-02-02 16:49:01,849:INFO:Starting cross validation
2026-02-02 16:49:01,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:01,931:INFO:Calculating mean and std
2026-02-02 16:49:01,931:INFO:Creating metrics dataframe
2026-02-02 16:49:01,934:INFO:Uploading results into container
2026-02-02 16:49:01,935:INFO:Uploading model into container now
2026-02-02 16:49:01,935:INFO:_master_model_container: 7
2026-02-02 16:49:01,935:INFO:_display_container: 2
2026-02-02 16:49:01,935:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2026-02-02 16:49:01,936:INFO:create_model() successfully completed......................................
2026-02-02 16:49:02,050:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:02,051:INFO:Creating metrics dataframe
2026-02-02 16:49:02,055:INFO:Initializing Bayesian Ridge
2026-02-02 16:49:02,055:INFO:Total runtime is 0.02595210870107015 minutes
2026-02-02 16:49:02,055:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:02,056:INFO:Initializing create_model()
2026-02-02 16:49:02,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:02,056:INFO:Checking exceptions
2026-02-02 16:49:02,056:INFO:Importing libraries
2026-02-02 16:49:02,056:INFO:Copying training dataset
2026-02-02 16:49:02,063:INFO:Defining folds
2026-02-02 16:49:02,063:INFO:Declaring metric variables
2026-02-02 16:49:02,063:INFO:Importing untrained model
2026-02-02 16:49:02,064:INFO:Bayesian Ridge Imported successfully
2026-02-02 16:49:02,064:INFO:Starting cross validation
2026-02-02 16:49:02,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:02,159:INFO:Calculating mean and std
2026-02-02 16:49:02,159:INFO:Creating metrics dataframe
2026-02-02 16:49:02,163:INFO:Uploading results into container
2026-02-02 16:49:02,163:INFO:Uploading model into container now
2026-02-02 16:49:02,164:INFO:_master_model_container: 8
2026-02-02 16:49:02,164:INFO:_display_container: 2
2026-02-02 16:49:02,164:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2026-02-02 16:49:02,164:INFO:create_model() successfully completed......................................
2026-02-02 16:49:02,287:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:02,287:INFO:Creating metrics dataframe
2026-02-02 16:49:02,290:INFO:Initializing Passive Aggressive Regressor
2026-02-02 16:49:02,290:INFO:Total runtime is 0.029863798618316652 minutes
2026-02-02 16:49:02,290:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:02,291:INFO:Initializing create_model()
2026-02-02 16:49:02,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:02,291:INFO:Checking exceptions
2026-02-02 16:49:02,291:INFO:Importing libraries
2026-02-02 16:49:02,291:INFO:Copying training dataset
2026-02-02 16:49:02,295:INFO:Defining folds
2026-02-02 16:49:02,295:INFO:Declaring metric variables
2026-02-02 16:49:02,296:INFO:Importing untrained model
2026-02-02 16:49:02,296:INFO:Passive Aggressive Regressor Imported successfully
2026-02-02 16:49:02,296:INFO:Starting cross validation
2026-02-02 16:49:02,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:02,385:INFO:Calculating mean and std
2026-02-02 16:49:02,386:INFO:Creating metrics dataframe
2026-02-02 16:49:02,389:INFO:Uploading results into container
2026-02-02 16:49:02,389:INFO:Uploading model into container now
2026-02-02 16:49:02,390:INFO:_master_model_container: 9
2026-02-02 16:49:02,390:INFO:_display_container: 2
2026-02-02 16:49:02,390:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=6994, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-02-02 16:49:02,390:INFO:create_model() successfully completed......................................
2026-02-02 16:49:02,500:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:02,501:INFO:Creating metrics dataframe
2026-02-02 16:49:02,504:INFO:Initializing Huber Regressor
2026-02-02 16:49:02,504:INFO:Total runtime is 0.033432885011037194 minutes
2026-02-02 16:49:02,504:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:02,505:INFO:Initializing create_model()
2026-02-02 16:49:02,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:02,505:INFO:Checking exceptions
2026-02-02 16:49:02,505:INFO:Importing libraries
2026-02-02 16:49:02,505:INFO:Copying training dataset
2026-02-02 16:49:02,509:INFO:Defining folds
2026-02-02 16:49:02,509:INFO:Declaring metric variables
2026-02-02 16:49:02,509:INFO:Importing untrained model
2026-02-02 16:49:02,510:INFO:Huber Regressor Imported successfully
2026-02-02 16:49:02,510:INFO:Starting cross validation
2026-02-02 16:49:02,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:02,633:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,633:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,634:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2026-02-02 16:49:02,657:INFO:Calculating mean and std
2026-02-02 16:49:02,658:INFO:Creating metrics dataframe
2026-02-02 16:49:02,661:INFO:Uploading results into container
2026-02-02 16:49:02,661:INFO:Uploading model into container now
2026-02-02 16:49:02,662:INFO:_master_model_container: 10
2026-02-02 16:49:02,662:INFO:_display_container: 2
2026-02-02 16:49:02,662:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2026-02-02 16:49:02,662:INFO:create_model() successfully completed......................................
2026-02-02 16:49:02,775:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:02,775:INFO:Creating metrics dataframe
2026-02-02 16:49:02,778:INFO:Initializing K Neighbors Regressor
2026-02-02 16:49:02,778:INFO:Total runtime is 0.03800299167633057 minutes
2026-02-02 16:49:02,779:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:02,779:INFO:Initializing create_model()
2026-02-02 16:49:02,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:02,779:INFO:Checking exceptions
2026-02-02 16:49:02,779:INFO:Importing libraries
2026-02-02 16:49:02,779:INFO:Copying training dataset
2026-02-02 16:49:02,784:INFO:Defining folds
2026-02-02 16:49:02,784:INFO:Declaring metric variables
2026-02-02 16:49:02,784:INFO:Importing untrained model
2026-02-02 16:49:02,784:INFO:K Neighbors Regressor Imported successfully
2026-02-02 16:49:02,785:INFO:Starting cross validation
2026-02-02 16:49:02,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:02,898:INFO:Calculating mean and std
2026-02-02 16:49:02,899:INFO:Creating metrics dataframe
2026-02-02 16:49:02,902:INFO:Uploading results into container
2026-02-02 16:49:02,902:INFO:Uploading model into container now
2026-02-02 16:49:02,903:INFO:_master_model_container: 11
2026-02-02 16:49:02,903:INFO:_display_container: 2
2026-02-02 16:49:02,903:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2026-02-02 16:49:02,904:INFO:create_model() successfully completed......................................
2026-02-02 16:49:03,021:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:03,021:INFO:Creating metrics dataframe
2026-02-02 16:49:03,025:INFO:Initializing Decision Tree Regressor
2026-02-02 16:49:03,025:INFO:Total runtime is 0.04212684631347657 minutes
2026-02-02 16:49:03,026:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:03,026:INFO:Initializing create_model()
2026-02-02 16:49:03,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:03,026:INFO:Checking exceptions
2026-02-02 16:49:03,027:INFO:Importing libraries
2026-02-02 16:49:03,027:INFO:Copying training dataset
2026-02-02 16:49:03,031:INFO:Defining folds
2026-02-02 16:49:03,031:INFO:Declaring metric variables
2026-02-02 16:49:03,032:INFO:Importing untrained model
2026-02-02 16:49:03,032:INFO:Decision Tree Regressor Imported successfully
2026-02-02 16:49:03,032:INFO:Starting cross validation
2026-02-02 16:49:03,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:03,132:INFO:Calculating mean and std
2026-02-02 16:49:03,133:INFO:Creating metrics dataframe
2026-02-02 16:49:03,135:INFO:Uploading results into container
2026-02-02 16:49:03,135:INFO:Uploading model into container now
2026-02-02 16:49:03,136:INFO:_master_model_container: 12
2026-02-02 16:49:03,136:INFO:_display_container: 2
2026-02-02 16:49:03,136:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=6994, splitter='best')
2026-02-02 16:49:03,136:INFO:create_model() successfully completed......................................
2026-02-02 16:49:03,245:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:03,245:INFO:Creating metrics dataframe
2026-02-02 16:49:03,249:INFO:Initializing Random Forest Regressor
2026-02-02 16:49:03,249:INFO:Total runtime is 0.045859491825103765 minutes
2026-02-02 16:49:03,249:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:03,249:INFO:Initializing create_model()
2026-02-02 16:49:03,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:03,249:INFO:Checking exceptions
2026-02-02 16:49:03,249:INFO:Importing libraries
2026-02-02 16:49:03,249:INFO:Copying training dataset
2026-02-02 16:49:03,254:INFO:Defining folds
2026-02-02 16:49:03,254:INFO:Declaring metric variables
2026-02-02 16:49:03,254:INFO:Importing untrained model
2026-02-02 16:49:03,255:INFO:Random Forest Regressor Imported successfully
2026-02-02 16:49:03,255:INFO:Starting cross validation
2026-02-02 16:49:03,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:03,781:INFO:Calculating mean and std
2026-02-02 16:49:03,782:INFO:Creating metrics dataframe
2026-02-02 16:49:03,784:INFO:Uploading results into container
2026-02-02 16:49:03,785:INFO:Uploading model into container now
2026-02-02 16:49:03,785:INFO:_master_model_container: 13
2026-02-02 16:49:03,785:INFO:_display_container: 2
2026-02-02 16:49:03,786:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=6994, verbose=0, warm_start=False)
2026-02-02 16:49:03,786:INFO:create_model() successfully completed......................................
2026-02-02 16:49:03,910:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:03,910:INFO:Creating metrics dataframe
2026-02-02 16:49:03,913:INFO:Initializing Extra Trees Regressor
2026-02-02 16:49:03,913:INFO:Total runtime is 0.056921672821044926 minutes
2026-02-02 16:49:03,913:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:03,914:INFO:Initializing create_model()
2026-02-02 16:49:03,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:03,914:INFO:Checking exceptions
2026-02-02 16:49:03,914:INFO:Importing libraries
2026-02-02 16:49:03,914:INFO:Copying training dataset
2026-02-02 16:49:03,920:INFO:Defining folds
2026-02-02 16:49:03,920:INFO:Declaring metric variables
2026-02-02 16:49:03,920:INFO:Importing untrained model
2026-02-02 16:49:03,921:INFO:Extra Trees Regressor Imported successfully
2026-02-02 16:49:03,921:INFO:Starting cross validation
2026-02-02 16:49:03,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:04,316:INFO:Calculating mean and std
2026-02-02 16:49:04,316:INFO:Creating metrics dataframe
2026-02-02 16:49:04,321:INFO:Uploading results into container
2026-02-02 16:49:04,323:INFO:Uploading model into container now
2026-02-02 16:49:04,324:INFO:_master_model_container: 14
2026-02-02 16:49:04,324:INFO:_display_container: 2
2026-02-02 16:49:04,325:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=6994, verbose=0, warm_start=False)
2026-02-02 16:49:04,325:INFO:create_model() successfully completed......................................
2026-02-02 16:49:04,447:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:04,447:INFO:Creating metrics dataframe
2026-02-02 16:49:04,450:INFO:Initializing AdaBoost Regressor
2026-02-02 16:49:04,450:INFO:Total runtime is 0.06586733261744182 minutes
2026-02-02 16:49:04,450:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:04,451:INFO:Initializing create_model()
2026-02-02 16:49:04,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:04,451:INFO:Checking exceptions
2026-02-02 16:49:04,451:INFO:Importing libraries
2026-02-02 16:49:04,451:INFO:Copying training dataset
2026-02-02 16:49:04,455:INFO:Defining folds
2026-02-02 16:49:04,456:INFO:Declaring metric variables
2026-02-02 16:49:04,456:INFO:Importing untrained model
2026-02-02 16:49:04,456:INFO:AdaBoost Regressor Imported successfully
2026-02-02 16:49:04,457:INFO:Starting cross validation
2026-02-02 16:49:04,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:04,703:INFO:Calculating mean and std
2026-02-02 16:49:04,704:INFO:Creating metrics dataframe
2026-02-02 16:49:04,706:INFO:Uploading results into container
2026-02-02 16:49:04,706:INFO:Uploading model into container now
2026-02-02 16:49:04,707:INFO:_master_model_container: 15
2026-02-02 16:49:04,707:INFO:_display_container: 2
2026-02-02 16:49:04,707:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=6994)
2026-02-02 16:49:04,707:INFO:create_model() successfully completed......................................
2026-02-02 16:49:04,823:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:04,823:INFO:Creating metrics dataframe
2026-02-02 16:49:04,826:INFO:Initializing Gradient Boosting Regressor
2026-02-02 16:49:04,827:INFO:Total runtime is 0.07214893500010174 minutes
2026-02-02 16:49:04,827:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:04,827:INFO:Initializing create_model()
2026-02-02 16:49:04,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:04,827:INFO:Checking exceptions
2026-02-02 16:49:04,827:INFO:Importing libraries
2026-02-02 16:49:04,827:INFO:Copying training dataset
2026-02-02 16:49:04,832:INFO:Defining folds
2026-02-02 16:49:04,832:INFO:Declaring metric variables
2026-02-02 16:49:04,833:INFO:Importing untrained model
2026-02-02 16:49:04,833:INFO:Gradient Boosting Regressor Imported successfully
2026-02-02 16:49:04,833:INFO:Starting cross validation
2026-02-02 16:49:04,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:05,106:INFO:Calculating mean and std
2026-02-02 16:49:05,106:INFO:Creating metrics dataframe
2026-02-02 16:49:05,108:INFO:Uploading results into container
2026-02-02 16:49:05,109:INFO:Uploading model into container now
2026-02-02 16:49:05,109:INFO:_master_model_container: 16
2026-02-02 16:49:05,109:INFO:_display_container: 2
2026-02-02 16:49:05,110:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=6994, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2026-02-02 16:49:05,110:INFO:create_model() successfully completed......................................
2026-02-02 16:49:05,226:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:05,227:INFO:Creating metrics dataframe
2026-02-02 16:49:05,230:INFO:Initializing Extreme Gradient Boosting
2026-02-02 16:49:05,230:INFO:Total runtime is 0.07886540492375693 minutes
2026-02-02 16:49:05,230:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:05,231:INFO:Initializing create_model()
2026-02-02 16:49:05,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:05,231:INFO:Checking exceptions
2026-02-02 16:49:05,231:INFO:Importing libraries
2026-02-02 16:49:05,231:INFO:Copying training dataset
2026-02-02 16:49:05,236:INFO:Defining folds
2026-02-02 16:49:05,236:INFO:Declaring metric variables
2026-02-02 16:49:05,237:INFO:Importing untrained model
2026-02-02 16:49:05,238:INFO:Extreme Gradient Boosting Imported successfully
2026-02-02 16:49:05,238:INFO:Starting cross validation
2026-02-02 16:49:05,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:05,844:INFO:Calculating mean and std
2026-02-02 16:49:05,845:INFO:Creating metrics dataframe
2026-02-02 16:49:05,847:INFO:Uploading results into container
2026-02-02 16:49:05,848:INFO:Uploading model into container now
2026-02-02 16:49:05,848:INFO:_master_model_container: 17
2026-02-02 16:49:05,849:INFO:_display_container: 2
2026-02-02 16:49:05,850:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2026-02-02 16:49:05,850:INFO:create_model() successfully completed......................................
2026-02-02 16:49:05,978:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:05,978:INFO:Creating metrics dataframe
2026-02-02 16:49:05,981:INFO:Initializing Light Gradient Boosting Machine
2026-02-02 16:49:05,981:INFO:Total runtime is 0.09138683875401817 minutes
2026-02-02 16:49:05,981:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:05,982:INFO:Initializing create_model()
2026-02-02 16:49:05,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:05,982:INFO:Checking exceptions
2026-02-02 16:49:05,982:INFO:Importing libraries
2026-02-02 16:49:05,982:INFO:Copying training dataset
2026-02-02 16:49:05,986:INFO:Defining folds
2026-02-02 16:49:05,987:INFO:Declaring metric variables
2026-02-02 16:49:05,987:INFO:Importing untrained model
2026-02-02 16:49:05,988:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-02 16:49:05,988:INFO:Starting cross validation
2026-02-02 16:49:05,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:06,885:INFO:Calculating mean and std
2026-02-02 16:49:06,886:INFO:Creating metrics dataframe
2026-02-02 16:49:06,889:INFO:Uploading results into container
2026-02-02 16:49:06,890:INFO:Uploading model into container now
2026-02-02 16:49:06,891:INFO:_master_model_container: 18
2026-02-02 16:49:06,891:INFO:_display_container: 2
2026-02-02 16:49:06,892:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=6994, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2026-02-02 16:49:06,892:INFO:create_model() successfully completed......................................
2026-02-02 16:49:07,026:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:07,026:INFO:Creating metrics dataframe
2026-02-02 16:49:07,032:INFO:Initializing CatBoost Regressor
2026-02-02 16:49:07,032:INFO:Total runtime is 0.10890575647354128 minutes
2026-02-02 16:49:07,032:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:07,034:INFO:Initializing create_model()
2026-02-02 16:49:07,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:07,034:INFO:Checking exceptions
2026-02-02 16:49:07,034:INFO:Importing libraries
2026-02-02 16:49:07,034:INFO:Copying training dataset
2026-02-02 16:49:07,039:INFO:Defining folds
2026-02-02 16:49:07,039:INFO:Declaring metric variables
2026-02-02 16:49:07,040:INFO:Importing untrained model
2026-02-02 16:49:07,040:INFO:CatBoost Regressor Imported successfully
2026-02-02 16:49:07,040:INFO:Starting cross validation
2026-02-02 16:49:07,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:15,603:INFO:Calculating mean and std
2026-02-02 16:49:15,604:INFO:Creating metrics dataframe
2026-02-02 16:49:15,607:INFO:Uploading results into container
2026-02-02 16:49:15,608:INFO:Uploading model into container now
2026-02-02 16:49:15,608:INFO:_master_model_container: 19
2026-02-02 16:49:15,608:INFO:_display_container: 2
2026-02-02 16:49:15,608:INFO:<catboost.core.CatBoostRegressor object at 0x0000020A9BC15C90>
2026-02-02 16:49:15,609:INFO:create_model() successfully completed......................................
2026-02-02 16:49:15,729:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:15,730:INFO:Creating metrics dataframe
2026-02-02 16:49:15,734:INFO:Initializing Dummy Regressor
2026-02-02 16:49:15,734:INFO:Total runtime is 0.25394140481948857 minutes
2026-02-02 16:49:15,734:INFO:SubProcess create_model() called ==================================
2026-02-02 16:49:15,734:INFO:Initializing create_model()
2026-02-02 16:49:15,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020A9BE480D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:15,735:INFO:Checking exceptions
2026-02-02 16:49:15,735:INFO:Importing libraries
2026-02-02 16:49:15,735:INFO:Copying training dataset
2026-02-02 16:49:15,740:INFO:Defining folds
2026-02-02 16:49:15,740:INFO:Declaring metric variables
2026-02-02 16:49:15,740:INFO:Importing untrained model
2026-02-02 16:49:15,741:INFO:Dummy Regressor Imported successfully
2026-02-02 16:49:15,741:INFO:Starting cross validation
2026-02-02 16:49:15,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-02 16:49:15,807:INFO:Calculating mean and std
2026-02-02 16:49:15,808:INFO:Creating metrics dataframe
2026-02-02 16:49:15,809:INFO:Uploading results into container
2026-02-02 16:49:15,810:INFO:Uploading model into container now
2026-02-02 16:49:15,810:INFO:_master_model_container: 20
2026-02-02 16:49:15,810:INFO:_display_container: 2
2026-02-02 16:49:15,811:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2026-02-02 16:49:15,811:INFO:create_model() successfully completed......................................
2026-02-02 16:49:15,922:INFO:SubProcess create_model() end ==================================
2026-02-02 16:49:15,923:INFO:Creating metrics dataframe
2026-02-02 16:49:15,926:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2026-02-02 16:49:15,928:INFO:Initializing create_model()
2026-02-02 16:49:15,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020A9BF0F050>, estimator=<catboost.core.CatBoostRegressor object at 0x0000020A9BC15C90>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-02 16:49:15,928:INFO:Checking exceptions
2026-02-02 16:49:15,929:INFO:Importing libraries
2026-02-02 16:49:15,929:INFO:Copying training dataset
2026-02-02 16:49:15,933:INFO:Defining folds
2026-02-02 16:49:15,933:INFO:Declaring metric variables
2026-02-02 16:49:15,933:INFO:Importing untrained model
2026-02-02 16:49:15,933:INFO:Declaring custom model
2026-02-02 16:49:15,934:INFO:CatBoost Regressor Imported successfully
2026-02-02 16:49:15,935:INFO:Cross validation set to False
2026-02-02 16:49:15,935:INFO:Fitting Model
2026-02-02 16:49:17,761:INFO:<catboost.core.CatBoostRegressor object at 0x0000020A9BD60B50>
2026-02-02 16:49:17,761:INFO:create_model() successfully completed......................................
2026-02-02 16:49:17,887:INFO:_master_model_container: 20
2026-02-02 16:49:17,887:INFO:_display_container: 2
2026-02-02 16:49:17,888:INFO:<catboost.core.CatBoostRegressor object at 0x0000020A9BD60B50>
2026-02-02 16:49:17,888:INFO:compare_models() successfully completed......................................
2026-02-02 16:49:17,892:INFO:Initializing save_model()
2026-02-02 16:49:17,892:INFO:save_model(model=<catboost.core.CatBoostRegressor object at 0x0000020A9BD60B50>, model_name=models\HousingData_regression_auto, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2026-02-02 16:49:17,892:INFO:Adding model into prep_pipe
2026-02-02 16:49:17,899:INFO:models\HousingData_regression_auto.pkl saved in current working directory
2026-02-02 16:49:17,903:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 <catboost.core.CatBoostRegressor object at 0x0000020A9BD60B50>)],
         verbose=False)
2026-02-02 16:49:17,903:INFO:save_model() successfully completed......................................
2026-02-03 10:15:06,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:15:06,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:15:06,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:15:06,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:15:12,766:INFO:PyCaret RegressionExperiment
2026-02-03 10:15:12,766:INFO:Logging name: reg-default-name
2026-02-03 10:15:12,766:INFO:ML Usecase: MLUsecase.REGRESSION
2026-02-03 10:15:12,767:INFO:version 3.3.2
2026-02-03 10:15:12,767:INFO:Initializing setup()
2026-02-03 10:15:12,767:INFO:self.USI: ff1c
2026-02-03 10:15:12,767:INFO:self._variable_keys: {'X_test', 'y', 'X', 'y_train', 'idx', 'logging_param', 'seed', 'memory', 'exp_name_log', 'fold_groups_param', 'data', 'target_param', 'USI', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'exp_id', 'transform_target_param', 'fold_generator', 'log_plots_param', '_available_plots', 'html_param', 'y_test', 'fold_shuffle_param', 'pipeline', 'gpu_param', '_ml_usecase'}
2026-02-03 10:15:12,767:INFO:Checking environment
2026-02-03 10:15:12,767:INFO:python_version: 3.11.9
2026-02-03 10:15:12,767:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 10:15:12,767:INFO:machine: AMD64
2026-02-03 10:15:12,807:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 10:15:12,807:INFO:Memory: svmem(total=16866873344, available=2415759360, percent=85.7, used=14451113984, free=2415759360)
2026-02-03 10:15:12,807:INFO:Physical Core: 8
2026-02-03 10:15:12,807:INFO:Logical Core: 16
2026-02-03 10:15:12,808:INFO:Checking libraries
2026-02-03 10:15:12,808:INFO:System:
2026-02-03 10:15:12,808:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 10:15:12,808:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 10:15:12,808:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 10:15:12,808:INFO:PyCaret required dependencies:
2026-02-03 10:15:13,036:INFO:                 pip: 24.0
2026-02-03 10:15:13,036:INFO:          setuptools: 80.9.0
2026-02-03 10:15:13,036:INFO:             pycaret: 3.3.2
2026-02-03 10:15:13,036:INFO:             IPython: 9.8.0
2026-02-03 10:15:13,036:INFO:          ipywidgets: 8.1.8
2026-02-03 10:15:13,036:INFO:                tqdm: 4.67.1
2026-02-03 10:15:13,036:INFO:               numpy: 1.26.4
2026-02-03 10:15:13,036:INFO:              pandas: 2.1.4
2026-02-03 10:15:13,036:INFO:              jinja2: 3.1.6
2026-02-03 10:15:13,037:INFO:               scipy: 1.11.4
2026-02-03 10:15:13,037:INFO:              joblib: 1.3.2
2026-02-03 10:15:13,037:INFO:             sklearn: 1.4.2
2026-02-03 10:15:13,037:INFO:                pyod: 2.0.6
2026-02-03 10:15:13,037:INFO:            imblearn: 0.14.1
2026-02-03 10:15:13,037:INFO:   category_encoders: 2.7.0
2026-02-03 10:15:13,037:INFO:            lightgbm: 4.6.0
2026-02-03 10:15:13,037:INFO:               numba: 0.63.1
2026-02-03 10:15:13,037:INFO:            requests: 2.32.5
2026-02-03 10:15:13,037:INFO:          matplotlib: 3.7.5
2026-02-03 10:15:13,037:INFO:          scikitplot: 0.3.7
2026-02-03 10:15:13,037:INFO:         yellowbrick: 1.5
2026-02-03 10:15:13,037:INFO:              plotly: 6.5.0
2026-02-03 10:15:13,037:INFO:    plotly-resampler: Not installed
2026-02-03 10:15:13,037:INFO:             kaleido: 1.2.0
2026-02-03 10:15:13,037:INFO:           schemdraw: 0.15
2026-02-03 10:15:13,037:INFO:         statsmodels: 0.14.6
2026-02-03 10:15:13,037:INFO:              sktime: 0.26.0
2026-02-03 10:15:13,037:INFO:               tbats: 1.1.3
2026-02-03 10:15:13,037:INFO:            pmdarima: 2.0.4
2026-02-03 10:15:13,037:INFO:              psutil: 7.1.3
2026-02-03 10:15:13,037:INFO:          markupsafe: 3.0.3
2026-02-03 10:15:13,037:INFO:             pickle5: Not installed
2026-02-03 10:15:13,038:INFO:         cloudpickle: 3.1.2
2026-02-03 10:15:13,038:INFO:         deprecation: 2.1.0
2026-02-03 10:15:13,038:INFO:              xxhash: 3.6.0
2026-02-03 10:15:13,038:INFO:           wurlitzer: Not installed
2026-02-03 10:15:13,038:INFO:PyCaret optional dependencies:
2026-02-03 10:15:15,225:INFO:                shap: Not installed
2026-02-03 10:15:15,226:INFO:           interpret: Not installed
2026-02-03 10:15:15,226:INFO:                umap: Not installed
2026-02-03 10:15:15,226:INFO:     ydata_profiling: Not installed
2026-02-03 10:15:15,226:INFO:  explainerdashboard: Not installed
2026-02-03 10:15:15,226:INFO:             autoviz: Not installed
2026-02-03 10:15:15,226:INFO:           fairlearn: Not installed
2026-02-03 10:15:15,226:INFO:          deepchecks: Not installed
2026-02-03 10:15:15,226:INFO:             xgboost: 3.1.2
2026-02-03 10:15:15,226:INFO:            catboost: 1.2.8
2026-02-03 10:15:15,226:INFO:              kmodes: Not installed
2026-02-03 10:15:15,226:INFO:             mlxtend: Not installed
2026-02-03 10:15:15,226:INFO:       statsforecast: Not installed
2026-02-03 10:15:15,226:INFO:        tune_sklearn: Not installed
2026-02-03 10:15:15,226:INFO:                 ray: Not installed
2026-02-03 10:15:15,226:INFO:            hyperopt: Not installed
2026-02-03 10:15:15,226:INFO:              optuna: 4.6.0
2026-02-03 10:15:15,226:INFO:               skopt: Not installed
2026-02-03 10:15:15,226:INFO:              mlflow: Not installed
2026-02-03 10:15:15,226:INFO:              gradio: Not installed
2026-02-03 10:15:15,227:INFO:             fastapi: 0.123.10
2026-02-03 10:15:15,227:INFO:             uvicorn: 0.38.0
2026-02-03 10:15:15,227:INFO:              m2cgen: Not installed
2026-02-03 10:15:15,227:INFO:           evidently: Not installed
2026-02-03 10:15:15,227:INFO:               fugue: Not installed
2026-02-03 10:15:15,227:INFO:           streamlit: Not installed
2026-02-03 10:15:15,227:INFO:             prophet: Not installed
2026-02-03 10:15:15,227:INFO:None
2026-02-03 10:15:15,227:INFO:Set up data.
2026-02-03 10:15:15,239:INFO:Set up folding strategy.
2026-02-03 10:15:15,239:INFO:Set up train/test split.
2026-02-03 10:15:15,300:INFO:Set up index.
2026-02-03 10:15:15,300:INFO:Assigning column types.
2026-02-03 10:15:15,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 10:15:15,305:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:15:15,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:15:15,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:15,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:15,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:15,455:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:15,459:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:18,638:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,648:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,658:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,863:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:18,867:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:18,868:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2026-02-03 10:15:18,874:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:18,957:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,020:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,024:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,031:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,204:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,205:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,208:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,209:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2026-02-03 10:15:19,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,402:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,407:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,504:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,571:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,577:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,577:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2026-02-03 10:15:19,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,748:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,749:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,753:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:15:19,912:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:19,915:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:19,916:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 10:15:20,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:20,106:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:20,109:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:20,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:15:20,283:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:20,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:20,287:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2026-02-03 10:15:20,443:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:20,447:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:20,621:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:20,625:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:20,628:INFO:Preparing preprocessing pipeline...
2026-02-03 10:15:20,628:INFO:Set up simple imputation.
2026-02-03 10:15:20,640:INFO:Set up encoding of ordinal features.
2026-02-03 10:15:20,642:INFO:Set up encoding of categorical features.
2026-02-03 10:15:20,727:INFO:Finished creating preprocessing pipeline.
2026-02-03 10:15:20,768:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=OrdinalEncoder(cols=['Age_Group'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Age_Group',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Mature    0
Young     1
NaN      -1
dtype: int64}])))])
2026-02-03 10:15:20,768:INFO:Creating final display dataframe.
2026-02-03 10:15:20,954:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              MEDV
2                   Target type        Regression
3           Original data shape         (243, 15)
4        Transformed data shape         (243, 15)
5   Transformed train set shape         (170, 15)
6    Transformed test set shape          (73, 15)
7              Numeric features                13
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              ff1c
2026-02-03 10:15:21,129:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:21,133:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:21,294:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:15:21,297:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:15:21,298:INFO:setup() successfully completed in 8.54s...............
2026-02-03 10:15:21,299:INFO:Initializing create_model()
2026-02-03 10:15:21,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EAC0809390>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:15:21,299:INFO:Checking exceptions
2026-02-03 10:15:21,300:INFO:Importing libraries
2026-02-03 10:15:21,301:INFO:Copying training dataset
2026-02-03 10:15:21,305:INFO:Defining folds
2026-02-03 10:15:21,306:INFO:Declaring metric variables
2026-02-03 10:15:21,306:INFO:Importing untrained model
2026-02-03 10:15:21,306:INFO:Linear Regression Imported successfully
2026-02-03 10:15:21,307:INFO:Starting cross validation
2026-02-03 10:15:21,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:15:26,971:INFO:Calculating mean and std
2026-02-03 10:15:26,973:INFO:Creating metrics dataframe
2026-02-03 10:15:26,977:INFO:Finalizing model
2026-02-03 10:15:27,026:INFO:Uploading results into container
2026-02-03 10:15:27,027:INFO:Uploading model into container now
2026-02-03 10:15:27,028:INFO:_master_model_container: 1
2026-02-03 10:15:27,028:INFO:_display_container: 2
2026-02-03 10:15:27,029:INFO:LinearRegression(n_jobs=-1)
2026-02-03 10:15:27,029:INFO:create_model() successfully completed......................................
2026-02-03 10:15:27,193:INFO:Initializing create_model()
2026-02-03 10:15:27,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EAC0809390>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:15:27,193:INFO:Checking exceptions
2026-02-03 10:15:27,194:INFO:Importing libraries
2026-02-03 10:15:27,195:INFO:Copying training dataset
2026-02-03 10:15:27,199:INFO:Defining folds
2026-02-03 10:15:27,199:INFO:Declaring metric variables
2026-02-03 10:15:27,199:INFO:Importing untrained model
2026-02-03 10:15:27,200:INFO:Decision Tree Regressor Imported successfully
2026-02-03 10:15:27,200:INFO:Starting cross validation
2026-02-03 10:15:27,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:15:32,185:INFO:Calculating mean and std
2026-02-03 10:15:32,185:INFO:Creating metrics dataframe
2026-02-03 10:15:32,189:INFO:Finalizing model
2026-02-03 10:15:32,232:INFO:Uploading results into container
2026-02-03 10:15:32,233:INFO:Uploading model into container now
2026-02-03 10:15:32,234:INFO:_master_model_container: 2
2026-02-03 10:15:32,234:INFO:_display_container: 3
2026-02-03 10:15:32,234:INFO:DecisionTreeRegressor(random_state=123)
2026-02-03 10:15:32,234:INFO:create_model() successfully completed......................................
2026-02-03 10:15:32,386:INFO:Initializing create_model()
2026-02-03 10:15:32,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EAC0809390>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:15:32,386:INFO:Checking exceptions
2026-02-03 10:15:32,388:INFO:Importing libraries
2026-02-03 10:15:32,388:INFO:Copying training dataset
2026-02-03 10:15:32,393:INFO:Defining folds
2026-02-03 10:15:32,393:INFO:Declaring metric variables
2026-02-03 10:15:32,393:INFO:Importing untrained model
2026-02-03 10:15:32,394:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-03 10:15:32,394:INFO:Starting cross validation
2026-02-03 10:15:32,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:15:33,915:INFO:Calculating mean and std
2026-02-03 10:15:33,916:INFO:Creating metrics dataframe
2026-02-03 10:15:33,920:INFO:Finalizing model
2026-02-03 10:15:33,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2026-02-03 10:15:33,983:INFO:You can set `force_col_wise=true` to remove the overhead.
2026-02-03 10:15:33,984:INFO:[LightGBM] [Info] Total Bins 463
2026-02-03 10:15:33,985:INFO:[LightGBM] [Info] Number of data points in the train set: 170, number of used features: 12
2026-02-03 10:15:33,987:INFO:[LightGBM] [Info] Start training from score 22.974706
2026-02-03 10:15:33,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:33,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:15:34,099:INFO:Uploading results into container
2026-02-03 10:15:34,100:INFO:Uploading model into container now
2026-02-03 10:15:34,101:INFO:_master_model_container: 3
2026-02-03 10:15:34,101:INFO:_display_container: 4
2026-02-03 10:15:34,102:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2026-02-03 10:15:34,102:INFO:create_model() successfully completed......................................
2026-02-03 10:38:11,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:38:11,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:38:11,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:38:11,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:38:15,867:INFO:PyCaret RegressionExperiment
2026-02-03 10:38:15,867:INFO:Logging name: reg-default-name
2026-02-03 10:38:15,867:INFO:ML Usecase: MLUsecase.REGRESSION
2026-02-03 10:38:15,867:INFO:version 3.3.2
2026-02-03 10:38:15,867:INFO:Initializing setup()
2026-02-03 10:38:15,867:INFO:self.USI: 444c
2026-02-03 10:38:15,867:INFO:self._variable_keys: {'target_param', 'fold_generator', 'exp_id', 'html_param', 'gpu_n_jobs_param', 'y_train', 'data', '_available_plots', 'transform_target_param', 'memory', 'X_test', 'exp_name_log', 'idx', 'logging_param', 'log_plots_param', '_ml_usecase', 'seed', 'X_train', 'gpu_param', 'fold_groups_param', 'USI', 'X', 'y', 'n_jobs_param', 'pipeline', 'fold_shuffle_param', 'y_test'}
2026-02-03 10:38:15,867:INFO:Checking environment
2026-02-03 10:38:15,867:INFO:python_version: 3.11.9
2026-02-03 10:38:15,867:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 10:38:15,868:INFO:machine: AMD64
2026-02-03 10:38:15,881:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 10:38:15,881:INFO:Memory: svmem(total=16866873344, available=2464759808, percent=85.4, used=14402113536, free=2464759808)
2026-02-03 10:38:15,881:INFO:Physical Core: 8
2026-02-03 10:38:15,881:INFO:Logical Core: 16
2026-02-03 10:38:15,881:INFO:Checking libraries
2026-02-03 10:38:15,881:INFO:System:
2026-02-03 10:38:15,881:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 10:38:15,882:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 10:38:15,882:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 10:38:15,882:INFO:PyCaret required dependencies:
2026-02-03 10:38:15,988:INFO:                 pip: 24.0
2026-02-03 10:38:15,988:INFO:          setuptools: 80.9.0
2026-02-03 10:38:15,988:INFO:             pycaret: 3.3.2
2026-02-03 10:38:15,988:INFO:             IPython: 9.8.0
2026-02-03 10:38:15,988:INFO:          ipywidgets: 8.1.8
2026-02-03 10:38:15,988:INFO:                tqdm: 4.67.1
2026-02-03 10:38:15,989:INFO:               numpy: 1.26.4
2026-02-03 10:38:15,989:INFO:              pandas: 2.1.4
2026-02-03 10:38:15,989:INFO:              jinja2: 3.1.6
2026-02-03 10:38:15,989:INFO:               scipy: 1.11.4
2026-02-03 10:38:15,989:INFO:              joblib: 1.3.2
2026-02-03 10:38:15,989:INFO:             sklearn: 1.4.2
2026-02-03 10:38:15,989:INFO:                pyod: 2.0.6
2026-02-03 10:38:15,989:INFO:            imblearn: 0.14.1
2026-02-03 10:38:15,989:INFO:   category_encoders: 2.7.0
2026-02-03 10:38:15,989:INFO:            lightgbm: 4.6.0
2026-02-03 10:38:15,989:INFO:               numba: 0.63.1
2026-02-03 10:38:15,989:INFO:            requests: 2.32.5
2026-02-03 10:38:15,989:INFO:          matplotlib: 3.7.5
2026-02-03 10:38:15,989:INFO:          scikitplot: 0.3.7
2026-02-03 10:38:15,989:INFO:         yellowbrick: 1.5
2026-02-03 10:38:15,989:INFO:              plotly: 6.5.0
2026-02-03 10:38:15,989:INFO:    plotly-resampler: Not installed
2026-02-03 10:38:15,989:INFO:             kaleido: 1.2.0
2026-02-03 10:38:15,989:INFO:           schemdraw: 0.15
2026-02-03 10:38:15,989:INFO:         statsmodels: 0.14.6
2026-02-03 10:38:15,989:INFO:              sktime: 0.26.0
2026-02-03 10:38:15,989:INFO:               tbats: 1.1.3
2026-02-03 10:38:15,990:INFO:            pmdarima: 2.0.4
2026-02-03 10:38:15,990:INFO:              psutil: 7.1.3
2026-02-03 10:38:15,990:INFO:          markupsafe: 3.0.3
2026-02-03 10:38:15,990:INFO:             pickle5: Not installed
2026-02-03 10:38:15,990:INFO:         cloudpickle: 3.1.2
2026-02-03 10:38:15,990:INFO:         deprecation: 2.1.0
2026-02-03 10:38:15,990:INFO:              xxhash: 3.6.0
2026-02-03 10:38:15,990:INFO:           wurlitzer: Not installed
2026-02-03 10:38:15,990:INFO:PyCaret optional dependencies:
2026-02-03 10:38:16,656:INFO:                shap: Not installed
2026-02-03 10:38:16,656:INFO:           interpret: Not installed
2026-02-03 10:38:16,656:INFO:                umap: Not installed
2026-02-03 10:38:16,656:INFO:     ydata_profiling: Not installed
2026-02-03 10:38:16,656:INFO:  explainerdashboard: Not installed
2026-02-03 10:38:16,656:INFO:             autoviz: Not installed
2026-02-03 10:38:16,656:INFO:           fairlearn: Not installed
2026-02-03 10:38:16,656:INFO:          deepchecks: Not installed
2026-02-03 10:38:16,656:INFO:             xgboost: 3.1.2
2026-02-03 10:38:16,656:INFO:            catboost: 1.2.8
2026-02-03 10:38:16,656:INFO:              kmodes: Not installed
2026-02-03 10:38:16,656:INFO:             mlxtend: Not installed
2026-02-03 10:38:16,656:INFO:       statsforecast: Not installed
2026-02-03 10:38:16,656:INFO:        tune_sklearn: Not installed
2026-02-03 10:38:16,656:INFO:                 ray: Not installed
2026-02-03 10:38:16,656:INFO:            hyperopt: Not installed
2026-02-03 10:38:16,656:INFO:              optuna: 4.6.0
2026-02-03 10:38:16,656:INFO:               skopt: Not installed
2026-02-03 10:38:16,656:INFO:              mlflow: Not installed
2026-02-03 10:38:16,656:INFO:              gradio: Not installed
2026-02-03 10:38:16,656:INFO:             fastapi: 0.123.10
2026-02-03 10:38:16,656:INFO:             uvicorn: 0.38.0
2026-02-03 10:38:16,656:INFO:              m2cgen: Not installed
2026-02-03 10:38:16,657:INFO:           evidently: Not installed
2026-02-03 10:38:16,657:INFO:               fugue: Not installed
2026-02-03 10:38:16,657:INFO:           streamlit: Not installed
2026-02-03 10:38:16,657:INFO:             prophet: Not installed
2026-02-03 10:38:16,657:INFO:None
2026-02-03 10:38:16,657:INFO:Set up data.
2026-02-03 10:38:16,666:INFO:Set up folding strategy.
2026-02-03 10:38:16,666:INFO:Set up train/test split.
2026-02-03 10:38:16,675:INFO:Set up index.
2026-02-03 10:38:16,675:INFO:Assigning column types.
2026-02-03 10:38:16,680:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 10:38:16,680:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,831:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:16,834:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:16,878:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:16,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,024:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,027:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,028:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2026-02-03 10:38:17,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,040:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,174:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,177:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,322:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,325:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,326:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2026-02-03 10:38:17,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,411:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,472:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,476:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,563:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,622:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,625:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,626:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2026-02-03 10:38:17,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,773:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,776:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:38:17,920:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:17,923:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:17,924:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 10:38:18,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:18,069:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:18,072:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:18,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:38:18,216:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:18,220:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:18,220:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2026-02-03 10:38:18,363:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:18,367:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:18,510:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:18,514:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:18,516:INFO:Preparing preprocessing pipeline...
2026-02-03 10:38:18,516:INFO:Set up simple imputation.
2026-02-03 10:38:18,519:INFO:Set up encoding of ordinal features.
2026-02-03 10:38:18,521:INFO:Set up encoding of categorical features.
2026-02-03 10:38:18,578:INFO:Finished creating preprocessing pipeline.
2026-02-03 10:38:18,610:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=OrdinalEncoder(cols=['Age_Group'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Age_Group',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Old      0
Young    1
NaN     -1
dtype: int64}])))])
2026-02-03 10:38:18,610:INFO:Creating final display dataframe.
2026-02-03 10:38:18,767:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              MEDV
2                   Target type        Regression
3           Original data shape         (243, 15)
4        Transformed data shape         (243, 15)
5   Transformed train set shape         (170, 15)
6    Transformed test set shape          (73, 15)
7              Numeric features                13
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              444c
2026-02-03 10:38:18,911:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:18,915:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:19,060:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:38:19,063:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:38:19,064:INFO:setup() successfully completed in 3.2s...............
2026-02-03 10:38:19,065:INFO:Initializing create_model()
2026-02-03 10:38:19,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:38:19,065:INFO:Checking exceptions
2026-02-03 10:38:19,066:INFO:Importing libraries
2026-02-03 10:38:19,066:INFO:Copying training dataset
2026-02-03 10:38:19,071:INFO:Defining folds
2026-02-03 10:38:19,071:INFO:Declaring metric variables
2026-02-03 10:38:19,071:INFO:Importing untrained model
2026-02-03 10:38:19,072:INFO:Linear Regression Imported successfully
2026-02-03 10:38:19,072:INFO:Starting cross validation
2026-02-03 10:38:19,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:38:24,385:INFO:Calculating mean and std
2026-02-03 10:38:24,386:INFO:Creating metrics dataframe
2026-02-03 10:38:24,390:INFO:Finalizing model
2026-02-03 10:38:24,438:INFO:Uploading results into container
2026-02-03 10:38:24,439:INFO:Uploading model into container now
2026-02-03 10:38:24,439:INFO:_master_model_container: 1
2026-02-03 10:38:24,440:INFO:_display_container: 2
2026-02-03 10:38:24,440:INFO:LinearRegression(n_jobs=-1)
2026-02-03 10:38:24,440:INFO:create_model() successfully completed......................................
2026-02-03 10:38:24,588:INFO:Initializing create_model()
2026-02-03 10:38:24,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:38:24,588:INFO:Checking exceptions
2026-02-03 10:38:24,589:INFO:Importing libraries
2026-02-03 10:38:24,589:INFO:Copying training dataset
2026-02-03 10:38:24,594:INFO:Defining folds
2026-02-03 10:38:24,594:INFO:Declaring metric variables
2026-02-03 10:38:24,594:INFO:Importing untrained model
2026-02-03 10:38:24,594:INFO:Decision Tree Regressor Imported successfully
2026-02-03 10:38:24,595:INFO:Starting cross validation
2026-02-03 10:38:24,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:38:28,383:INFO:Calculating mean and std
2026-02-03 10:38:28,383:INFO:Creating metrics dataframe
2026-02-03 10:38:28,386:INFO:Finalizing model
2026-02-03 10:38:28,415:INFO:Uploading results into container
2026-02-03 10:38:28,416:INFO:Uploading model into container now
2026-02-03 10:38:28,416:INFO:_master_model_container: 2
2026-02-03 10:38:28,416:INFO:_display_container: 3
2026-02-03 10:38:28,417:INFO:DecisionTreeRegressor(random_state=123)
2026-02-03 10:38:28,417:INFO:create_model() successfully completed......................................
2026-02-03 10:38:28,556:INFO:Initializing create_model()
2026-02-03 10:38:28,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:38:28,556:INFO:Checking exceptions
2026-02-03 10:38:28,557:INFO:Importing libraries
2026-02-03 10:38:28,557:INFO:Copying training dataset
2026-02-03 10:38:28,562:INFO:Defining folds
2026-02-03 10:38:28,562:INFO:Declaring metric variables
2026-02-03 10:38:28,562:INFO:Importing untrained model
2026-02-03 10:38:28,563:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-03 10:38:28,564:INFO:Starting cross validation
2026-02-03 10:38:28,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:38:29,389:INFO:Calculating mean and std
2026-02-03 10:38:29,390:INFO:Creating metrics dataframe
2026-02-03 10:38:29,392:INFO:Finalizing model
2026-02-03 10:38:29,435:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2026-02-03 10:38:29,435:INFO:You can set `force_col_wise=true` to remove the overhead.
2026-02-03 10:38:29,436:INFO:[LightGBM] [Info] Total Bins 463
2026-02-03 10:38:29,437:INFO:[LightGBM] [Info] Number of data points in the train set: 170, number of used features: 12
2026-02-03 10:38:29,438:INFO:[LightGBM] [Info] Start training from score 22.974706
2026-02-03 10:38:29,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:38:29,507:INFO:Uploading results into container
2026-02-03 10:38:29,508:INFO:Uploading model into container now
2026-02-03 10:38:29,509:INFO:_master_model_container: 3
2026-02-03 10:38:29,509:INFO:_display_container: 4
2026-02-03 10:38:29,510:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2026-02-03 10:38:29,510:INFO:create_model() successfully completed......................................
2026-02-03 10:38:29,661:INFO:Initializing blend_models()
2026-02-03 10:38:29,661:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator_list=[LinearRegression(n_jobs=-1), DecisionTreeRegressor(random_state=123), LGBMRegressor(n_jobs=-1, random_state=123)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=False, return_train_score=False)
2026-02-03 10:38:29,661:INFO:Checking exceptions
2026-02-03 10:38:29,664:INFO:Importing libraries
2026-02-03 10:38:29,664:INFO:Copying training dataset
2026-02-03 10:38:29,664:INFO:Getting model names
2026-02-03 10:38:29,665:INFO:SubProcess create_model() called ==================================
2026-02-03 10:38:29,669:INFO:Initializing create_model()
2026-02-03 10:38:29,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator=VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D2CDBAA810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:38:29,669:INFO:Checking exceptions
2026-02-03 10:38:29,669:INFO:Importing libraries
2026-02-03 10:38:29,669:INFO:Copying training dataset
2026-02-03 10:38:29,673:INFO:Defining folds
2026-02-03 10:38:29,673:INFO:Declaring metric variables
2026-02-03 10:38:29,674:INFO:Importing untrained model
2026-02-03 10:38:29,674:INFO:Declaring custom model
2026-02-03 10:38:29,676:INFO:Voting Regressor Imported successfully
2026-02-03 10:38:29,676:INFO:Starting cross validation
2026-02-03 10:38:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:38:30,720:INFO:Calculating mean and std
2026-02-03 10:38:30,721:INFO:Creating metrics dataframe
2026-02-03 10:38:30,724:INFO:Finalizing model
2026-02-03 10:38:30,867:INFO:Uploading results into container
2026-02-03 10:38:30,869:INFO:Uploading model into container now
2026-02-03 10:38:30,870:INFO:_master_model_container: 4
2026-02-03 10:38:30,870:INFO:_display_container: 5
2026-02-03 10:38:30,877:INFO:VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1)
2026-02-03 10:38:30,877:INFO:create_model() successfully completed......................................
2026-02-03 10:38:31,025:INFO:SubProcess create_model() end ==================================
2026-02-03 10:38:31,025:INFO:_master_model_container: 4
2026-02-03 10:38:31,026:INFO:_display_container: 5
2026-02-03 10:38:31,031:INFO:VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1)
2026-02-03 10:38:31,031:INFO:blend_models() successfully completed......................................
2026-02-03 10:38:31,164:INFO:Initializing predict_model()
2026-02-03 10:38:31,164:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, estimator=VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D2F6264F40>)
2026-02-03 10:38:31,164:INFO:Checking exceptions
2026-02-03 10:38:31,164:INFO:Preloading libraries
2026-02-03 10:38:31,402:INFO:Initializing get_config()
2026-02-03 10:38:31,403:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D2F53A7410>, variable=target_param)
2026-02-03 10:38:31,403:INFO:Variable:  returned as MEDV
2026-02-03 10:38:31,403:INFO:get_config() successfully completed......................................
2026-02-03 10:50:47,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:50:47,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:50:47,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:50:47,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 10:50:50,948:INFO:PyCaret RegressionExperiment
2026-02-03 10:50:50,948:INFO:Logging name: reg-default-name
2026-02-03 10:50:50,949:INFO:ML Usecase: MLUsecase.REGRESSION
2026-02-03 10:50:50,949:INFO:version 3.3.2
2026-02-03 10:50:50,949:INFO:Initializing setup()
2026-02-03 10:50:50,949:INFO:self.USI: 6bc7
2026-02-03 10:50:50,949:INFO:self._variable_keys: {'gpu_param', 'html_param', 'USI', 'seed', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'fold_generator', '_ml_usecase', 'target_param', 'pipeline', '_available_plots', 'exp_name_log', 'y_train', 'gpu_n_jobs_param', 'idx', 'y_test', 'y', 'data', 'exp_id', 'X_test', 'transform_target_param', 'memory', 'X_train', 'fold_groups_param', 'log_plots_param', 'X'}
2026-02-03 10:50:50,949:INFO:Checking environment
2026-02-03 10:50:50,949:INFO:python_version: 3.11.9
2026-02-03 10:50:50,949:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 10:50:50,949:INFO:machine: AMD64
2026-02-03 10:50:50,963:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 10:50:50,963:INFO:Memory: svmem(total=16866873344, available=4418334720, percent=73.8, used=12448538624, free=4418334720)
2026-02-03 10:50:50,963:INFO:Physical Core: 8
2026-02-03 10:50:50,963:INFO:Logical Core: 16
2026-02-03 10:50:50,963:INFO:Checking libraries
2026-02-03 10:50:50,963:INFO:System:
2026-02-03 10:50:50,963:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 10:50:50,963:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 10:50:50,963:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 10:50:50,963:INFO:PyCaret required dependencies:
2026-02-03 10:50:51,072:INFO:                 pip: 24.0
2026-02-03 10:50:51,073:INFO:          setuptools: 80.9.0
2026-02-03 10:50:51,073:INFO:             pycaret: 3.3.2
2026-02-03 10:50:51,073:INFO:             IPython: 9.8.0
2026-02-03 10:50:51,073:INFO:          ipywidgets: 8.1.8
2026-02-03 10:50:51,073:INFO:                tqdm: 4.67.1
2026-02-03 10:50:51,073:INFO:               numpy: 1.26.4
2026-02-03 10:50:51,073:INFO:              pandas: 2.1.4
2026-02-03 10:50:51,073:INFO:              jinja2: 3.1.6
2026-02-03 10:50:51,073:INFO:               scipy: 1.11.4
2026-02-03 10:50:51,073:INFO:              joblib: 1.3.2
2026-02-03 10:50:51,073:INFO:             sklearn: 1.4.2
2026-02-03 10:50:51,073:INFO:                pyod: 2.0.6
2026-02-03 10:50:51,073:INFO:            imblearn: 0.14.1
2026-02-03 10:50:51,073:INFO:   category_encoders: 2.7.0
2026-02-03 10:50:51,073:INFO:            lightgbm: 4.6.0
2026-02-03 10:50:51,073:INFO:               numba: 0.63.1
2026-02-03 10:50:51,073:INFO:            requests: 2.32.5
2026-02-03 10:50:51,073:INFO:          matplotlib: 3.7.5
2026-02-03 10:50:51,073:INFO:          scikitplot: 0.3.7
2026-02-03 10:50:51,073:INFO:         yellowbrick: 1.5
2026-02-03 10:50:51,073:INFO:              plotly: 6.5.0
2026-02-03 10:50:51,074:INFO:    plotly-resampler: Not installed
2026-02-03 10:50:51,074:INFO:             kaleido: 1.2.0
2026-02-03 10:50:51,074:INFO:           schemdraw: 0.15
2026-02-03 10:50:51,074:INFO:         statsmodels: 0.14.6
2026-02-03 10:50:51,074:INFO:              sktime: 0.26.0
2026-02-03 10:50:51,074:INFO:               tbats: 1.1.3
2026-02-03 10:50:51,074:INFO:            pmdarima: 2.0.4
2026-02-03 10:50:51,074:INFO:              psutil: 7.1.3
2026-02-03 10:50:51,074:INFO:          markupsafe: 3.0.3
2026-02-03 10:50:51,074:INFO:             pickle5: Not installed
2026-02-03 10:50:51,074:INFO:         cloudpickle: 3.1.2
2026-02-03 10:50:51,074:INFO:         deprecation: 2.1.0
2026-02-03 10:50:51,074:INFO:              xxhash: 3.6.0
2026-02-03 10:50:51,074:INFO:           wurlitzer: Not installed
2026-02-03 10:50:51,074:INFO:PyCaret optional dependencies:
2026-02-03 10:50:51,734:INFO:                shap: Not installed
2026-02-03 10:50:51,734:INFO:           interpret: Not installed
2026-02-03 10:50:51,734:INFO:                umap: Not installed
2026-02-03 10:50:51,734:INFO:     ydata_profiling: Not installed
2026-02-03 10:50:51,734:INFO:  explainerdashboard: Not installed
2026-02-03 10:50:51,734:INFO:             autoviz: Not installed
2026-02-03 10:50:51,734:INFO:           fairlearn: Not installed
2026-02-03 10:50:51,734:INFO:          deepchecks: Not installed
2026-02-03 10:50:51,734:INFO:             xgboost: 3.1.2
2026-02-03 10:50:51,735:INFO:            catboost: 1.2.8
2026-02-03 10:50:51,735:INFO:              kmodes: Not installed
2026-02-03 10:50:51,735:INFO:             mlxtend: Not installed
2026-02-03 10:50:51,735:INFO:       statsforecast: Not installed
2026-02-03 10:50:51,735:INFO:        tune_sklearn: Not installed
2026-02-03 10:50:51,735:INFO:                 ray: Not installed
2026-02-03 10:50:51,735:INFO:            hyperopt: Not installed
2026-02-03 10:50:51,735:INFO:              optuna: 4.6.0
2026-02-03 10:50:51,735:INFO:               skopt: Not installed
2026-02-03 10:50:51,735:INFO:              mlflow: Not installed
2026-02-03 10:50:51,735:INFO:              gradio: Not installed
2026-02-03 10:50:51,735:INFO:             fastapi: 0.123.10
2026-02-03 10:50:51,735:INFO:             uvicorn: 0.38.0
2026-02-03 10:50:51,735:INFO:              m2cgen: Not installed
2026-02-03 10:50:51,735:INFO:           evidently: Not installed
2026-02-03 10:50:51,735:INFO:               fugue: Not installed
2026-02-03 10:50:51,735:INFO:           streamlit: Not installed
2026-02-03 10:50:51,735:INFO:             prophet: Not installed
2026-02-03 10:50:51,735:INFO:None
2026-02-03 10:50:51,735:INFO:Set up data.
2026-02-03 10:50:51,745:INFO:Set up folding strategy.
2026-02-03 10:50:51,745:INFO:Set up train/test split.
2026-02-03 10:50:51,753:INFO:Set up index.
2026-02-03 10:50:51,753:INFO:Assigning column types.
2026-02-03 10:50:51,758:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 10:50:51,758:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,764:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,916:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:51,920:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:51,962:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:50:51,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,126:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,129:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,130:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2026-02-03 10:50:52,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,284:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,287:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,294:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,436:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,441:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,442:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2026-02-03 10:50:52,454:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,591:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,594:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,740:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,744:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,745:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2026-02-03 10:50:52,832:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:52,891:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:52,894:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:52,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:53,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 10:50:53,040:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:53,043:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:53,044:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 10:50:53,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:53,189:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:53,192:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:53,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2026-02-03 10:50:53,339:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:53,343:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:53,344:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2026-02-03 10:50:53,489:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:53,493:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:53,636:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:53,640:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:53,643:INFO:Preparing preprocessing pipeline...
2026-02-03 10:50:53,643:INFO:Set up simple imputation.
2026-02-03 10:50:53,647:INFO:Set up encoding of ordinal features.
2026-02-03 10:50:53,649:INFO:Set up encoding of categorical features.
2026-02-03 10:50:53,701:INFO:Finished creating preprocessing pipeline.
2026-02-03 10:50:53,730:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['CRIM', 'ZN', 'INDUS', 'CHAS',
                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',
                                             'TAX', 'PTRATIO', 'B', 'LSTAT'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerWrapper(include=['Age_Group'],
                                    transformer=OrdinalEncoder(cols=['Age_Group'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'Age_Group',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Old      0
Young    1
NaN     -1
dtype: int64}])))])
2026-02-03 10:50:53,730:INFO:Creating final display dataframe.
2026-02-03 10:50:53,883:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              MEDV
2                   Target type        Regression
3           Original data shape         (243, 15)
4        Transformed data shape         (243, 15)
5   Transformed train set shape         (170, 15)
6    Transformed test set shape          (73, 15)
7              Numeric features                13
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              6bc7
2026-02-03 10:50:54,030:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:54,034:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:54,178:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 10:50:54,182:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 10:50:54,183:INFO:setup() successfully completed in 3.24s...............
2026-02-03 10:50:54,183:INFO:Initializing create_model()
2026-02-03 10:50:54,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:50:54,184:INFO:Checking exceptions
2026-02-03 10:50:54,185:INFO:Importing libraries
2026-02-03 10:50:54,185:INFO:Copying training dataset
2026-02-03 10:50:54,190:INFO:Defining folds
2026-02-03 10:50:54,190:INFO:Declaring metric variables
2026-02-03 10:50:54,190:INFO:Importing untrained model
2026-02-03 10:50:54,191:INFO:Linear Regression Imported successfully
2026-02-03 10:50:54,191:INFO:Starting cross validation
2026-02-03 10:50:54,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:50:59,557:INFO:Calculating mean and std
2026-02-03 10:50:59,558:INFO:Creating metrics dataframe
2026-02-03 10:50:59,564:INFO:Finalizing model
2026-02-03 10:50:59,617:INFO:Uploading results into container
2026-02-03 10:50:59,618:INFO:Uploading model into container now
2026-02-03 10:50:59,619:INFO:_master_model_container: 1
2026-02-03 10:50:59,619:INFO:_display_container: 2
2026-02-03 10:50:59,619:INFO:LinearRegression(n_jobs=-1)
2026-02-03 10:50:59,620:INFO:create_model() successfully completed......................................
2026-02-03 10:50:59,780:INFO:Initializing create_model()
2026-02-03 10:50:59,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:50:59,780:INFO:Checking exceptions
2026-02-03 10:50:59,781:INFO:Importing libraries
2026-02-03 10:50:59,781:INFO:Copying training dataset
2026-02-03 10:50:59,786:INFO:Defining folds
2026-02-03 10:50:59,786:INFO:Declaring metric variables
2026-02-03 10:50:59,786:INFO:Importing untrained model
2026-02-03 10:50:59,787:INFO:Decision Tree Regressor Imported successfully
2026-02-03 10:50:59,787:INFO:Starting cross validation
2026-02-03 10:50:59,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:51:03,642:INFO:Calculating mean and std
2026-02-03 10:51:03,643:INFO:Creating metrics dataframe
2026-02-03 10:51:03,645:INFO:Finalizing model
2026-02-03 10:51:03,681:INFO:Uploading results into container
2026-02-03 10:51:03,682:INFO:Uploading model into container now
2026-02-03 10:51:03,683:INFO:_master_model_container: 2
2026-02-03 10:51:03,683:INFO:_display_container: 3
2026-02-03 10:51:03,683:INFO:DecisionTreeRegressor(random_state=123)
2026-02-03 10:51:03,683:INFO:create_model() successfully completed......................................
2026-02-03 10:51:03,818:INFO:Initializing create_model()
2026-02-03 10:51:03,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:51:03,818:INFO:Checking exceptions
2026-02-03 10:51:03,820:INFO:Importing libraries
2026-02-03 10:51:03,820:INFO:Copying training dataset
2026-02-03 10:51:03,824:INFO:Defining folds
2026-02-03 10:51:03,824:INFO:Declaring metric variables
2026-02-03 10:51:03,824:INFO:Importing untrained model
2026-02-03 10:51:03,825:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-03 10:51:03,825:INFO:Starting cross validation
2026-02-03 10:51:03,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:51:04,867:INFO:Calculating mean and std
2026-02-03 10:51:04,868:INFO:Creating metrics dataframe
2026-02-03 10:51:04,871:INFO:Finalizing model
2026-02-03 10:51:04,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2026-02-03 10:51:04,917:INFO:You can set `force_col_wise=true` to remove the overhead.
2026-02-03 10:51:04,917:INFO:[LightGBM] [Info] Total Bins 463
2026-02-03 10:51:04,918:INFO:[LightGBM] [Info] Number of data points in the train set: 170, number of used features: 12
2026-02-03 10:51:04,919:INFO:[LightGBM] [Info] Start training from score 22.974706
2026-02-03 10:51:04,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 10:51:04,984:INFO:Uploading results into container
2026-02-03 10:51:04,985:INFO:Uploading model into container now
2026-02-03 10:51:04,985:INFO:_master_model_container: 3
2026-02-03 10:51:04,985:INFO:_display_container: 4
2026-02-03 10:51:04,986:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2026-02-03 10:51:04,986:INFO:create_model() successfully completed......................................
2026-02-03 10:51:05,135:INFO:Initializing blend_models()
2026-02-03 10:51:05,135:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator_list=[LinearRegression(n_jobs=-1), DecisionTreeRegressor(random_state=123), LGBMRegressor(n_jobs=-1, random_state=123)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=False, return_train_score=False)
2026-02-03 10:51:05,135:INFO:Checking exceptions
2026-02-03 10:51:05,138:INFO:Importing libraries
2026-02-03 10:51:05,138:INFO:Copying training dataset
2026-02-03 10:51:05,138:INFO:Getting model names
2026-02-03 10:51:05,139:INFO:SubProcess create_model() called ==================================
2026-02-03 10:51:05,143:INFO:Initializing create_model()
2026-02-03 10:51:05,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator=VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022540837710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 10:51:05,143:INFO:Checking exceptions
2026-02-03 10:51:05,143:INFO:Importing libraries
2026-02-03 10:51:05,144:INFO:Copying training dataset
2026-02-03 10:51:05,148:INFO:Defining folds
2026-02-03 10:51:05,148:INFO:Declaring metric variables
2026-02-03 10:51:05,148:INFO:Importing untrained model
2026-02-03 10:51:05,148:INFO:Declaring custom model
2026-02-03 10:51:05,150:INFO:Voting Regressor Imported successfully
2026-02-03 10:51:05,151:INFO:Starting cross validation
2026-02-03 10:51:05,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 10:51:05,945:INFO:Calculating mean and std
2026-02-03 10:51:05,946:INFO:Creating metrics dataframe
2026-02-03 10:51:05,949:INFO:Finalizing model
2026-02-03 10:51:06,113:INFO:Uploading results into container
2026-02-03 10:51:06,114:INFO:Uploading model into container now
2026-02-03 10:51:06,115:INFO:_master_model_container: 4
2026-02-03 10:51:06,115:INFO:_display_container: 5
2026-02-03 10:51:06,122:INFO:VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1)
2026-02-03 10:51:06,122:INFO:create_model() successfully completed......................................
2026-02-03 10:51:06,265:INFO:SubProcess create_model() end ==================================
2026-02-03 10:51:06,266:INFO:_master_model_container: 4
2026-02-03 10:51:06,266:INFO:_display_container: 5
2026-02-03 10:51:06,270:INFO:VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1)
2026-02-03 10:51:06,270:INFO:blend_models() successfully completed......................................
2026-02-03 10:51:06,393:INFO:Initializing predict_model()
2026-02-03 10:51:06,393:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, estimator=VotingRegressor(estimators=[('Linear Regression', LinearRegression(n_jobs=-1)),
                            ('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(n_jobs=-1, random_state=123))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022542674220>)
2026-02-03 10:51:06,393:INFO:Checking exceptions
2026-02-03 10:51:06,393:INFO:Preloading libraries
2026-02-03 10:51:06,630:INFO:Initializing get_config()
2026-02-03 10:51:06,630:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000225407E9C50>, variable=target_param)
2026-02-03 10:51:06,631:INFO:Variable:  returned as MEDV
2026-02-03 10:51:06,631:INFO:get_config() successfully completed......................................
2026-02-03 13:48:49,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:48:49,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:48:49,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:48:49,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:56:50,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:56:50,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:56:50,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 13:56:50,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:00:42,053:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:00:42,062:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:06:08,704:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:06:08,705:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:40,575:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:40,576:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:47,309:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:47,311:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:53,145:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:10:53,146:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:11:00,317:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:11:00,318:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:12:05,120:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:12:05,121:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:15:55,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:15:55,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:15:55,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:15:55,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:19:59,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:19:59,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:19:59,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:19:59,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:20:07,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:20:07,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:20:07,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:20:07,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:20:24,735:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:20:24,739:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:20:26,782:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:20:26,783:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:20:30,610:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:20:30,612:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:11,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:23:11,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:23:11,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:23:11,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:23:14,405:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:14,407:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:16,444:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:16,445:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:18,490:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:18,491:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:23:18,536:INFO:PyCaret ClassificationExperiment
2026-02-03 14:23:18,536:INFO:Logging name: clf-default-name
2026-02-03 14:23:18,537:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-03 14:23:18,537:INFO:version 3.3.2
2026-02-03 14:23:18,537:INFO:Initializing setup()
2026-02-03 14:23:18,537:INFO:self.USI: cb8e
2026-02-03 14:23:18,537:INFO:self._variable_keys: {'y_train', 'X_train', 'data', 'logging_param', 'USI', 'fix_imbalance', '_available_plots', 'y', 'target_param', 'y_test', 'html_param', 'exp_name_log', 'fold_generator', 'fold_groups_param', '_ml_usecase', 'fold_shuffle_param', 'idx', 'n_jobs_param', 'log_plots_param', 'memory', 'seed', 'is_multiclass', 'X_test', 'exp_id', 'pipeline', 'gpu_param', 'X', 'gpu_n_jobs_param'}
2026-02-03 14:23:18,537:INFO:Checking environment
2026-02-03 14:23:18,537:INFO:python_version: 3.11.9
2026-02-03 14:23:18,537:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 14:23:18,537:INFO:machine: AMD64
2026-02-03 14:23:18,550:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 14:23:18,550:INFO:Memory: svmem(total=16866873344, available=2370670592, percent=85.9, used=14496202752, free=2370670592)
2026-02-03 14:23:18,550:INFO:Physical Core: 8
2026-02-03 14:23:18,550:INFO:Logical Core: 16
2026-02-03 14:23:18,551:INFO:Checking libraries
2026-02-03 14:23:18,551:INFO:System:
2026-02-03 14:23:18,551:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 14:23:18,551:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 14:23:18,551:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 14:23:18,551:INFO:PyCaret required dependencies:
2026-02-03 14:23:18,690:INFO:                 pip: 24.0
2026-02-03 14:23:18,690:INFO:          setuptools: 80.9.0
2026-02-03 14:23:18,690:INFO:             pycaret: 3.3.2
2026-02-03 14:23:18,691:INFO:             IPython: 9.8.0
2026-02-03 14:23:18,691:INFO:          ipywidgets: 8.1.8
2026-02-03 14:23:18,691:INFO:                tqdm: 4.67.1
2026-02-03 14:23:18,691:INFO:               numpy: 1.26.4
2026-02-03 14:23:18,691:INFO:              pandas: 2.1.4
2026-02-03 14:23:18,691:INFO:              jinja2: 3.1.6
2026-02-03 14:23:18,691:INFO:               scipy: 1.11.4
2026-02-03 14:23:18,691:INFO:              joblib: 1.3.2
2026-02-03 14:23:18,691:INFO:             sklearn: 1.4.2
2026-02-03 14:23:18,691:INFO:                pyod: 2.0.6
2026-02-03 14:23:18,691:INFO:            imblearn: 0.14.1
2026-02-03 14:23:18,691:INFO:   category_encoders: 2.7.0
2026-02-03 14:23:18,691:INFO:            lightgbm: 4.6.0
2026-02-03 14:23:18,691:INFO:               numba: 0.63.1
2026-02-03 14:23:18,691:INFO:            requests: 2.32.5
2026-02-03 14:23:18,691:INFO:          matplotlib: 3.7.5
2026-02-03 14:23:18,691:INFO:          scikitplot: 0.3.7
2026-02-03 14:23:18,691:INFO:         yellowbrick: 1.5
2026-02-03 14:23:18,691:INFO:              plotly: 6.5.0
2026-02-03 14:23:18,691:INFO:    plotly-resampler: Not installed
2026-02-03 14:23:18,691:INFO:             kaleido: 1.2.0
2026-02-03 14:23:18,691:INFO:           schemdraw: 0.15
2026-02-03 14:23:18,691:INFO:         statsmodels: 0.14.6
2026-02-03 14:23:18,692:INFO:              sktime: 0.26.0
2026-02-03 14:23:18,692:INFO:               tbats: 1.1.3
2026-02-03 14:23:18,692:INFO:            pmdarima: 2.0.4
2026-02-03 14:23:18,692:INFO:              psutil: 7.1.3
2026-02-03 14:23:18,692:INFO:          markupsafe: 3.0.3
2026-02-03 14:23:18,692:INFO:             pickle5: Not installed
2026-02-03 14:23:18,692:INFO:         cloudpickle: 3.1.2
2026-02-03 14:23:18,692:INFO:         deprecation: 2.1.0
2026-02-03 14:23:18,692:INFO:              xxhash: 3.6.0
2026-02-03 14:23:18,692:INFO:           wurlitzer: Not installed
2026-02-03 14:23:18,692:INFO:PyCaret optional dependencies:
2026-02-03 14:23:18,781:INFO:                shap: Not installed
2026-02-03 14:23:18,781:INFO:           interpret: Not installed
2026-02-03 14:23:18,781:INFO:                umap: Not installed
2026-02-03 14:23:18,782:INFO:     ydata_profiling: Not installed
2026-02-03 14:23:18,782:INFO:  explainerdashboard: Not installed
2026-02-03 14:23:18,782:INFO:             autoviz: Not installed
2026-02-03 14:23:18,782:INFO:           fairlearn: Not installed
2026-02-03 14:23:18,782:INFO:          deepchecks: Not installed
2026-02-03 14:23:18,782:INFO:             xgboost: 3.1.2
2026-02-03 14:23:18,782:INFO:            catboost: 1.2.8
2026-02-03 14:23:18,782:INFO:              kmodes: Not installed
2026-02-03 14:23:18,782:INFO:             mlxtend: Not installed
2026-02-03 14:23:18,782:INFO:       statsforecast: Not installed
2026-02-03 14:23:18,782:INFO:        tune_sklearn: Not installed
2026-02-03 14:23:18,782:INFO:                 ray: Not installed
2026-02-03 14:23:18,782:INFO:            hyperopt: Not installed
2026-02-03 14:23:18,782:INFO:              optuna: 4.6.0
2026-02-03 14:23:18,782:INFO:               skopt: Not installed
2026-02-03 14:23:18,782:INFO:              mlflow: Not installed
2026-02-03 14:23:18,782:INFO:              gradio: Not installed
2026-02-03 14:23:18,782:INFO:             fastapi: 0.123.10
2026-02-03 14:23:18,782:INFO:             uvicorn: 0.38.0
2026-02-03 14:23:18,782:INFO:              m2cgen: Not installed
2026-02-03 14:23:18,782:INFO:           evidently: Not installed
2026-02-03 14:23:18,782:INFO:               fugue: Not installed
2026-02-03 14:23:18,782:INFO:           streamlit: Not installed
2026-02-03 14:23:18,783:INFO:             prophet: Not installed
2026-02-03 14:23:18,783:INFO:None
2026-02-03 14:23:18,783:INFO:Set up data.
2026-02-03 14:23:18,791:INFO:Set up folding strategy.
2026-02-03 14:23:18,791:INFO:Set up train/test split.
2026-02-03 14:23:18,805:INFO:Set up index.
2026-02-03 14:23:18,807:INFO:Assigning column types.
2026-02-03 14:23:18,811:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 14:23:18,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:23:18,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:23:18,925:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:18,928:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:23:19,123:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:23:19,159:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,163:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,164:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 14:23:19,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:23:19,261:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,264:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,325:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:23:19,363:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,367:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,367:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-03 14:23:19,463:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,466:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,568:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,571:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:19,574:INFO:Preparing preprocessing pipeline...
2026-02-03 14:23:19,578:INFO:Set up label encoding.
2026-02-03 14:23:19,578:INFO:Set up simple imputation.
2026-02-03 14:23:19,581:INFO:Set up encoding of categorical features.
2026-02-03 14:23:19,644:INFO:Finished creating preprocessing pipeline.
2026-02-03 14:23:19,653:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'weight_g',
                                             'size_cm3'],
                                    transformer=SimpleImputer(add_indi...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['color_category'],
                                    transformer=OneHotEncoder(cols=['color_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2026-02-03 14:23:19,653:INFO:Creating final display dataframe.
2026-02-03 14:23:19,842:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                           ripeness
2                   Target type                                         Multiclass
3                Target mapping  breaking: 0, firm-ripe: 1, hard: 2, pre-condit...
4           Original data shape                                           (250, 8)
5        Transformed data shape                                          (250, 11)
6   Transformed train set shape                                          (175, 11)
7    Transformed test set shape                                           (75, 11)
8              Numeric features                                                  6
9          Categorical features                                                  1
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               cb8e
2026-02-03 14:23:19,939:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:19,943:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:20,047:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:23:20,050:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:23:20,052:INFO:setup() successfully completed in 1.52s...............
2026-02-03 14:23:20,053:INFO:Initializing create_model()
2026-02-03 14:23:20,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:23:20,053:INFO:Checking exceptions
2026-02-03 14:23:20,054:INFO:Importing libraries
2026-02-03 14:23:20,054:INFO:Copying training dataset
2026-02-03 14:23:20,058:INFO:Defining folds
2026-02-03 14:23:20,058:INFO:Declaring metric variables
2026-02-03 14:23:20,058:INFO:Importing untrained model
2026-02-03 14:23:20,059:INFO:Logistic Regression Imported successfully
2026-02-03 14:23:20,059:INFO:Starting cross validation
2026-02-03 14:23:20,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:23:25,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:23:25,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:23:25,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:23:25,611:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,640:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,646:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,648:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,648:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,648:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,649:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,649:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,650:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,650:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:25,669:INFO:Calculating mean and std
2026-02-03 14:23:25,670:INFO:Creating metrics dataframe
2026-02-03 14:23:25,676:INFO:Finalizing model
2026-02-03 14:23:25,824:INFO:Uploading results into container
2026-02-03 14:23:25,825:INFO:Uploading model into container now
2026-02-03 14:23:25,826:INFO:_master_model_container: 1
2026-02-03 14:23:25,826:INFO:_display_container: 2
2026-02-03 14:23:25,826:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-03 14:23:25,826:INFO:create_model() successfully completed......................................
2026-02-03 14:23:25,970:INFO:Initializing create_model()
2026-02-03 14:23:25,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:23:25,970:INFO:Checking exceptions
2026-02-03 14:23:25,971:INFO:Importing libraries
2026-02-03 14:23:25,971:INFO:Copying training dataset
2026-02-03 14:23:25,975:INFO:Defining folds
2026-02-03 14:23:25,975:INFO:Declaring metric variables
2026-02-03 14:23:25,975:INFO:Importing untrained model
2026-02-03 14:23:25,976:INFO:Decision Tree Classifier Imported successfully
2026-02-03 14:23:25,976:INFO:Starting cross validation
2026-02-03 14:23:25,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:23:26,099:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,100:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,103:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,105:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,107:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,109:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,109:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:26,109:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,853:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,855:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,856:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,859:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,860:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,860:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,864:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,865:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,869:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,870:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,872:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,872:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,875:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,875:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,878:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,882:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,886:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,891:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:29,906:INFO:Calculating mean and std
2026-02-03 14:23:29,907:INFO:Creating metrics dataframe
2026-02-03 14:23:29,911:INFO:Finalizing model
2026-02-03 14:23:29,951:INFO:Uploading results into container
2026-02-03 14:23:29,952:INFO:Uploading model into container now
2026-02-03 14:23:29,952:INFO:_master_model_container: 2
2026-02-03 14:23:29,952:INFO:_display_container: 3
2026-02-03 14:23:29,953:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-03 14:23:29,953:INFO:create_model() successfully completed......................................
2026-02-03 14:23:30,099:INFO:Initializing create_model()
2026-02-03 14:23:30,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:23:30,099:INFO:Checking exceptions
2026-02-03 14:23:30,100:INFO:Importing libraries
2026-02-03 14:23:30,100:INFO:Copying training dataset
2026-02-03 14:23:30,104:INFO:Defining folds
2026-02-03 14:23:30,104:INFO:Declaring metric variables
2026-02-03 14:23:30,104:INFO:Importing untrained model
2026-02-03 14:23:30,105:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-03 14:23:30,106:INFO:Starting cross validation
2026-02-03 14:23:30,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:23:32,597:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,603:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,609:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,751:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,941:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,953:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:32,960:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,016:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,029:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,037:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,147:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,159:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,167:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,223:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,227:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,236:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,290:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,296:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,299:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,304:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,303:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,309:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,337:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,343:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,348:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,429:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,434:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,439:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:33,452:INFO:Calculating mean and std
2026-02-03 14:23:33,453:INFO:Creating metrics dataframe
2026-02-03 14:23:33,456:INFO:Finalizing model
2026-02-03 14:23:33,516:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2026-02-03 14:23:33,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2026-02-03 14:23:33,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2026-02-03 14:23:33,518:INFO:[LightGBM] [Info] Total Bins 300
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Number of data points in the train set: 175, number of used features: 10
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:23:33,519:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:23:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:23:33,749:INFO:Uploading results into container
2026-02-03 14:23:33,750:INFO:Uploading model into container now
2026-02-03 14:23:33,750:INFO:_master_model_container: 3
2026-02-03 14:23:33,750:INFO:_display_container: 4
2026-02-03 14:23:33,751:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-03 14:23:33,752:INFO:create_model() successfully completed......................................
2026-02-03 14:23:33,896:INFO:Initializing blend_models()
2026-02-03 14:23:33,896:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=False, return_train_score=False)
2026-02-03 14:23:33,897:INFO:Checking exceptions
2026-02-03 14:23:33,903:INFO:Importing libraries
2026-02-03 14:23:33,903:INFO:Copying training dataset
2026-02-03 14:23:33,903:INFO:Getting model names
2026-02-03 14:23:33,904:INFO:SubProcess create_model() called ==================================
2026-02-03 14:23:33,909:INFO:Initializing create_model()
2026-02-03 14:23:33,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021497688210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:23:33,909:INFO:Checking exceptions
2026-02-03 14:23:33,909:INFO:Importing libraries
2026-02-03 14:23:33,909:INFO:Copying training dataset
2026-02-03 14:23:33,913:INFO:Defining folds
2026-02-03 14:23:33,913:INFO:Declaring metric variables
2026-02-03 14:23:33,913:INFO:Importing untrained model
2026-02-03 14:23:33,913:INFO:Declaring custom model
2026-02-03 14:23:33,916:INFO:Voting Classifier Imported successfully
2026-02-03 14:23:33,916:INFO:Starting cross validation
2026-02-03 14:23:33,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:23:36,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,392:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,430:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,434:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,440:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,509:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,515:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,521:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,548:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,556:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,564:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,655:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,661:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,665:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,667:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,671:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,676:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,833:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,839:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,867:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,868:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,872:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,873:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,877:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,877:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,889:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,894:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,898:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:36,912:INFO:Calculating mean and std
2026-02-03 14:23:36,913:INFO:Creating metrics dataframe
2026-02-03 14:23:36,916:INFO:Finalizing model
2026-02-03 14:23:37,251:INFO:Uploading results into container
2026-02-03 14:23:37,252:INFO:Uploading model into container now
2026-02-03 14:23:37,253:INFO:_master_model_container: 4
2026-02-03 14:23:37,253:INFO:_display_container: 5
2026-02-03 14:23:37,261:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2026-02-03 14:23:37,261:INFO:create_model() successfully completed......................................
2026-02-03 14:23:37,403:INFO:SubProcess create_model() end ==================================
2026-02-03 14:23:37,404:INFO:_master_model_container: 4
2026-02-03 14:23:37,404:INFO:_display_container: 5
2026-02-03 14:23:37,409:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2026-02-03 14:23:37,410:INFO:blend_models() successfully completed......................................
2026-02-03 14:23:37,540:INFO:Initializing predict_model()
2026-02-03 14:23:37,540:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002149749C710>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021497EB0EA0>)
2026-02-03 14:23:37,540:INFO:Checking exceptions
2026-02-03 14:23:37,540:INFO:Preloading libraries
2026-02-03 14:23:37,648:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:37,652:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:23:37,656:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:04,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:04,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:04,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:04,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:16,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:16,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:16,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:16,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:28:34,427:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:34,429:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:36,475:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:36,476:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:39,066:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:39,067:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:28:39,091:INFO:PyCaret ClassificationExperiment
2026-02-03 14:28:39,091:INFO:Logging name: clf-default-name
2026-02-03 14:28:39,091:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-03 14:28:39,091:INFO:version 3.3.2
2026-02-03 14:28:39,091:INFO:Initializing setup()
2026-02-03 14:28:39,091:INFO:self.USI: 1e96
2026-02-03 14:28:39,091:INFO:self._variable_keys: {'fold_generator', 'fold_groups_param', 'is_multiclass', 'data', 'y', 'html_param', 'exp_name_log', 'fold_shuffle_param', 'fix_imbalance', 'pipeline', 'X', 'n_jobs_param', 'USI', 'gpu_param', 'y_test', 'gpu_n_jobs_param', 'memory', '_ml_usecase', 'X_train', 'exp_id', '_available_plots', 'y_train', 'target_param', 'idx', 'X_test', 'log_plots_param', 'seed', 'logging_param'}
2026-02-03 14:28:39,091:INFO:Checking environment
2026-02-03 14:28:39,091:INFO:python_version: 3.11.9
2026-02-03 14:28:39,091:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 14:28:39,091:INFO:machine: AMD64
2026-02-03 14:28:39,104:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 14:28:39,104:INFO:Memory: svmem(total=16866873344, available=3919794176, percent=76.8, used=12947079168, free=3919794176)
2026-02-03 14:28:39,105:INFO:Physical Core: 8
2026-02-03 14:28:39,105:INFO:Logical Core: 16
2026-02-03 14:28:39,105:INFO:Checking libraries
2026-02-03 14:28:39,105:INFO:System:
2026-02-03 14:28:39,105:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 14:28:39,105:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 14:28:39,105:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 14:28:39,105:INFO:PyCaret required dependencies:
2026-02-03 14:28:39,213:INFO:                 pip: 24.0
2026-02-03 14:28:39,213:INFO:          setuptools: 80.9.0
2026-02-03 14:28:39,213:INFO:             pycaret: 3.3.2
2026-02-03 14:28:39,213:INFO:             IPython: 9.8.0
2026-02-03 14:28:39,213:INFO:          ipywidgets: 8.1.8
2026-02-03 14:28:39,213:INFO:                tqdm: 4.67.1
2026-02-03 14:28:39,213:INFO:               numpy: 1.26.4
2026-02-03 14:28:39,214:INFO:              pandas: 2.1.4
2026-02-03 14:28:39,214:INFO:              jinja2: 3.1.6
2026-02-03 14:28:39,214:INFO:               scipy: 1.11.4
2026-02-03 14:28:39,214:INFO:              joblib: 1.3.2
2026-02-03 14:28:39,214:INFO:             sklearn: 1.4.2
2026-02-03 14:28:39,214:INFO:                pyod: 2.0.6
2026-02-03 14:28:39,214:INFO:            imblearn: 0.14.1
2026-02-03 14:28:39,214:INFO:   category_encoders: 2.7.0
2026-02-03 14:28:39,214:INFO:            lightgbm: 4.6.0
2026-02-03 14:28:39,214:INFO:               numba: 0.63.1
2026-02-03 14:28:39,214:INFO:            requests: 2.32.5
2026-02-03 14:28:39,214:INFO:          matplotlib: 3.7.5
2026-02-03 14:28:39,214:INFO:          scikitplot: 0.3.7
2026-02-03 14:28:39,214:INFO:         yellowbrick: 1.5
2026-02-03 14:28:39,214:INFO:              plotly: 6.5.0
2026-02-03 14:28:39,214:INFO:    plotly-resampler: Not installed
2026-02-03 14:28:39,214:INFO:             kaleido: 1.2.0
2026-02-03 14:28:39,214:INFO:           schemdraw: 0.15
2026-02-03 14:28:39,214:INFO:         statsmodels: 0.14.6
2026-02-03 14:28:39,214:INFO:              sktime: 0.26.0
2026-02-03 14:28:39,214:INFO:               tbats: 1.1.3
2026-02-03 14:28:39,214:INFO:            pmdarima: 2.0.4
2026-02-03 14:28:39,215:INFO:              psutil: 7.1.3
2026-02-03 14:28:39,215:INFO:          markupsafe: 3.0.3
2026-02-03 14:28:39,215:INFO:             pickle5: Not installed
2026-02-03 14:28:39,215:INFO:         cloudpickle: 3.1.2
2026-02-03 14:28:39,215:INFO:         deprecation: 2.1.0
2026-02-03 14:28:39,215:INFO:              xxhash: 3.6.0
2026-02-03 14:28:39,215:INFO:           wurlitzer: Not installed
2026-02-03 14:28:39,215:INFO:PyCaret optional dependencies:
2026-02-03 14:28:39,275:INFO:                shap: Not installed
2026-02-03 14:28:39,276:INFO:           interpret: Not installed
2026-02-03 14:28:39,276:INFO:                umap: Not installed
2026-02-03 14:28:39,276:INFO:     ydata_profiling: Not installed
2026-02-03 14:28:39,276:INFO:  explainerdashboard: Not installed
2026-02-03 14:28:39,276:INFO:             autoviz: Not installed
2026-02-03 14:28:39,276:INFO:           fairlearn: Not installed
2026-02-03 14:28:39,276:INFO:          deepchecks: Not installed
2026-02-03 14:28:39,276:INFO:             xgboost: 3.1.2
2026-02-03 14:28:39,276:INFO:            catboost: 1.2.8
2026-02-03 14:28:39,276:INFO:              kmodes: Not installed
2026-02-03 14:28:39,276:INFO:             mlxtend: Not installed
2026-02-03 14:28:39,276:INFO:       statsforecast: Not installed
2026-02-03 14:28:39,276:INFO:        tune_sklearn: Not installed
2026-02-03 14:28:39,276:INFO:                 ray: Not installed
2026-02-03 14:28:39,276:INFO:            hyperopt: Not installed
2026-02-03 14:28:39,276:INFO:              optuna: 4.6.0
2026-02-03 14:28:39,276:INFO:               skopt: Not installed
2026-02-03 14:28:39,276:INFO:              mlflow: Not installed
2026-02-03 14:28:39,276:INFO:              gradio: Not installed
2026-02-03 14:28:39,276:INFO:             fastapi: 0.123.10
2026-02-03 14:28:39,277:INFO:             uvicorn: 0.38.0
2026-02-03 14:28:39,277:INFO:              m2cgen: Not installed
2026-02-03 14:28:39,277:INFO:           evidently: Not installed
2026-02-03 14:28:39,277:INFO:               fugue: Not installed
2026-02-03 14:28:39,277:INFO:           streamlit: Not installed
2026-02-03 14:28:39,277:INFO:             prophet: Not installed
2026-02-03 14:28:39,277:INFO:None
2026-02-03 14:28:39,277:INFO:Set up data.
2026-02-03 14:28:39,283:INFO:Set up folding strategy.
2026-02-03 14:28:39,283:INFO:Set up train/test split.
2026-02-03 14:28:39,292:INFO:Set up index.
2026-02-03 14:28:39,292:INFO:Assigning column types.
2026-02-03 14:28:39,296:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 14:28:39,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,409:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,413:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,518:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,554:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,557:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,558:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 14:28:39,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,655:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,658:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:28:39,755:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,758:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,759:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-03 14:28:39,854:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,857:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,953:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:39,957:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:39,962:INFO:Preparing preprocessing pipeline...
2026-02-03 14:28:39,963:INFO:Set up label encoding.
2026-02-03 14:28:39,963:INFO:Set up simple imputation.
2026-02-03 14:28:39,965:INFO:Set up encoding of categorical features.
2026-02-03 14:28:40,025:INFO:Finished creating preprocessing pipeline.
2026-02-03 14:28:40,034:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'weight_g',
                                             'size_cm3'],
                                    transformer=SimpleImputer(add_indi...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['color_category'],
                                    transformer=OneHotEncoder(cols=['color_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2026-02-03 14:28:40,034:INFO:Creating final display dataframe.
2026-02-03 14:28:40,219:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                           ripeness
2                   Target type                                         Multiclass
3                Target mapping  breaking: 0, firm-ripe: 1, hard: 2, pre-condit...
4           Original data shape                                           (250, 8)
5        Transformed data shape                                          (250, 11)
6   Transformed train set shape                                          (175, 11)
7    Transformed test set shape                                           (75, 11)
8              Numeric features                                                  6
9          Categorical features                                                  1
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               1e96
2026-02-03 14:28:40,313:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:40,317:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:40,415:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:28:40,418:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:28:40,420:INFO:setup() successfully completed in 1.33s...............
2026-02-03 14:28:40,421:INFO:Initializing create_model()
2026-02-03 14:28:40,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:28:40,421:INFO:Checking exceptions
2026-02-03 14:28:40,422:INFO:Importing libraries
2026-02-03 14:28:40,422:INFO:Copying training dataset
2026-02-03 14:28:40,426:INFO:Defining folds
2026-02-03 14:28:40,426:INFO:Declaring metric variables
2026-02-03 14:28:40,426:INFO:Importing untrained model
2026-02-03 14:28:40,427:INFO:Logistic Regression Imported successfully
2026-02-03 14:28:40,427:INFO:Starting cross validation
2026-02-03 14:28:40,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:28:45,744:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,749:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,754:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,756:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,762:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,766:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,767:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,771:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,772:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,777:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,779:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,779:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,782:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,783:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,784:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,785:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,796:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,798:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,801:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,804:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,808:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,813:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,817:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,818:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,819:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,822:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,827:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,833:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,839:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,871:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,872:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2026-02-03 14:28:45,879:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,880:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,886:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,891:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,893:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,900:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:45,917:INFO:Calculating mean and std
2026-02-03 14:28:45,918:INFO:Creating metrics dataframe
2026-02-03 14:28:45,923:INFO:Finalizing model
2026-02-03 14:28:46,033:INFO:Uploading results into container
2026-02-03 14:28:46,033:INFO:Uploading model into container now
2026-02-03 14:28:46,034:INFO:_master_model_container: 1
2026-02-03 14:28:46,034:INFO:_display_container: 2
2026-02-03 14:28:46,035:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-02-03 14:28:46,035:INFO:create_model() successfully completed......................................
2026-02-03 14:28:46,185:INFO:Initializing create_model()
2026-02-03 14:28:46,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:28:46,185:INFO:Checking exceptions
2026-02-03 14:28:46,186:INFO:Importing libraries
2026-02-03 14:28:46,186:INFO:Copying training dataset
2026-02-03 14:28:46,190:INFO:Defining folds
2026-02-03 14:28:46,190:INFO:Declaring metric variables
2026-02-03 14:28:46,190:INFO:Importing untrained model
2026-02-03 14:28:46,191:INFO:Decision Tree Classifier Imported successfully
2026-02-03 14:28:46,191:INFO:Starting cross validation
2026-02-03 14:28:46,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:28:46,306:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,307:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,307:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,311:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,312:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,312:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,316:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,318:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,318:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,323:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:46,326:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,361:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,363:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,364:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,367:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,370:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,372:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,376:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,385:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,389:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,390:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,391:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,392:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,394:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,395:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,397:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,398:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:50,413:INFO:Calculating mean and std
2026-02-03 14:28:50,415:INFO:Creating metrics dataframe
2026-02-03 14:28:50,419:INFO:Finalizing model
2026-02-03 14:28:50,462:INFO:Uploading results into container
2026-02-03 14:28:50,463:INFO:Uploading model into container now
2026-02-03 14:28:50,464:INFO:_master_model_container: 2
2026-02-03 14:28:50,464:INFO:_display_container: 3
2026-02-03 14:28:50,464:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2026-02-03 14:28:50,465:INFO:create_model() successfully completed......................................
2026-02-03 14:28:50,615:INFO:Initializing create_model()
2026-02-03 14:28:50,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:28:50,615:INFO:Checking exceptions
2026-02-03 14:28:50,616:INFO:Importing libraries
2026-02-03 14:28:50,616:INFO:Copying training dataset
2026-02-03 14:28:50,620:INFO:Defining folds
2026-02-03 14:28:50,620:INFO:Declaring metric variables
2026-02-03 14:28:50,620:INFO:Importing untrained model
2026-02-03 14:28:50,621:INFO:Light Gradient Boosting Machine Imported successfully
2026-02-03 14:28:50,622:INFO:Starting cross validation
2026-02-03 14:28:50,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:28:53,922:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:53,930:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:53,938:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,313:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,321:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,327:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,550:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,555:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,562:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,617:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,623:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,628:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,691:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,699:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,703:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,732:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,737:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,743:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,774:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,781:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,786:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,821:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,825:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,830:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,865:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,869:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,872:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:54,881:INFO:Calculating mean and std
2026-02-03 14:28:54,882:INFO:Creating metrics dataframe
2026-02-03 14:28:54,884:INFO:Finalizing model
2026-02-03 14:28:54,940:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2026-02-03 14:28:54,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2026-02-03 14:28:54,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2026-02-03 14:28:54,942:INFO:[LightGBM] [Info] Total Bins 300
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Number of data points in the train set: 175, number of used features: 10
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:28:54,943:INFO:[LightGBM] [Info] Start training from score -1.609438
2026-02-03 14:28:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:54,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-02-03 14:28:55,079:INFO:Uploading results into container
2026-02-03 14:28:55,080:INFO:Uploading model into container now
2026-02-03 14:28:55,081:INFO:_master_model_container: 3
2026-02-03 14:28:55,081:INFO:_display_container: 4
2026-02-03 14:28:55,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-02-03 14:28:55,082:INFO:create_model() successfully completed......................................
2026-02-03 14:28:55,228:INFO:Initializing blend_models()
2026-02-03 14:28:55,228:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=False, return_train_score=False)
2026-02-03 14:28:55,228:INFO:Checking exceptions
2026-02-03 14:28:55,232:INFO:Importing libraries
2026-02-03 14:28:55,232:INFO:Copying training dataset
2026-02-03 14:28:55,232:INFO:Getting model names
2026-02-03 14:28:55,233:INFO:SubProcess create_model() called ==================================
2026-02-03 14:28:55,238:INFO:Initializing create_model()
2026-02-03 14:28:55,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2864DF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:28:55,239:INFO:Checking exceptions
2026-02-03 14:28:55,239:INFO:Importing libraries
2026-02-03 14:28:55,239:INFO:Copying training dataset
2026-02-03 14:28:55,242:INFO:Defining folds
2026-02-03 14:28:55,242:INFO:Declaring metric variables
2026-02-03 14:28:55,243:INFO:Importing untrained model
2026-02-03 14:28:55,243:INFO:Declaring custom model
2026-02-03 14:28:55,245:INFO:Voting Classifier Imported successfully
2026-02-03 14:28:55,246:INFO:Starting cross validation
2026-02-03 14:28:55,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2026-02-03 14:28:57,734:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,741:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,748:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,807:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,814:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,824:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,946:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,957:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:57,965:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,018:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,028:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,035:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,085:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,093:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,099:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,167:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,184:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,192:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,229:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,233:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,236:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,238:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,243:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,245:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,246:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,250:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,256:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,386:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,391:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,397:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:58,406:INFO:Calculating mean and std
2026-02-03 14:28:58,407:INFO:Creating metrics dataframe
2026-02-03 14:28:58,410:INFO:Finalizing model
2026-02-03 14:28:59,052:INFO:Uploading results into container
2026-02-03 14:28:59,053:INFO:Uploading model into container now
2026-02-03 14:28:59,054:INFO:_master_model_container: 4
2026-02-03 14:28:59,054:INFO:_display_container: 5
2026-02-03 14:28:59,061:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2026-02-03 14:28:59,061:INFO:create_model() successfully completed......................................
2026-02-03 14:28:59,209:INFO:SubProcess create_model() end ==================================
2026-02-03 14:28:59,210:INFO:_master_model_container: 4
2026-02-03 14:28:59,210:INFO:_display_container: 5
2026-02-03 14:28:59,217:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2026-02-03 14:28:59,217:INFO:blend_models() successfully completed......................................
2026-02-03 14:28:59,359:INFO:Initializing predict_model()
2026-02-03 14:28:59,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F285F0EF10>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002F286CD47C0>)
2026-02-03 14:28:59,359:INFO:Checking exceptions
2026-02-03 14:28:59,359:INFO:Preloading libraries
2026-02-03 14:28:59,474:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:59,479:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:28:59,483:WARNING:C:\Users\tream\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'ripe') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2026-02-03 14:30:20,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:30:20,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:30:20,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:30:20,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-02-03 14:30:25,543:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:25,545:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:27,599:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:27,600:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:49,941:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:49,942:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:52,027:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:52,029:WARNING:C:\Users\tream\OneDrive\Documents\1DEV\INFOMEDIA_MAGANG\automl\backend\app\services\ingestion.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  pd.to_datetime(df[col].dropna().iloc[:10], errors='raise')

2026-02-03 14:30:52,057:INFO:PyCaret ClassificationExperiment
2026-02-03 14:30:52,057:INFO:Logging name: clf-default-name
2026-02-03 14:30:52,057:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-02-03 14:30:52,057:INFO:version 3.3.2
2026-02-03 14:30:52,057:INFO:Initializing setup()
2026-02-03 14:30:52,058:INFO:self.USI: ca3c
2026-02-03 14:30:52,058:INFO:self._variable_keys: {'y_train', '_available_plots', 'seed', 'fold_groups_param', 'data', 'exp_name_log', 'X_train', 'X_test', 'fold_generator', 'gpu_param', 'X', '_ml_usecase', 'y_test', 'idx', 'fix_imbalance', 'logging_param', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'y', 'log_plots_param', 'is_multiclass', 'target_param', 'exp_id', 'fold_shuffle_param', 'pipeline', 'html_param', 'USI'}
2026-02-03 14:30:52,058:INFO:Checking environment
2026-02-03 14:30:52,058:INFO:python_version: 3.11.9
2026-02-03 14:30:52,058:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2026-02-03 14:30:52,058:INFO:machine: AMD64
2026-02-03 14:30:52,070:INFO:platform: Windows-10-10.0.26200-SP0
2026-02-03 14:30:52,071:INFO:Memory: svmem(total=16866873344, available=3971436544, percent=76.5, used=12895436800, free=3971436544)
2026-02-03 14:30:52,071:INFO:Physical Core: 8
2026-02-03 14:30:52,071:INFO:Logical Core: 16
2026-02-03 14:30:52,071:INFO:Checking libraries
2026-02-03 14:30:52,071:INFO:System:
2026-02-03 14:30:52,071:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2026-02-03 14:30:52,071:INFO:executable: C:\Users\tream\AppData\Local\Programs\Python\Python311\python.exe
2026-02-03 14:30:52,071:INFO:   machine: Windows-10-10.0.26200-SP0
2026-02-03 14:30:52,071:INFO:PyCaret required dependencies:
2026-02-03 14:30:52,178:INFO:                 pip: 24.0
2026-02-03 14:30:52,179:INFO:          setuptools: 80.9.0
2026-02-03 14:30:52,179:INFO:             pycaret: 3.3.2
2026-02-03 14:30:52,179:INFO:             IPython: 9.8.0
2026-02-03 14:30:52,179:INFO:          ipywidgets: 8.1.8
2026-02-03 14:30:52,179:INFO:                tqdm: 4.67.1
2026-02-03 14:30:52,179:INFO:               numpy: 1.26.4
2026-02-03 14:30:52,179:INFO:              pandas: 2.1.4
2026-02-03 14:30:52,179:INFO:              jinja2: 3.1.6
2026-02-03 14:30:52,179:INFO:               scipy: 1.11.4
2026-02-03 14:30:52,179:INFO:              joblib: 1.3.2
2026-02-03 14:30:52,179:INFO:             sklearn: 1.4.2
2026-02-03 14:30:52,179:INFO:                pyod: 2.0.6
2026-02-03 14:30:52,179:INFO:            imblearn: 0.14.1
2026-02-03 14:30:52,179:INFO:   category_encoders: 2.7.0
2026-02-03 14:30:52,179:INFO:            lightgbm: 4.6.0
2026-02-03 14:30:52,179:INFO:               numba: 0.63.1
2026-02-03 14:30:52,179:INFO:            requests: 2.32.5
2026-02-03 14:30:52,179:INFO:          matplotlib: 3.7.5
2026-02-03 14:30:52,179:INFO:          scikitplot: 0.3.7
2026-02-03 14:30:52,179:INFO:         yellowbrick: 1.5
2026-02-03 14:30:52,179:INFO:              plotly: 6.5.0
2026-02-03 14:30:52,179:INFO:    plotly-resampler: Not installed
2026-02-03 14:30:52,179:INFO:             kaleido: 1.2.0
2026-02-03 14:30:52,180:INFO:           schemdraw: 0.15
2026-02-03 14:30:52,180:INFO:         statsmodels: 0.14.6
2026-02-03 14:30:52,180:INFO:              sktime: 0.26.0
2026-02-03 14:30:52,180:INFO:               tbats: 1.1.3
2026-02-03 14:30:52,180:INFO:            pmdarima: 2.0.4
2026-02-03 14:30:52,180:INFO:              psutil: 7.1.3
2026-02-03 14:30:52,180:INFO:          markupsafe: 3.0.3
2026-02-03 14:30:52,180:INFO:             pickle5: Not installed
2026-02-03 14:30:52,180:INFO:         cloudpickle: 3.1.2
2026-02-03 14:30:52,180:INFO:         deprecation: 2.1.0
2026-02-03 14:30:52,180:INFO:              xxhash: 3.6.0
2026-02-03 14:30:52,180:INFO:           wurlitzer: Not installed
2026-02-03 14:30:52,180:INFO:PyCaret optional dependencies:
2026-02-03 14:30:52,228:INFO:                shap: Not installed
2026-02-03 14:30:52,228:INFO:           interpret: Not installed
2026-02-03 14:30:52,229:INFO:                umap: Not installed
2026-02-03 14:30:52,229:INFO:     ydata_profiling: Not installed
2026-02-03 14:30:52,229:INFO:  explainerdashboard: Not installed
2026-02-03 14:30:52,229:INFO:             autoviz: Not installed
2026-02-03 14:30:52,229:INFO:           fairlearn: Not installed
2026-02-03 14:30:52,229:INFO:          deepchecks: Not installed
2026-02-03 14:30:52,229:INFO:             xgboost: 3.1.2
2026-02-03 14:30:52,229:INFO:            catboost: 1.2.8
2026-02-03 14:30:52,229:INFO:              kmodes: Not installed
2026-02-03 14:30:52,229:INFO:             mlxtend: Not installed
2026-02-03 14:30:52,229:INFO:       statsforecast: Not installed
2026-02-03 14:30:52,229:INFO:        tune_sklearn: Not installed
2026-02-03 14:30:52,229:INFO:                 ray: Not installed
2026-02-03 14:30:52,229:INFO:            hyperopt: Not installed
2026-02-03 14:30:52,229:INFO:              optuna: 4.6.0
2026-02-03 14:30:52,229:INFO:               skopt: Not installed
2026-02-03 14:30:52,229:INFO:              mlflow: Not installed
2026-02-03 14:30:52,229:INFO:              gradio: Not installed
2026-02-03 14:30:52,229:INFO:             fastapi: 0.123.10
2026-02-03 14:30:52,230:INFO:             uvicorn: 0.38.0
2026-02-03 14:30:52,230:INFO:              m2cgen: Not installed
2026-02-03 14:30:52,230:INFO:           evidently: Not installed
2026-02-03 14:30:52,230:INFO:               fugue: Not installed
2026-02-03 14:30:52,230:INFO:           streamlit: Not installed
2026-02-03 14:30:52,230:INFO:             prophet: Not installed
2026-02-03 14:30:52,230:INFO:None
2026-02-03 14:30:52,230:INFO:Set up data.
2026-02-03 14:30:52,236:INFO:Set up folding strategy.
2026-02-03 14:30:52,236:INFO:Set up train/test split.
2026-02-03 14:30:52,244:INFO:Set up index.
2026-02-03 14:30:52,244:INFO:Assigning column types.
2026-02-03 14:30:52,249:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-02-03 14:30:52,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,312:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,357:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,361:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,496:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,500:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,500:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-02-03 14:30:52,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,606:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,611:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-02-03 14:30:52,720:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,723:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,724:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-02-03 14:30:52,819:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,822:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,918:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:52,921:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:52,924:INFO:Preparing preprocessing pipeline...
2026-02-03 14:30:52,925:INFO:Set up label encoding.
2026-02-03 14:30:52,926:INFO:Set up simple imputation.
2026-02-03 14:30:52,928:INFO:Set up encoding of categorical features.
2026-02-03 14:30:52,987:INFO:Finished creating preprocessing pipeline.
2026-02-03 14:30:52,995:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tream\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['firmness', 'hue', 'saturation',
                                             'brightness', 'weight_g',
                                             'size_cm3', 'density',
                                             'color_brightness_ratio',...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['color_category'],
                                    transformer=OneHotEncoder(cols=['color_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2026-02-03 14:30:52,996:INFO:Creating final display dataframe.
2026-02-03 14:30:53,187:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                           ripeness
2                   Target type                                         Multiclass
3                Target mapping  breaking: 0, firm-ripe: 1, hard: 2, pre-condit...
4           Original data shape                                          (250, 11)
5        Transformed data shape                                          (250, 14)
6   Transformed train set shape                                          (175, 14)
7    Transformed test set shape                                           (75, 14)
8              Numeric features                                                  9
9          Categorical features                                                  1
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               ca3c
2026-02-03 14:30:53,287:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:53,290:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:53,388:INFO:Soft dependency imported: xgboost: 3.1.2
2026-02-03 14:30:53,392:INFO:Soft dependency imported: catboost: 1.2.8
2026-02-03 14:30:53,398:INFO:setup() successfully completed in 1.34s...............
2026-02-03 14:30:53,399:INFO:Initializing create_model()
2026-02-03 14:30:53,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001129456CA50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-02-03 14:30:53,399:INFO:Checking exceptions
2026-02-03 14:30:53,400:INFO:Importing libraries
2026-02-03 14:30:53,400:INFO:Copying training dataset
2026-02-03 14:30:53,404:INFO:Defining folds
2026-02-03 14:30:53,405:INFO:Declaring metric variables
2026-02-03 14:30:53,405:INFO:Importing untrained model
2026-02-03 14:30:53,405:INFO:Logistic Regression Imported successfully
2026-02-03 14:30:53,406:INFO:Starting cross validation
2026-02-03 14:30:53,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
